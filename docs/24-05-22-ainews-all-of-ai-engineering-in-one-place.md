---
companies:
- openai
- google-deepmind
- anthropic
- mistral-ai
- cohere
- hugging-face
- adept
- midjourney
- character-ai
- microsoft
- amazon
- nvidia
- salesforce
- mastercard
- palo-alto-networks
- axa
- novartis
- discord
- twilio
- tinder
- khan-academy
- sourcegraph
- mongodb
- neo4j
- hasura
- modular
- cognition
- anysphere
- perplexity-ai
- groq
- mozilla
- nous-research
- galileo
- unsloth
- langchain
- llamaindex
- instructor
- weights-biases
- lambda-labs
- neptune
- datastax
- crusoe
- covalent
- qdrant
- baseten
- e2b
- octo-ai
- gradient-ai
- lancedb
- log10
- deepgram
- outlines
- crew-ai
- factory-ai
date: '2024-05-23T01:22:53.232395Z'
description: '即将于 **6 月 25 日至 27 日**在旧金山举行的 **AI 工程师世界博览会 (AI Engineer World''s Fair)**
  将采用显著扩大的活动形式，届时将有来自 **OpenAI、DeepMind、Anthropic、Mistral、Cohere、HuggingFace** 和 **Character.ai**
  等**顶尖模型实验室**的展位、演讲和研讨会。此外，**微软 Azure、亚马逊 AWS、谷歌 Vertex** 以及 **英伟达 (Nvidia)、Salesforce、万事达卡
  (Mastercard)、派拓网络 (Palo Alto Networks)** 等各大公司也将参与其中。


  本次活动涵盖 **9 个主题方向**，包括 **RAG（检索增强生成）、多模态、评估/运维 (evals/ops)、开源模型、代码生成、GPU、智能体 (agents)、财富
  500 强中的 AI**，以及新增的 **AI 领导力**方向。


  此外，**Anthropic** 分享了关于 **Claude 3 Sonnet** 的可解释性研究，揭示了数百万个可引导的可解释特征，这些特征可用于修改模型行为，包括与偏见和不安全内容相关的安全特征，不过其实际应用仍需进一步研究。该活动还为
  AI News 的读者提供了折扣码。'
id: cb95bcde-3d85-4898-9cc4-6b7272ca5b88
models:
- claude-3-sonnet
- claude-3
original_slug: ainews-the-top-ai-engineer
people: []
title: '**AI 工程全集，尽在此处**


  （也可以翻译为：**AI 工程一站式汇总**）'
topics:
- interpretability
- feature-steering
- safety
- multilinguality
- multimodality
- rag
- evals-ops
- open-models
- code-generation
- gpus
- agents
- ai-leadership
---

<!-- buttondown-editor-mode: plaintext -->**Deep IRL networks 是你唯一需要的！6 月 25-27 日在旧金山。**

> 2024/5/21-2024/5/22 AI 新闻。
我们为您检查了 7 个 subreddits、[**384** 个 Twitter 账号](https://twitter.com/i/lists/1585430245762441216) 和 **29** 个 Discord（**380** 个频道和 **7699** 条消息）。
预计节省阅读时间（以 200wpm 计算）：**805 分钟**。

有很多非技术性新闻——[加州参议院通过了 SB 1047](https://www.reddit.com/r/LocalLLaMA/comments/1cxqtrv/comment/l54rdfh/)，关于 [Vox 报道的 OpenAI 员工合同](https://x.com/KelseyTuoc/status/1793402040439476554) 和 [安全派辞职](https://x.com/GretchenMarina/status/1793403475260551517) 的更多爆炸性新闻，虽然 [Mistral v0.3 已发布](https://x.com/reach_vb/status/1793337655595340267)，但目前还没有评估报告或博客文章可供讨论。

鉴于今天是技术上的平静日，我们借此机会分享 [**AI Engineer World's Fair** 首批演讲者名单](https://x.com/aiDotEngineer/status/1791506805065216017) 的公告！

> 摘要：我们为 AI News 读者提供一次性折扣：[**点击此处**](https://ti.to/software-3/ai-engineer-worlds-fair/discount/AINEWS) 并在周五结束前输入 `AINEWS` :)

 
![image.png](https://assets.buttondown.email/images/a40e40f8-c9f2-4721-a6f8-3bbcfb777204.png?w=960&fit=max)
 

## AI Engineer World's Fair (6 月 25-27 日在旧金山)

[首届峰会好评如潮](https://eugeneyan.com/writing/aieng-reflections/)，现在的**新形式规模扩大了 4 倍**，包含展位、演讲和研讨会，参与方包括：

- **顶级模型实验室** (OpenAI, DeepMind, Anthropic, Mistral, Cohere, HuggingFace, Adept, Midjourney, Character.ai 等)
- **三大云厂商** (Microsoft Azure, Amazon AWS, Google Vertex)
- **将 AI 投入生产的大型公司** (Nvidia, Salesforce, Mastercard, Palo Alto Networks, AXA, Novartis, Discord, Twilio, Tinder, Khan Academy, Sourcegraph, MongoDB, Neo4j, Hasura 等)
- **设定议程的颠覆性初创公司** (Modular 即 Chris Lattner, Cognition 即 Devin, Anysphere 即 Cursor, Perplexity, Groq, Mozilla, Nous Research, Galileo, Unsloth 等)
- **AI Engineer 领域的顶级工具** (LangChain, LlamaIndex, Instructor, Weights & Biases, Lambda Labs, Neptune, Datastax, Crusoe, Covalent, Qdrant, Baseten, E2B, Octo AI, Gradient AI, LanceDB, Log10, Deepgram, Outlines, Unsloth, Crew AI, Factory AI 等等)

涵盖 **9 个演讲方向**：**RAG、Multimodality、Evals/Ops（新增！）、Open Models（新增！）、CodeGen、GPUs（新增！）、Agents、AI in the Fortune 500（新增！）**，以及首次设立的专门面向 AI 副总裁的 **AI Leadership** 方向，还有 **50 多场研讨会和展览会议**，涵盖了所有 AI 工程主题。当然，最重要的方向是未列出的：**走廊交流 (hallway track)**，我们对此投入了大量心血，但在发生之前无法描述。

为了庆祝 World's Fair 的启动，**我们为 AI News 读者提供一次性折扣**：[**点击此处**](https://ti.to/software-3/ai-engineer-worlds-fair/discount/AINEWS) 并在周五结束前输入 `AINEWS` :) 

如果这里或 Latent Space 的内容与你的兴趣具有最高的余弦相似度 (cosine similarity)，**那么这个会议就是为你量身定制的**。6 月 25-27 日旧金山见！

---


{% if medium == 'web' %}


**目录**

[TOC] 

{% else %}

**目录**和 Discord 摘要已移至此邮件的网页版：[{{ email.subject }}]({{ email_url }})！

{% endif %}



---

# AI Twitter 综述

> 所有综述均由 Claude 3 Opus 完成，从 4 次运行中选取最佳。我们正在尝试使用 Haiku 进行聚类和流程工程 (flow engineering)。

**Anthropic 关于 Claude 3 Sonnet 的可解释性研究**

- **提取可解释特征**：[@AnthropicAI](https://twitter.com/AnthropicAI/status/1792935511582986466) 使用字典学习从 Claude 3 Sonnet 的激活值中提取了数百万个可解释的“特征”，这些特征对应于模型学到的抽象概念。**许多特征是多语言和多模态的**。
- **通过特征引导修改行为**：[@AnthropicAI](https://twitter.com/AnthropicAI/status/1792935517991895061) 发现，在前向传播过程中对这些特征进行干预（“特征引导”）可以**以与特征含义相关的可解释方式，可靠地修改模型的行为和输出**。
- **安全相关特征**：[@AnthropicAI](https://twitter.com/AnthropicAI/status/1792935524220481777) 识别出许多与令人担忧的能力或行为相对应的“安全相关”特征，例如**不安全代码、偏见、不诚实、权力寻求以及危险/犯罪内容**。激活这些特征可能会诱导模型表现出这些行为。
- **初步工作，仍需更多研究**：[@AnthropicAI](https://twitter.com/AnthropicAI/status/1792935531925430407) 指出这项工作是初步的，虽然这些特征似乎与安全应用有合理的关联，但**仍需要大量工作来建立实际效用**。
- **可解释性团队招聘**：[@AnthropicAI](https://twitter.com/AnthropicAI/status/1792935540536279368) 正在为其可解释性团队招聘经理、研究科学家和研究工程师，以进一步推进这项工作。

**Microsoft 的 Phi-3 模型**

- **Phi-3 小型和中型模型发布**：[@_philschmid](https://twitter.com/_philschmid/status/1792934321407369532) 宣布 Microsoft 已在 MIT 许可证下发布了 Phi-3 small (7B) 和 medium (14B) 模型，**其 instruct 版本支持高达 128k 的上下文**。
- **表现超越 Mistral, Llama, GPT-3.5**：[@_philschmid](https://twitter.com/_philschmid/status/1792934321407369532) 声称 Phi-3 small 在基准测试中优于 Mistral 7B 和 Llama 3 8B，而 **Phi-3 medium 的表现则优于 GPT-3.5 和 Cohere Command R+**。
- **训练细节**：[@_philschmid](https://twitter.com/_philschmid/status/1792934321407369532) 指出这些模型是在 4.8 万亿个 token 上训练的，包括合成数据和过滤后的公开数据集，并支持多语言，**通过 SFT 和 DPO 进行了微调**。目前尚未发布基座模型。
- **Phi-3-Vision 模型**：Microsoft 还发布了拥有 4.2B 参数的 Phi-3-vision，[@rohanpaul_ai](https://twitter.com/rohanpaul_ai/status/1793031695702036869) 指出它**在视觉推理任务上优于 Claude-3 Haiku 和 Gemini 1.0 Pro V 等更大规模的模型**。
- **基准测试与微调**：许多人渴望对 Phi-3 模型进行基准测试，并可能针对特定应用进行微调，尽管 [@abacaj](https://twitter.com/abacaj/status/1792991309751284123) 指出**在对话模型上进行微调有时会导致性能比基座模型更差**。

**Perplexity AI 与 TakoViz 合作开展知识搜索**

- **使用 TakoViz 进行先进知识搜索**：[@perplexity_ai](https://twitter.com/perplexity_ai/status/1792948540542517458) 宣布与 TakoViz 建立合作伙伴关系，为 Perplexity 用户带来**先进的知识搜索和可视化功能**，允许他们搜索、对比并分享权威的知识卡片。
- **权威数据提供商**：[@perplexity_ai](https://twitter.com/perplexity_ai/status/1792948544669667554) 指出 TakoViz 的知识来源于**权威数据提供商，其不断增长的索引涵盖了金融、经济和地缘政治数据**。
- **交互式知识卡片**：[@AravSrinivas](https://twitter.com/AravSrinivas/status/1792963691669008390) 解释说，用户现在可以提示 Perplexity **比较特定时间段内的股票价格或贷款等数据**，并返回交互式知识卡片。
- **超越摘要功能**：[@AravSrinivas](https://twitter.com/AravSrinivas/status/1792964343874892202) 表示，这使得 Perplexity 能够超越简单的摘要，**实现跨时间线的细粒度数据查询**，现在通过单个搜索栏即可完成。
- **对合作的热情**：[@AravSrinivas](https://twitter.com/AravSrinivas/status/1792966258822095347) 表达了他对与 TakoViz 团队合作并参与其种子前轮融资的热爱，并提到了他们的**客户至上精神以及这次集成将为 Perplexity 用户带来的价值**。

**杂项**

- **Karina Nguyen 加入 OpenAI**：[@karinanguyen_](https://twitter.com/karinanguyen_/status/1792996299069071760) 宣布在 Anthropic 工作 2 年后离职并加入 OpenAI 担任研究员，分享了**关于 AI 进展、文化和个人成长的经验教训**。
- **Suno 为 AI 音乐融资 1.25 亿美元**：[@suno_ai_](https://twitter.com/suno_ai_/status/1792922276683297162) 宣布融资 1.25 亿美元，旨在**构建能够增强音乐制作中人类创造力的 AI**，并正在招聘音乐创作者、音乐爱好者和技术专家。
- **Yann LeCun 谈 LLMs 与下一代 AI**：[@ylecun](https://twitter.com/ylecun/status/1793326904692428907) 建议对构建下一代 AI 系统感兴趣的学生**不要研究 LLMs**，暗示他本人正在研究替代方案。
- **Mistral AI 发布新的 Base 和 Instruct 模型**：[@_philschmid](https://twitter.com/_philschmid/status/1793337888110694683) 分享了 Mistral AI 发布了新的 7B Base 和 Instruct 模型，具有**扩展的 32k 词汇量、function calling 支持以及 Apache 2.0 许可证**。
- **Cerebras 和 Neural Magic 实现稀疏 LLMs**：[@slashML](https://twitter.com/slashML/status/1793030889233936695) 分享了来自 Cerebras 和 Neural Magic 的论文，关于**实现稀疏的基础 LLMs，以实现更快、更高效的预训练和推理**。

---

# AI Reddit 回顾

> 涵盖 r/LocalLlama, r/machinelearning, r/openai, r/stablediffusion, r/ArtificialInteligence, /r/LLMDevs, /r/Singularity。评论抓取功能现已上线，但仍有很大改进空间！

**AI 模型发布与基准测试**

- **微软在 MIT 许可证下发布 Phi-3 模型**：在 /r/LocalLLaMA 中，微软已在 Huggingface 上以 MIT 许可证发布了 Phi-3 small (7B) 和 medium (14B) 模型，包括 [**128k 和 4-8k 上下文版本以及一个视觉模型**](https://www.reddit.com/r/LocalLLaMA/comments/1cxa6w5/phi3_small_medium_are_now_available_under_the_mit/)。
- **Phi-3 模型已集成到 llama.cpp 和 Ollama**：Phi-3 模型已被 [添加到 llama.cpp](https://www.reddit.com/r/LocalLLaMA/comments/1cxi14h/phi3_128k_model_support_merged_into_llamacpp/) 和 [Ollama](https://www.reddit.com/r/LocalLLaMA/comments/1cxofw0/has_anyone_gotten_phi3vision128kinstruct/) 框架中，**基准测试显示它们在 7-14B 参数范围内的表现优于其他模型**。
- **Meta 可能不会开源 400B 模型**：根据 [/r/LocalLLaMA 上的一位爆料者](https://www.reddit.com/r/LocalLLaMA/comments/1cxnrov/disappointing_if_true_meta_plans_to_not_open_the/)，Meta 可能会违背之前的迹象，**不开源其 400B 模型，这会让许多人感到失望**。
- **基准测试比较了 17 个 LLM 在 NL to SQL 上的表现**：[/r/LocalLLaMA 上发布的一项全面基准测试](https://www.reddit.com/r/LocalLLaMA/comments/1cx1wdy/findings_from_latest_comprehensive_benchmark/) 比较了包括 GPT-4 在内的 **17 个 LLM 在自然语言转 SQL (NL to SQL) 任务上的表现，GPT-4 在准确性和成本方面领先，但不同托管平台的性能差异显著**。

**AI 硬件与计算**

- **微软为主流 PC 引入 NPU**：微软宣布 [神经网络处理单元 (NPU) 将成为主流 PC 处理 AI 工作负载的标配](https://www.reddit.com/r/singularity/comments/1cxcdie/microsoft_event_live/)，新款 Surface 笔记本电脑将提供 **独有的 64GB RAM 选项以支持大模型**。
- **M.2 和 PCIe NPU 加速器概览**：[/r/LocalLLaMA 上的一篇综述](https://www.reddit.com/r/LocalLLaMA/comments/1cx5jvc/overview_of_m2_pcie_npus/) 探讨了目前 **M.2 和 PCIe NPU 加速卡的情况，指出大多数加速卡在内存带宽方面仍落后于 GPU，但该领域正在迅速发展**。

**AI 担忧与监管**

- **欧洲通过《AI 法案》监管 AI 开发和使用**：[欧盟已通过全面的《AI 法案》(AI Act)](https://www.reddit.com/r/singularity/comments/1cxfqau/corpos_should_drop_the_whole_ai_safety_facade/)，该法案将 **从 2026 年开始监管 AI 系统的开发和使用，并可能影响全球的监管趋势**。
- **加州参议院通过 AI 安全与创新法案**：加州参议院通过了 [SB1047 法案以促进 AI 安全与创新](https://www.reddit.com/r/LocalLLaMA/comments/1cxnrov/disappointing_if_true_meta_plans_to_not_open_the/)，**反应褒贬不一，一些人担心这会限制该州的 AI 进步**。
- **TED 负责人称 Meta 开源 AI 是“鲁莽的”**：[TED 负责人 Chris Anderson 称 Meta 开源 AI 模型是“鲁莽的”](https://www.reddit.com/r/singularity/comments/1cx4onf/i_am_tired_of_scarjo_conflict/)，**对于 AI 进步的倡导者来说，这样一位有影响力的人物持此立场令人担忧**。

**AI 助手与 Agent**

- **微软推出 Copilot AI Agent 功能**：微软宣布了 [Copilot 的新 Agent 功能](https://www.reddit.com/r/OpenAI/comments/1cxhjov/recall_is_actually_a_massive_game_changer/)，它们可以 **充当虚拟员工，早期预览展示了其自动化复杂工作流的能力**。
- **演示展示了实时多模态 AI 游戏 Agent**：[/r/singularity 上发布的一个演示](https://www.reddit.com/r/singularity/comments/1cxcdie/microsoft_event_live/) 展示了 **实时多模态 AI Agent 如何通过视觉感知游戏状态并提供战略指导来辅助视频游戏**。
- **关于亚马逊 AI 助手缺乏进展的疑问**：/r/singularity [讨论了亚马逊在 AI 助手方面相对于其他科技巨头明显的进展不足](https://www.reddit.com/r/singularity/comments/1cxbib0/how_is_amazon_missing_the_ai_boat_so_badly_here/)，**考虑到他们通过 Alexa 拥有的广泛消费者覆盖面，这一点令人费解**。

**Meme 与幽默**

- **Meme 凸显 AI 的飞速进展**：关于 [AI 进步的飞快速度](https://www.reddit.com/r/LocalLLaMA/comments/1cxa6w5/phi3_small_medium_are_now_available_under_the_mit/)、**各大公司夸张的宣称以及对先进 AI 系统的担忧，各种 Meme 和笑话广为流传**。

---

# AI Discord 摘要回顾

> 摘要之摘要的摘要

1. **LLM 基准测试与性能优化**：
   - **微软的 [Phi-3 Models](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct)** 提供了高上下文长度和强劲性能，引发了关于基准测试和内存使用的讨论，但也发现了在 **llama.cpp** 等工具中的兼容性问题。
   - 讨论了如 **torch.compile** 和特定 GPU 设置等各种优化计算效率的技术，并通过 [tensor 重塑示例](https://github.com/tinygrad/tinygrad/blob/d12d412e8b0c900681e9d6c39e46c6e1594c2dcc/tinygrad/tensor.py#L83)等见解进行了分享。

2. **开源 AI 工具与框架**：
   - **[Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)** 框架成为微调 Llama 和 Mistral 等模型的首选，其 Docker 设置简化了使用（[快速入门指南](https://latent-space-xi.vercel.app/til/create-a-conda-env-for-axolotl)）。
   - **[LlamaIndex](https://docs.llamaindex.ai/en/stable/api_reference/packs/code_hierarchy/?h=code)** 引入了文档解析和批处理推理技术，集成了 GPT-4o 的能力，以增强复杂文档处理和查询准确性。

3. **AI 立法与社区响应**：
   - 加利福尼亚州的 SB 1047 [法案](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047)引发了关于新规对开源模型影响的激烈辩论，人们担心这会扼杀创新并偏袒主要的既得利益者。
   - 围绕 AI 语音复制产生了伦理和法律问题的讨论，特别是 OpenAI 争议性地模仿 Scarlett Johansson 的声音，在公众强烈反对后随后将其移除。

4. **新型 AI 模型发布与分析**：
   - 社区对 **Mistral-7B v0.3**（具有扩展词汇表和 function calling，[详情](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)）等新发布感到兴奋，而 **Moondream2** 的更新提高了视觉问答的分辨率和准确性。
   - Anthropic 在 **可解释机器学习（interpretable machine learning）** 方面的工作以及 **Phi-3 Vision** 的发布，促使人们深入研究扩展单语义性（[研究](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html)）和实际的 AI 应用。

5. **实际 AI 实现与挑战**：
   - 成员们分享了实际的 AI 实现，从使用 **Surya OCR 进行 PDF 提取**并将文档转换为 markdown（[GitHub 仓库](https://github.com/satish860/PDF-Extraction-API)），到在 **Azure 上构建安全的代码执行环境**（[动态会话](https://t.co/lTrUPoTMcF)）。
   - **LangChain** 社区强调了部署和端点一致性问题，[GitHub 仓库](https://github.com/langchain-ai/langserve/issues/301)上的详细故障排除帮助简化了部署流程并增强了 chatbot 功能。

---

{% if medium == 'web' %}

# 第一部分：高层级 Discord 摘要

## [Unsloth AI (Daniel Han)](https://discord.com/channels/1179035537009545276) Discord

**Phi-3 登场，怀疑与兴奋并存**：微软推出的 **Phi-3 models**（如 [Phi-3-Medium-128K-Instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct)）引发了讨论，由于潜在的基准测试问题，兴奋中夹杂着怀疑，一位用户用一个词评价道：“*确实（literally）*。”

**AI 法律新前沿**：加州的 SB 1047 引发了关于 AI 法律和开源模型影响的讨论，Meta 决定不开源其 400B 模型的权重进一步加剧了讨论，引发了社区对这种受限访问所带来的广泛影响的辩论。

**Unsloth 在模型保存和 Flash Attention 方面的困扰**：有报告称 Unsloth 的 `model.save_pretrained_gguf()` 函数和 Flash Attention 兼容性存在问题，社区建议重新安装 Unsloth 或[移除 Flash Attention](https://github.com/unslothai/unsloth)，并针对 PyTorch 2.3 版本在 T4 GPU 上的问题提供了特定变通方案。

**引导式解码（Guided Decoding）与 YAML 技巧**：关于使用 *引导式解码* 生成结构化 YAML 输出的热烈讨论揭示了 vLLM 对高级语法的潜在支持，强调了将语法（grammars）集成到 prompting 过程中的重要性。

**前沿模型讨论与科幻交织**：用户分享了进展并测试了 [MoRA](https://arxiv.org/abs/2405.12130) 等方法，同时还热烈讨论了《沙丘》系列的哲学内涵，并为读小说优于看电影辩护，强调了对科幻叙事深度的偏好。

---

## [LLM Finetuning (Hamel + Dan)](https://discord.com/channels/1238365980128706560) Discord

- **Surya OCR 助力 PDF 提取胜出**：Marker PDF 有效地将 PDF 转换为 Markdown，凭借 Surya OCR 超越了其他模型，该解决方案已在 [GitHub 上开源](https://github.com/satish860/PDF-Extraction-API)。

- **自我翻译优于原生提示词**：对比了原生语言 Prompt 与翻译后的英文指令；一位成员分享了关于自我翻译的研究，推荐了针对特定任务的 Prompt 策略，并提供了一篇[相关论文](https://arxiv.org/pdf/2308.01223)。

- **新加坡成员分享 LLM 工作坊笔记**：来自新加坡的 Cedric 在他的[工作坊笔记](https://gist.github.com/cedrickchee/c3d9f8fed88f1c486b883153a64ee7dc)中总结了掌握 LLM 的关键点，受到了社区的好评。

- **模型训练与微调趋向于使用 `axolotl`**：多个频道讨论了使用 Axolotl 进行模型微调，并引用了 [Axolotl 的主分支](https://github.com/OpenAccess-AI-Collective/axolotl/tree/main?tab=readme-ov-file#quickstart-)。用户被引导至 [Axolotl Docker 镜像](https://hub.docker.com/layers/winglian/axolotl/main-20240522-py3.11-cu121-2.2.2/images/sha256-47e0feb612caf261764631a0c516868910fb017786a17e4dd40d3e0afb48e018?context=explore)，并分享了[环境配置指南](https://latent-space-xi.vercel.app/til/create-a-conda-env-for-axolotl)。

- **Gradio 维护者加入**：Gradio 维护者 Freddy 为社区提供了 Gradio 资源，包括[快速入门](https://www.gradio.app/guides/quickstart)和[快速开发聊天机器人](https://www.gradio.app/guides/creating-a-chatbot-fast)，而另一位成员表示他们将对自己编写的 Gradio 扩展提出疑问。



---



## [Perplexity AI](https://discord.com/channels/1047197230748151888) Discord

- **微软 Copilot+ 的大胆举措**：关于[微软发布](https://blogs.microsoft.com/blog/2024/05/20/introducing-copilot-pcs/) "Copilot+ PC" 的讨论爆发，这些 PC 被观察到整合了与 OpenAI 非常相似的功能。这些 PC 拥有 40+ TOPS 的性能、全天候电池续航、AI 图像生成能力以及超过 40 种语言的实时字幕。

- **剖析 GPT-4o 上下文窗口**：在关于 GPT-4o 上下文窗口的争论中，公会成员普遍认为 **32k** 默认大小是现状，尽管其能力的边界仍是一个令人好奇的话题。

- **Perplexity 的 Haiku 障碍** *(避免使用 "Unleash")*：公会发现 Perplexity 的默认模型使用发生了重大转变，普通用户从 GPT-3.5 转向使用 **Haiku**，而 **Sonar** 仍为专业用户专属，这引发了关于模型可用性和策略的讨论。

- **API 异常出现**：由于发现 Perplexity 的 API 落后于其网页端，生成过时的标题和令人不满意的搜索输出，担忧随之浮现；其 Beta 状态和有限的 Endpoint 支持进一步加剧了这一问题。

- **社区协作呼吁**：公会成员互相提醒要使共享线程能够正常分享，并提供了[视觉辅助](https://discord.com/channels/1047197230748151888/1054944216876331118/1208752189606989825)来帮助理解该过程，同时还分享了针对共同关注话题的特定 Perplexity AI 搜索链接。



---



## [Stability.ai (Stable Diffusion)](https://discord.com/channels/1002292111942635562) Discord

- **混合模型——并非完美融合**：关于将 *Lightning* 和 *Hyper 模型* 与基础 Stable 模型集成的讨论显示，虽然这种方法可以减少图像生成步骤，但架构不兼容通常会导致低质量的结果。

- **对欧盟 AI 法案（EU AI Act）的担忧增加**：用户批评了新批准的[欧盟 AI 法案](https://www.consilium.europa.eu/en/press/press-releases/2024/05/21/artificial-intelligence-ai-act-council-gives-final-green-light-to-the-first-worldwide-rules-on-ai/)，特别是水印要求，这可能会给 AI 生成内容创作者带来困难。

- **本地 AI 搭建的烦恼**：社区分享了在本地实现 *Stable Diffusion* 的困难，尤其是在 AMD GPU 上。共识倾向于选择 Nvidia GPU，因为其安装简单且具有性能优势。

- **AI 生成内容的质量控制**：对于各种在线空间中充斥着低质量、通用且通常是性暗示的 AI 生成图像，存在明显的反感，这表明在 AI 艺术领域需要更好的内容策展和价值评估。

- **GPU 辩论——Nvidia 赢得青睐**：一场激烈的辩论确认了 Nvidia GPU 是运行 *Stable Diffusion* 的首选，建议优先选择至少具有 12GB VRAM 的版本以获得最佳 AI 性能。



---

## [Eleuther](https://discord.com/channels/729741769192767510) Discord

- **JAX 实现面临 TFLOPS 差异**：工程师们分享了在对 pallas、naive 和 flash v2 的 **JAX** 实现进行基准测试时的困难。报告了 GPU 上的共享内存错误和 TFLOPS 差异，强调了精确性能测量的必要性。

- **对预印本和学术出版的混合看法**：公会讨论了在 ArXiv 等平台上使用预印本的问题。共识似乎正在发生变化，主要期刊越来越多地接受预印本，标志着学术传播方式的转变。

- **GPT-3 在零温度下的随机性**：讨论围绕 GPT-3 在 temperature 0 时的非确定性输出展开，深入探讨了潜在的硬件层因素，如 CUDA kernel 的非确定性。提到的资源包括一篇 [arxiv 论文](https://arxiv.org/abs/2210.14986) 和一个 OpenAI [论坛讨论](https://community.openai.com/t/run-same-query-many-times-different-results/140588)。

- **小数据集困境**：在简短的插话中，成员们谈到了在小数据集上训练 AI 的挑战，指出其性能通常滞后于在互联网全量数据等更大语料库上训练的模型。

- **可解释机器学习受到关注**：Anthropic 在可解释机器学习特征方面的工作引发了热议，可以在[此处](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html)进一步探索。

- **lm-evaluation Harness 中的 MCQ 随机化查询**：公会成员对 **lm-eval-harness** 中 MCQ 缺乏答案选项随机化表示担忧，特别是对于 **SciQ** 和 **MMLU** 等数据集，暗示了基准测试偏差的可能性。



---



## [HuggingFace](https://discord.com/channels/879548962464493619) Discord

- **微软将 Phi-3 集成到 Transformers**：微软宣布发布 **Phi-3** 模型，具有高达 128k 的上下文和视觉语言 (VLM) 版本，可在 [HuggingFace](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct) 上访问。这些发布为基于指令和视觉语言的 AI 任务提供了新的可能性。

- **ZeroGPU 助力开源 AI**：通过 **$10M ZeroGPU** 计划，Hugging Face 正在通过提供免费 GPU 资源支持独立和学术创作者，自 2024 年 5 月 1 日以来已覆盖超过 1,300 个 spaces。更多详情请见[官方推文](https://x.com/ClementDelangue/status/1791115403734778185)。

- **微调大模型的挑战**：社区参与了关于微调 **Falcon-180B** 等模型的挑战讨论，指出需要超出 **8xH100** 配置的硬件。目前正在努力在 **Llama-8B** 等模型中适配嵌入量化，以实现更高效的内存利用。

- **AI 立法观察**：对话显示了对加州 AI 监管法律及其对初创公司与大公司影响的担忧。建议前往 [NousResearch 的 Discord 服务器](https://discord.gg/jqVphNsB4H) 进行更深入的探讨。

- **AI 工具与贡献**：开发者贡献了多个工具和数据集，例如名为 [Notie](https://github.com/branyang02/notie) 的 markdown 笔记应用、使用 Hexo.js 的 Docker 友好型静态 wiki，以及各种新模型，如多语言的 **NorskGPT-Llama3-70b**。还提到了一个名为 [SDXL Flash](https://huggingface.co/spaces/KingNish/SDXL-Flash) 的工具，据称可以在几秒钟内生成高质量图像，展示了 AI 工具开发的活力。



---

## [LM Studio](https://discord.com/channels/1110598183144399058) Discord

**LM Studio 中的双 GPU 动态**：LM Studio 可以处理双 GPU，但它们必须是相同类型的，且用户应对齐 VRAM 容量以获得最佳性能。多 GPU 的配置涉及在系统中创建和修改预设文件。

**Prompt 的精准度与趣味性**：用户建议在 Prompt 中直接引用文本以提高清晰度，同时，人们用“Prompt Engineering”这个带点幽默感的术语来描述那些细致入微的 Prompt 构建策略。

**Phi-3 模型备受关注**：将 **Phi-3** 模型集成到 llama.cpp 的工作正在进行中，用户们正热切等待 Beta 版本发布以及支持新模型的 LM Studio 更新。同时，关于运行 **Phi-3 Medium** 的量化建议是保持在 **Q4** 或以下。

**Linux 的 ROCm 领域**：Linux 用户表达了对 ROCm 测试版本的兴趣，并承认由于 ROCm 平台上的 Tensor 不匹配错误，运行 **Phi-3-medium-128k** 模型仍面临挑战。

**引人注目的新模型发布**：**Mistral v0.3 Instruct** 现已发布，它配备了改进的 Tokenizer 并支持 Function Calling，在语言模型功能方面带来了进步。可以通过 [lmstudio community Huggingface 页面](https://huggingface.co/lmstudio-community/Mistral-7B-Instruct-v0.3-GGUF)进行访问。

---

## [Nous Research AI](https://discord.com/channels/1053877538025386074) Discord

- **别出心裁的 Apple ID 解锁**：工程师们透露了一个[新网站](https://x.com/crinquand_paul/status/1793037790864687448)，用于为非美国 Apple ID 绕过 Vision Pro 的应用限制，这对于想要访问受地理限制的 AI 工具的人来说可能很有趣。

- **增强版 Moondream 发布，挑战极限**：Moondream 的最新更新将图像分辨率提高到了 **756x756**，并将 TextVQA 分数从 **53.1 提升至 57.2**，在各种基准测试中实现了约 0.5% 的提升，详见[这条推文](https://fxtwitter.com/vikhyatk/status/1792512588431159480?s=19)。

- **Phi-3 Small 即将到来？**：关于 Microsoft 对 Phi 模型发布策略的猜测不断，工程师们分享了关于 Phi 3、7 和 14 可用性的见解。Yann LeCun 在 [Twitter](https://x.com/q_brabus/status/1793227643556372596?s=46) 上澄清了关于即将发布的 **LLaMa 3 400B+** 模型将是闭源的传闻，指出其将继续保持开源状态。

- **SB 1047 引起争议**：加利福尼亚州的 SB 1047 法案让工程师们对其对开源软件（OSS）的影响感到担忧，分享的[法案文本](https://legiscan.com/CA/text/SB1047/id/2919384)凸显了这一点，Meta 也因涉嫌监管操纵而受到批评。

- **Anthropic 的认知图谱**：Anthropic 追踪语言模型认知图谱的努力引起了工程师们的关注，这为专注于 AI 解释性的人员提供了潜在的宝贵资源。关于 LLM 推理的家庭配置讨论中，提到了使用 2x **4090s** 的个人基础设施，而 **Runpod** 和 **Replicate** 等平台因其便利性也成为了讨论对象，尽管某些平台的操作难度较大。

- **Phi-3 Vision 发布，深度与访问兼备**：随附全面的教育资源包发布，工程师们讨论了这个具有 **128K Context** 的多模态模型 Phi-3 Vision，并提供了 Microsoft 资源的链接，如 [技术报告](https://aka.ms/phi3-tech-report) 和 [Hugging Face](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct) 上的模型页面。

- **数字知识的宏伟设计**：围绕 Obsidian 的知识图谱可视化展开了讨论，它被比作“合成大脑”，讨论还扩展到了其插件集成和数据哲学，并辅以[知识图谱延时摄影视频](https://youtube.com/shorts/4YQhH61tvOc?si=0Dx1KyJP8VMz-pXY)以及针对 Obsidian 新手的解释视频。

---

## [CUDA MODE](https://discord.com/channels/1189498204333543425) Discord

- **寻求 SASS 速成课程**：Engineering guild 成员正在寻求如何学习 **Syntactically Awesome Style Sheets (SASS)** 的指导，这是一种 CSS 的扩展，专注于高效地维护样式表。
- **关于 CUDA 函数限定符的好奇心**：关于 **CUDA** 中函数限定符的讨论正在进行中，包括为什么一个函数可以同时是 `__device__` 和 `__host__`，但不能同时是 `__global__` 和 `__host__`。
- **Torch 与 Numpy 中的优化与陷阱**：成员们正在比较 `torch.empty_like` 与 `torch.empty` 的性能，并讨论由 `numpy's np.zeros_like` 引起的内存泄漏。此外，还有关于 **ResNet blocks** 编译问题的见解分享，利用用户定义的 **Triton kernels** 进行优化，以及一份内容丰富的 [PyTorch tutorial](https://pytorch.org/tutorials/recipes/torch_compile_user_defined_triton_kernel_tutorial.html)。

- **AI 安全的立法热议**：关于 [SB 1047](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047) 通过的热烈讨论，这是一项安全与创新法案，为更受监管的 AI 发展奠定了基础；同时还提到了[这里](https://frankforce.com/city-in-a-bottle-a-256-byte-raycasting-system/)描述的一个超紧凑光线投射引擎。

- **GitHub Pull Requests 技术深挖**：深入探讨了 GitHub pull requests，重点关注 encoder backward passes 的确定性、针对大型数据集的 DataLoader 重构、C 语言中的 HellaSwag 评估以及 kernel 操作的确定性，体现了社区对效率和精确度的重视。相关的链接包括[这个关于确定性 encoder backward kernels 的 PR](https://github.com/karpathy/llm.c/pull/442) 和[这个关于 DataLoader 重构的 PR](https://github.com/karpathy/llm.c/pull/440)。



---



## [OpenAI](https://discord.com/channels/974519864045756446) Discord

- **人工语音争议**：一个与 **Scarlett Johansson** 相似的 AI 生成语音引发了对 AI 伦理实践的担忧，此前 OpenAI 的模型被指出创造了一个与她“惊人相似”的语音。在 Johansson 的法律团队要求透明化后， OpenAI 随后决定移除该语音。
  
- **聊天机器人大杂烩**：对于**代码辅助**，用户推荐了 **GPT-3.5** 的替代方案，特别指出 **Meta AI’s Llama 3** 和 **Mistral Large** 是高效且免费的选择。相比之下，由于微软 **Copilot** 被认为具有**侵入性**和遥测问题，用户对其表示不满。

- **更紧凑 Token 的工具与技巧**：在管理 token 使用和响应冗余度方面， AI 工程师建议设置 **max tokens** 并使用**输出模板**来创建简洁的响应。关于自定义工具，一些开发者表示，与使用 **CodePilot** 等辅助工具相比，使用自己的 prompts 效果更好。

- **平台与模型需要调整**：参与者指出了格式问题，例如 **OpenAI Playground** 输出中不必要的换行符以及不一致的换行处理。此外，服务中断促使大家分享了 [OpenAI Status Page](https://status.openai.com) 以进行服务监控。

- **微软扩展多模态 AI**：微软推出了结合语言和视觉的 **Phi-3-vision**，并评论了其在各种应用中的潜力。为了进一步阅读，成员们参考了一篇详细介绍 **Azure** 上 **Phi-3 family** 新增模型的[博客文章](https://azure.microsoft.com/en-us/blog/new-models-added-to-the-phi-3-family-available-on-microsoft-azure/)。



---

## [Modular (Mojo 🔥)](https://discord.com/channels/1087530497313357884) Discord

- **Mojo 社区会议回顾**：Mojo 爱好者可以通过观看[录像](https://www.youtube.com/playlist?list=PLh0S94-sJw_7nzHzy5DJDm8LUJUss9s0D)了解最新的社区会议内容，会议涵盖了 Basalt 和 Compact Dict 等主题。会议信号表明 Mojo 中将弃用 Tensors，并开启了关于开发数值和 AI 应用新库的对话。

- **Python IPC vs. Threading**：针对 Tkinter 应用中的长时间运行查询，解决方案从多线程、消息队列到 IPC 模块不等，以防止 UI 卡顿。[RabbitMQ 的 Pika Python 客户端教程链接](https://www.rabbitmq.com/tutorials/tutorial-six-python)虽然看起来很有前景，但在实现过程中遇到了困难。

- **Mojo 的技术演进与实践**：关于 Mojo 的讨论显示目前没有官方的包管理器，但 `.mojopkg` 文件已投入使用，特别是在 [lightbug_http](https://github.com/saviorand/lightbug_http/releases/tag/latest-build) 中。Mojo 的优化是基于 MLIR 的，人们对其对自定义数据类型的影响持续保持好奇。`math.bit` 现在已被恰当地重命名为 `bit`，并对 `bswap` 到 `byte_reverse` 等多个函数名称进行了调整。

- **Nightly 版本与开发挑战**：Nightly 版本讨论包括一个 PR 问题，即由于作者提交错误导致 DCO 测试套件失败，已在 [GitHub](https://github.com/modularml/mojo/pull/2739) 上处理。Nightly 版本的发布延迟被追踪到 GitHub Actions，并通过 [GitHub Status](https://www.githubstatus.com/) 得到确认。`math.bit` 模块也被重命名为 `bit`，修改了函数名称以提高清晰度。

- **性能优化建议**：在对小数据集进行排序时，对指针数组进行排序可能更有效。关于 **DTypePointer memset**，向量化版本在 100,000 字节时性能提升了 20%，但由于“使用 clobber memory”的潜在问题，在大数据量下扩展效果不佳。



---



## [LAION](https://discord.com/channels/823813159592001537) Discord

- **语音 AI 的法律迷宫**：使用模仿 Scarlett Johansson 的配音演员引发了关于“冒充”权利的法律和伦理辩论，成员们反思了 [Midler v. Ford Motor Co.](https://en.wikipedia.org/wiki/Midler_v._Ford_Motor_Co.) 案件，将其视为潜在的先例。
  
- **调查数据集消失**：Sakuga-42M 数据集（涉及卡通动画帧研究）的突然移除让成员们对潜在的法律触发因素感到困惑，引发了关于在法律范围内共享数据集的更广泛影响的讨论。

- **微软多模态模型引发关注**：关于微软 **Phi-3 Vision** 模型的讨论深入探讨了其机制，该模型由 [Hugging Face](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct) 展示，引发了关于其功能的对话，特别是与 **GPT-4** 的彩色分类图表输出相比。

- **Anthropic 论文困扰工程师**：最近的 Anthropic 扩展论文被标记为内容沉重但尚未被阅读，这表明尽管它在该领域具有潜在的重要性，但可能需要更清晰的提炼才能被从业者充分理解。

- **怀旧合成语音魅力**：成员们重温了往昔时光，回忆起 DECtalk 语音合成技术，并通过 [Speak & Spell 视频](https://youtu.be/RpeegJ0J5mE?t=121)分享了怀旧之情，这对许多人来说是接触个人计算的最早尝试之一。



---

## [LlamaIndex](https://discord.com/channels/1059199217496772688) Discord

- **GPT-4o 为文档解析铺平道路**：尽管面临背景图像和不规则布局的挑战，GPT-4o 已被用于通过 [LlamaParse](https://t.co/g5TG7brSwt) 将 PDF 和幻灯片等复杂文档解析为结构化的 markdown。详情见[此处](https://t.co/vhtYzsleh2)。

- **Azure 上的安全容器化代码执行**：Azure Container Apps 正在实现 LLM 生成代码在动态会话中的安全执行。更多见解请参考这些 Azure 相关链接：[Container Apps](https://t.co/2cnsBH411k) 和 [Code Security](https://t.co/lTrUPoTMcF)。

- **OpenDev AI 工程师简介**：发布了一场讨论 OpenDevin 的网络研讨会，这是一个旨在创建自主 AI 工程师的平台，由 Robert Brennan 提供教程。感兴趣的观众可以在[此处](https://t.co/a22k0zsV3n)观看。

- **批处理推理增强 GenAI 能力**：关于 GenAI 应用的批处理推理（Batch Inference）处理的最新进展表明，其对数据分析和查询能力有重大益处。通过这些链接深入了解详情：[Batch Inference Integration](https://t.co/vnuvvypZCz) 和 [GenAI Techniques](https://t.co/M0vQQ1uAki)。

- **应对 LlamaIndex 的挑战与解决方案**：AI 工程师们一直在应对 LlamaIndex 的挑战，从在聊天前端设置文档预览到 `"ModuleNotFoundError"` 和 `"pydantic.v1.error_wrappers.ValidationError"` 等错误。这些问题的解决方案涉及导入路径修正和 prompt 移除，同时正在讨论使用余弦相似度（cosine similarity）和 HNSW 的检索器等索引策略，以提高扩展效率。



---



## [OpenRouter (Alex Atallah)](https://discord.com/channels/1091220969173028894) Discord

**打字习惯引发角色扮演讨论**：成员们幽默地识别出 **OpenRouter** 用户的两大类型：寻求 AI 陪伴的用户和钻研奇幻叙事的用户。对话轻松地探讨了部分用户的角色扮演倾向。

**关注 Phi-3**：具备高质量推理能力的 **Phi-3 Vision Model** 已在服务器上推出。可以通过 [HuggingFace](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct) 探索该模型的属性。

**啰嗦的 Wizard 需要修剪**：**Wizard8x22** 模型的冗长问题已得到确认，建议通过调整重复惩罚（repetition penalty）作为解决方案。对话还扩展到对比其他模型的性能，强调模型行为并非在所有方面都一致。

**账单困扰与非营利组织的烦恼**：用户在学生平台上的账单错误引发了讨论，导致了一个涉及重新输入账单信息的临时修复方案。同时也表达了对未来非营利组织折扣的希望。

**实验 LLM 动作指令**：通过 [Twitter 线程](https://x.com/leonjcoe/status/1792946945528320382)分享了 **LLMs** 的创新用法，探索将动作指令作为增强与语言模型交互的新方式。征求了同行工程师的反馈，以突破当前 LLM 交互范式的界限。



---



## [Interconnects (Nathan Lambert)](https://discord.com/channels/1179127597926469703) Discord

**Phi 模型加入战局**：**Phi-small** 和 **Phi-medium** 的发布引发了关于 **Phi-3 Vision** 特性的讨论，并确认它代表了一个新的且稍大一些的变体。

**Meta 的模型决策引起骚动**：一条推文暗示 **Meta** 可能出于对立法的恐惧而保持其 400B 模型闭源，但另一消息来源反驳称该**模型将保持开放权重（open-weight）**。这种混乱凸显了在当前监管环境下分享大规模模型权重的敏感性。 

**OpenAI 因未兑现承诺而遭受抨击**：由于未能履行分配 20% 计算资源的承诺，OpenAI 已解散其**超级对齐（Superalignment）团队**，并引发了辞职潮。再加上涉及前员工 NDA 和既定股权（vested equity）问题的丑闻，给 OpenAI 的领导层和透明度蒙上了一层阴影。

**AI 性能受挫**：微软 Surface 的绘图 AI 因云端安全检查导致的延迟问题而面临批评——这反映了 AI 应用中本地处理能力与安全协议之间的权衡。 

**“研究员”头衔的泛滥**：**Anthropic** 现在拥有超过 500 名“研究员”，这令人惊讶，并引发了关于“研究员”头衔稀释及其对科技行业认知影响的讨论。



---

## [OpenAccess AI Collective (axolotl)](https://discord.com/channels/1104757954588196865) Discord

- **Cohere 集成与 Tokenizer 问题**：工程师们正致力于将 [Cohere (commandr)](https://github.com/OpenAccess-AI-Collective/axolotl/pull/1547/files) 集成到 **Axolotl 系统**中，同时解决与[文档](https://github.com/huggingface/transformers/blob/d24097e0229485287ff4959258c552168bd898c6/src/transformers/models/cohere/tokenization_cohere_fast.py#L51C7-L51C26)中提到的 `CohereTokenizerFast` 相关的 Tokenization 问题。

- **发现 Tiny Mistral 与蒸馏流水线更新**：分享了一个用于测试自定义函数的 **Tiny Mistral 模型**，同时社区讨论了正在进行的 **Mistral 模型**蒸馏流水线（Distillation Pipeline）工作，据报道运行状况良好。

- **全量微调（Full Finetuning）与 LoRA 的讨论**：关于全量微调与 **LoRA** 进行了建设性的讨论，深入探讨了性能差异，特别是模型调整中的风格保留问题，并建议直接参考 [Axolotl GitHub README](https://github.com/OpenAccess-AI-Collective/axolotl?tab=readme-ov-file#tokenization-mismatch-bw-inference--training) 来解决 Tokenization 问题。

- **Axolotl 的下一个大版本与 GPU 微调困扰**：用户对 **Axolotl** 的下一个稳定大版本表示好奇，并讨论了使用 `examples/mistral/lora.yml` 进行微调时 GPU 显存需求的挑战，寻求处理 `CUDA out of memory errors` 的建议。

- **LoRA 合并与状态字典卸载（State Dictionary Offloading）指南**：明确了 **LoRA 合并**中 `offload_dir` 的设置，指出合并后使用 `offload_state_dict` 函数处理大型模型状态字典的重要性，并参考了 [Phorm AI 中的代码搜索](https://phorm.ai/query?projectId=1e8ce0ca-5f45-4b83-a0f4-9da45ce8e78b&threadId=dce0e2d6-3e84-461f-a383-70860ed4ddfb)。



---



## [Latent Space](https://discord.com/channels/822583790773862470) Discord

- **Langchain JS 待完善**：工程师们讨论了 **Langchain JS** 在快速原型设计中的效用，尽管其完善程度落后于 Python 版本。架构重构计划有望在未来版本中带来增强。

- **Scale AI 获得 10 亿美元融资**：[Scale AI](https://fortune.com/2024/05/21/scale-ai-funding-valuation-ceo-alexandr-wang-profitability/) 在一轮融资中筹集了惊人的 10 亿美元，使其估值飙升至 138 亿美元，并预测将在 2024 年底前实现阶段性盈利。

- **Phi 表现强劲**：微软的 **Phi 3 模型**（包含 4K 和 128K 上下文长度链接）已亮相，因其能在 MacBook Pro M1 Pro 等轻量级平台上运行而受到赞誉。社区正在审视其与 **Mixtral**、**Llama** 和 **GPT** 等领先模型的竞争性能。

- **Anthropic 通过字典学习（Dictionary Learning）定义特征**：Anthropic 在其前沿模型的字典学习方面取得了重大进展，能够提取数百万个特征。这被视为 AI 安全性和有效性方面的飞跃，改变了模型激活（Activations）的处理方式。

- **Humane 在 AI Pin 遇挫后寻求收购**：Humane 在其 AI Pin 设备遭遇市场障碍后正寻求收购，洽谈显示其估值目标在 7.5 亿至 10 亿美元之间。讨论围绕着在苹果等巨头主导的市场中进行硬件创新的困难展开。

- **综述论文俱乐部（Survey Paper Club）：浓缩 AI 研究**：邀请成员加入 **Survey Paper Club**，以便在一小时内高效接触多篇研究论文，[注册](https://lu.ma/e5nk2ebp)后可获得邮件通知。



---

## [LangChain AI](https://discord.com/channels/1038097195422978059) Discord

- **LangChain Community 规范 vs LangChain**：讨论明确了 **LangChain** 与 **LangChain Community** 版本之间的区别；前者的架构在 [官方文档](https://python.langchain.com/v0.2/docs/concepts/#architecture) 中有详细阐述。

- **LangServe 'invoke' 困扰**：报告了 **LangServe** 中关于 'invoke' 端点无法提供完整输出的技术问题，这引发了多个频道的辩论，用户反映输出交付存在不一致性。具体问题包括缺少文档检索和输出为空，正如 [LangServe 讨论 #461](https://github.com/langchain-ai/langserve/discussions/461) 及相关 GitHub issues 所记录。

- **RemoteRunnable 的运行问题**：注意到 **RemoteRunnable** 的表现未达预期，与 **RunnableWithMessageHistory** 不一致，导致文档来源缺失并影响了运行可靠性（[参见 GitHub issue](https://github.com/langchain-ai/langserve/issues/618)）。

- **由 Upstage AI Solar 和 LangChain 驱动的 PDF 助手**：分享了一篇 [博客文章](https://medium.com/@sonam.gupta1105/creating-a-pdf-query-assistant-with-upstage-ai-solar-and-langchain-integration-6631280093b5)，指导如何利用新的 **Upstage AI Solar LLM** 与 **LangChain** 集成来构建 PDF 查询助手。

- **简化 LangServe 的 AWS 部署**：成员们被引向一篇 [Medium 文章](https://medium.com/aimonks/deploy-langserve-application-to-aws-2d34b6ee5c1a)，该文章简化了在 AWS 上部署 LangServe 的过程，避开了 Terraform、Pulumi 或 AWS CDK 等云技术的复杂性。



---



## [OpenInterpreter](https://discord.com/channels/1146610656779440188) Discord

**技术对话：OpenInterpreter 的设备对话**：工程师们正在探索 Open Interpreter 如何在应用和设备之间建立联系，利用 Boox E Ink 平板、OneNote 和 VSCode 等工具。尤其令人感兴趣的是使用 Open Interpreter 在无需浏览器干预的情况下查询代码或论文。

**极速 GPT-4o 故障排除**：在将 GPT-4o 与 Open Interpreter 集成时，用户注意到速度至少提升了 5 倍，但面临与 API keys 相关的错误消息挑战。

**Gemini 中的换行符干扰**：由于多余的换行符，Gemini 1.5 和 Gemini Flash 等模型的代码执行受到阻碍；代码块中缺少 "python" 声明也受到了关注。

**立法传说与 AI**：加利福尼亚州备受争议的 AI 法案及随后的讨论点燃了社区，参议员 Scott Wiener 的一封 [公开信](https://x.com/Scott_Wiener/status/1792572175116816853) 正在流传并引发辩论，信中强调了负责任的 AI 发展。

**比尔·盖茨预见更友好的 AI**：盖茨最近撰文谈到了软件中 AI 的未来，预见界面将能通过简单的语言指令处理任务，类似于朋友的协助；他的文章在技术爱好者中引起了关注。一个非官方的 ChatGPT macOS 应用候补名单绕过方法在 [Twitter](https://x.com/testingcatalog/status/1793347117458636981) 上流传，展示了人们对更快获取 AI 软件工具的兴趣。



---

## [tinygrad (George Hotz)](https://discord.com/channels/1068976834382925865) Discord

- **Trigonometric Redefinition a No-Go**：三角函数重定义行不通：社区成员讨论了尝试使用 Taylor series 重定义 **sine** 等三角函数的有效性，共识是这是不必要的重复造轮子。引用了 IBM 对 sine 等函数进行区间划分的实用方法，表明使用既定方法可以在函数中实现完美的准确度。

- **IBM's Code Holds the Answers**：IBM 的代码提供了答案：参与者分享了 **IBM 的 sine 函数实现**，强调了实现完美准确度的复杂性。此外，他们还提到了 IBM 针对大数的范围缩减（range reduction）解决方案，虽然复杂但通常不会影响性能。

- **Training Mode Tips and Tricks**：训练模式技巧：在 **tinygrad** 中，解释了使用 `Tensor.train()` 和 `Tensor.no_grad` 来切换梯度跟踪的方法。有用的代码示例（如这个 [cartpole 示例](https://github.com/tinygrad/tinygrad/blob/d12d412e8b0c900681e9d6c39e46c6e1594c2dcc/examples/beautiful_cartpole.py#L58)）展示了这些机制的用法和好处。

- **Under the Hood of `Tensor.train`**：`Tensor.train` 的底层原理：明确了 `Tensor.train` 实际上是在管理 `Tensor.training` 状态。对于那些喜欢直接控制的人，手动设置 `Tensor.training` 是一个选项，这得到了 tinygrad [后端实现](https://github.com/tinygrad/tinygrad/blob/d12d412e8b0c900681e9d6c39e46c6e1594c2dcc/tinygrad/tensor.py#L83)的支持。

- **Nailing Views with Movement Ops**：通过 Movement Ops 搞定 View：围绕链式移动操作（chained movement operations）的行为及其创建多个 View 的潜力展开了讨论。一个使用 `ShapeTracker` 的例子演示了特定的操作组合如何产生此类场景。



---



## [DiscoResearch](https://discord.com/channels/1178995845727785010) Discord

**SFT vs Preference Optimization Debate**：SFT 与 Preference Optimization 之争：在关于模型训练策略的讨论中，一位成员区分了 **Supervised Fine-Tuning (SFT)** 是增强模型对目标数据点的概率分布，而 **Preference Optimization** 则同时调整期望和非期望的结果。他们质疑了 SFT 相对于 Preference Optimization 的普遍使用，后者可能为模型行为提供更全面的方法。

**Excitement Over Phi3 Vision's Low-Parameter Efficiency**：对 Phi3 Vision 低参数效率的兴奋：一位工程师强调，仅拥有 42 亿参数的 **Phi3 Vision** 的开发是图像处理任务中低延迟推理（low-latency inference）的重大进步。该成员断言这可能对机器人技术产生开创性影响，并赞扬了该模型在吞吐量提升方面的潜力，同时分享了公告链接（[来源](https://x.com/jphme/status/1792950682695479734)）。

**Comparing Image Models Between Moondream2 and Phi3 Vision**：Moondream2 与 Phi3 Vision 图像模型对比：社区权衡了 **Moondream2** 与 **Phi3 Vision** 在图像相关任务中的表现。虽然 **Moondream2** 存在幻觉（hallucinations）问题，但一位成员提到正在努力减轻这一问题，展示了对图像模型保真度的持续追求（[Moondream2](https://huggingface.co/spaces/vikhyatk/moondream2)）。

**Mixed Reactions to Microsoft's Model Drops**：对微软发布模型的反应不一：**Microsoft 的 7b 和 14b Instruct 模型**的发布引发了各种观点，从对其在某些语言中的局限性的担忧，到对其在复杂推理和提取任务中效用的乐观。讨论反映了社区对新发布模型及其能力的批判性分析。

**Skepticism Towards Meta's 400b Model**：对 Meta 400b 模型的怀疑：由于社区中流传着关于 **Meta 可能不会开源 400b 模型**的担忧，一位成员通过指出绰号为 Jimmy 的消息来源可信度不明来表达怀疑。这表明了社区对传闻验证的批判态度。



---



## [Cohere](https://discord.com/channels/954421988141711382) Discord

- **Cohere is hiring**：Cohere 正在招聘：一位热心的成员分享了 [Cohere 的职业机会](https://cohere.com/careers)，强调了利用先进的 ML/AI 解决现实世界问题的机会。
  
- **VRAM Calculator Intrigues**：VRAM 计算器引发关注：工程师们正在讨论 [LLM Model VRAM Calculator](https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator) 的发现，质疑为什么在相同上下文长度下， Phi 3 Mini 的 VRAM 占用比 Phi 3 Medium 更高。

- **Bilingual Bot Integration Quest**：双语机器人集成探索：多条帖子显示一名成员正在寻找将 **Command-R** 集成到 **BotPress** 的指南，并请求英文和西班牙文的帮助。

- **Link Confusion Alert**：链接混淆警示：访问 Cohere 招聘页面时存在困惑，至少有一名成员无法通过提供的链接找到正确的页面。

## [AI Stack Devs (Yoko Li)](https://discord.com/channels/1122748573000409160) Discord

- **关于 AI 伴侣的闲聊**：由短语 *"AI waifus save lives!"* 引发的讨论演变成了关于潜在情感化 AI 的对话，暗示了**情感分析 (sentiment analysis)** 对聊天机器人的重要性。
- **聊天机器人的情感智能正在兴起**：分享的 **VentureBeat 文章** 促使工程师们思考当 AI 开始“理解”情感时对商业机器人的影响，这对**用户体验 (user experience)** 和**界面设计 (interface design)** 可能具有重大意义。[关于情感 AI 的 VentureBeat 文章](https://beat.com/ai/exclusive-inflection-ai-reveals-new-team-and-plan-to-embed-emotional-ai-in-business-bots)。
- **3D 聊天机器人受到关注**：来自 **4Wall AI** 的一名成员强调了他们正在进行的 **3D 角色聊天机器人** 工作，暗示了该领域内**人机交互 (human-computer interaction)** 的新机遇。
- **流行文化与 AI 的碰撞**：对 *"Just Monika"* 的引用引发了对《心跳文学部》(*Doki Doki Literature Club*) GIF 的分享，展示了流行文化如何影响围绕 AI 人格的对话。[Ddlc Doki Doki Literature Club GIF](https://tenor.com/view/ddlc-doki-doki-literature-club-just-monika-monika-gif-20717242)。

---

## [Datasette - LLM (@SimonW)](https://discord.com/channels/823971286308356157) Discord

**Snapdragon 开发套件引发辩论**：Qualcomm 售价 899.99 美元的新款 Snapdragon 开发套件（配备 Snapdragon X Elite，拥有 32GB LPDDR5x RAM 和 512GB NVMe 存储）引发了与其前代 600 美元型号相比性价比的讨论，详见 [The Verge](https://www.theverge.com/2024/5/21/24158603/qualcomm-windows-snapdragon-dev-kit-x-elite) 和 [Microsoft Store](https://www.microsoft.com/en-us/d/windows-dev-kit-2023/94k0p67w7581?activetab=pivot:overviewtab)。

**Mac Mini 服务器获得好评**：一位 AI 工程师分享了他们使用 Mac Mini 作为可靠的 Llamafile 服务器并配合 Tailscale 使用的成功经验，赞扬了其**零冷启动 (zero-cold start)** 特性和无缝的 **'llm' CLI** 集成，为需要稳定服务器解决方案的开发者提供了一个实际用例。

**对经济型开发套件的需求**：用户间的讨论表明，人们强烈渴望更实惠的开发套件，同时也表达了审美偏好，例如希望采用透明外壳设计，但未提及具体产品。

**Smalltalk AI 展现潜力**：一位成员介绍了 Claude 进行闲聊 (Smalltalk) 的能力，以“什么是青蛙？”作为示例问题，AI 通过关于两栖动物的基本回答解决了该问题，表明了 AI 对话能力的进步。

---

## [LLM Perf Enthusiasts AI](https://discord.com/channels/1168579740391710851) Discord

**Llama3/Phi3 中的简洁性失误**：有人询问如何阻止 **llama3/phi3** 用 "*additional items omitted for brevity*"（为了简洁起见，省略了额外项）来截断回答，但随后没有出现解决方案或进一步讨论。

---

## [Mozilla AI](https://discord.com/channels/1089876418936180786) Discord

- **面向工程思维的社区活动**：Mozilla AI 宣布启动**成员组织的活动**，以激发创意分享和社区互动，包括演讲、AMA 和演示，首场活动是由 [LLM360 主办的 AMA](https://discord.com/events/1089876418936180786/1240722407594004561)。
  
- **关于开源 LLM 的 AMA**：[LLM360](https://www.llm360.ai/) 举办了一场 [AMA 环节](https://discord.com/events/1089876418936180786/1240722407594004561)，深入探讨了他们在开源 LLM 方面的工作细节，吸引了大量技术爱好者。

- **使用 Llamafiles 生成 Embeddings**：资深机器学习工程师 Kate Silverstein 将演示如何使用 llamafiles 生成 Embeddings，并详细阐述她的[最新博客文章](https://discord.com/channels/1089876418936180786/1242235316170129439)。

- **活动日历一键直达**：Mozilla AI 鼓励成员经常查看活动日历，以获取一系列由社区主导的讨论和技术活动。

- **关于 LLaMA CPP 中模型规范的查询**：一位成员寻求关于通过终端使用 **tinyllama** 模型的澄清，询问是否必须指定 `model="LLaMA_CPP"`，以及在代码片段成功运行时实际生效的是哪个模型。

---

**MLOps @Chipro Discord** 没有新消息。如果该公会长期沉寂，请告知我们，我们将将其移除。

---

**AI21 Labs (Jamba) Discord** 没有新消息。如果该公会长期沉寂，请告知我们，我们将将其移除。

---

**YAIG (a16z Infra) Discord** 没有新消息。如果该公会长期沉寂，请告知我们，我们将将其移除。

---

# 第 2 部分：频道详细摘要与链接

### **Unsloth AI (Daniel Han) ▷ #[general](https://discord.com/channels/1179035537009545276/1179035537529643040/1242398812887056434)** (1309 条消息 🔥🔥🔥):

- **OpenAI 与数据集挑战**：成员们讨论了各种**数据集挑战**，包括转换格式、使用 **ShareGPT** 以及优化训练参数（如 batch sizes）。一位用户分享说，他们“花了 5 小时将网站抓取并转换为 alpaca 格式”，结果发现毫无用处，这表明这些过程是多么繁琐。
- **Phi-3 发布！用户持怀疑态度但感到兴奋**：来自 Microsoft 的 **Phi-3 模型**引发了热议，成员们提到了 [Phi-3-Medium-128K-Instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct)，但也有人对其 benchmark 的有效性表示怀疑。一位用户评价道：“*确实如此 (literally)*”。
- **最新法律限制**：关于加州 SB 1047 法案等 **AI 法规**的对话引发了对开源模型影响的讨论。“Meta 计划不为其 400B 模型开放权重”引发了辩论，用户对其全球影响表示担忧。
- **Colab/Kaggle 的技术问题与解决方法**：记录了一些**常见的技术故障**，特别是关于更新破坏兼容性的问题。用户 `theyruinedelise` 指出了一些必要的解决方法，例如由于“*Pytorch 无法正确检测 T4*”的问题而需要重启 Colab 会话。
- **Unsloth 平台进展**：用户讨论了 Unsloth 平台上的**新模型支持**，例如 [Mistral v3](https://twitter.com/danielhanchen/status/1793356226006511902)，并对改进的 fine-tuning 功能表示兴奋。“Unsloth 现在支持 Mistral v3”，这使得社区更容易采用前沿模型。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>

<li><a href="https://huggingface.co/Sao10K/Fimbulvetr-11B-v2">Sao10K/Fimbulvetr-11B-v2 · Hugging Face</a>：未找到描述</li><li><a href="https://huggingface.co/unsloth/mistral-7b-v0.3-bnb-4bit">unsloth/mistral-7b-v0.3-bnb-4bit · Hugging Face</a>：未找到描述</li><li><a href="https://huggingface.co/fai">fai (fai)</a>：未找到描述</li><li><a href="https://x.com/Scott_Wiener/status/1792572175116816853">来自参议员 Scott Wiener (@Scott_Wiener) 的推文</a>：最近几周，网上出现了大量关于 SB 1047 的讨论，这是我关于负责任地开发最大且最强大的 AI 前沿模型的法案。我们听到了一些非常深刻的见解...</li><li><a href="https://github.com/oKatanaaa/kolibrify/tree/master/examples/training_mini_dolphin">kolibrify/examples/training_mini_dolphin at master · oKatanaaa/kolibrify</a>：使用 Unsloth 进行指令遵循 LLMs 的课程训练 - oKatanaaa/kolibrify</li><li><a href="https://x.com/q_brabus/status/1793227643556372596">来自 QBrabus eu/acc (@q_brabus) 的推文</a>：@apples_jimmy @ylecun @iamgingertrash 问题：关于即将推出的 LLaMa 3 400B+ 模型，它会是开放权重的吗？有很多关于这方面的传闻... 回答：不，它仍然计划是开放的...</li><li><a href="https://huggingface.co/microsoft/Phi-3-medium-128k-instruct">microsoft/Phi-3-medium-128k-instruct · Hugging Face</a>：未找到描述</li><li><a href="https://x.com/erhartford/status/1791573520176025716">来自 Eric Hartford (@erhartford) 的推文</a>：为了回应加州的 SB 1047 法案和 OpenAI 的闭源立场，Cognitive Computations 推出了 Patchy-2.0。该许可证镜像了 Apache-2.0，但明确禁止 OpenAI 和该州...</li><li><a href="https://huggingface.co/docs/datasets/en/loading#csv">Load</a>：未找到描述</li><li><a href="https://www.reddit.com/r/LocalLLaMA/comments/">Reddit - 深入探索一切</a>：未找到描述</li><li><a href="https://github.com/hsiehjackson/RULER?tab=readme-ov-file>">GitHub - hsiehjackson/RULER：此仓库包含 RULER 的源代码：你的长上下文语言模型的真实上下文大小是多少？</a>：此仓库包含 RULER 的源代码：你的长上下文语言模型的真实上下文大小是多少？ - hsiehjackson/RULER</li><li><a href="https://github.com/huggingface/transformers/issues/11693">禁用数据加载器打乱的标志 · Issue #11693 · huggingface/transformers</a>：🚀 功能请求 目前，Trainer 默认会打乱 train_dataset，且没有启用/禁用的标志。@sgugger 动机 即使打乱数据集带来了很多好处...</li><li><a href="https://www.reddit.com/r/LocalLLaMA/comments/1cxnrov/disappointing_if_true_meta_plans_to_not_open_the/">Reddit - 深入探索一切</a>：未找到描述</li><li><a href="https://youtu.be/e3Gvq4NDqvw?si=3b2lILNAiR5CZJMW">Scarlett Johansson 在 OpenAI 发布与其声音“惊人相似”的语音后要求得到答复</a>：Scarlett Johansson 正向 OpenAI 及其 CEO Sam Altman 要求答复，因为该公司发布了一个她认为听起来与其本人“惊人相似”的 ChatGPT 语音...</li><li><a href="https://imgur.com/FhBnfFP">imgur.com</a>：在 Imgur 发现互联网的魔力，这是一个由社区驱动的娱乐目的地。通过有趣的笑话、流行模因、娱乐动图、感人故事、病毒视频等来振奋精神...</li><li><a href="https://www.reddit.com/r/LocalLLaMA/comments/1cxw3u5/it_did_finally_happen_a_law_just_passed_for_the/">Reddit - 深入探索一切</a>：未找到描述</li><li><a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047">法案文本 - SB-1047 前沿人工智能模型安全创新法案。</a>：未找到描述</li><li><a href="https://x.com/Scott_Wiene">来自 FxTwitter / FixupX 的推文</a>：抱歉，该用户不存在 :(</li><li><a href="https://github.com/unslothai/unsloth/issues/504">[紧急] Colab 已损坏 · Issue #504 · unslothai/unsloth</a>：Colab 目前已损坏 - 正在修复中</li><li><a href="https://x.com/danielhanchen/status/1792985678030221464">来自 Daniel Han (@danielhanchen) 的推文</a>：@GoogleColab @PyTorch @thechrisperry 更新：一位 @UnslothAI 社区成员 (Edd) 发现 PyTorch 2.3 无法正确检测 Tesla T4 - PyTorch 认为 Tesla T4 可以支持 bfloat16，但实际上它不支持。...</li><li><a href="https://huggingface.co/datasets/Skorcht/schizoroleplaydataset">Skorcht/schizoroleplaydataset · Hugging Face 数据集</a>：未找到描述</li><li><a href="https://huggingface.co/datasets/Skorcht/ariannarp">Skorcht/ariannarp · Hugging Face 数据集</a>：未找到描述</li><li><a href="https://lu.ma/1wu5ppl5">GPU 优化研讨会 · Luma</a>：我们将举办一场关于 GPU 优化的研讨会，邀请了来自 OpenAI、NVIDIA、Meta 和 Voltron Data 的重磅演讲嘉宾。该活动将在 YouTube 上直播，</li>

以及…</li><li><a href="https://github.com/pytorch/pytorch/blob/main/torch/distributed/fsdp/_optim_utils.py#L1369>">pytorch/torch/distributed/fsdp/_optim_utils.py at main · pytorch/pytorch</a>: Python 中的 Tensor 和动态神经网络，具有强大的 GPU 加速功能 - pytorch/pytorch
</li>
</ul>

</div>
  

---


### **Unsloth AI (Daniel Han) ▷ #[random](https://discord.com/channels/1179035537009545276/1179039861576056922/1242432957030076466)** (233 条消息🔥🔥): 

- **MoRA 引发好奇**：成员们询问了一种名为 [MoRA](https://arxiv.org/abs/2405.12130) 的新方法，并分享了测试其原生（vanilla）实现的计划。有人指出，它似乎是 LoRA 的“放大”版本，针对测量目标景观（objective landscapes）的内在维度进行了优化。

- **《沙丘》系列与哲学讨论占据主导**：用户就《沙丘》系列在最初的英雄之旅之外的哲学深度展开了详细讨论。他们注意到后续的书籍变得越来越具有哲学性，脱离了简单的叙事。

- **科幻小说和推荐刷屏聊天室**：对话转向了各种科幻小说和推荐，包括 Peter Watts 的《盲视》（Blindsight），该书对外星智能和吸血鬼有独特的见解，被描述为“硬核到极致的科幻小说”。

- **对复杂科幻情节的热爱**：用户对复杂且引人入胜的科幻情节表现出热情，将硬科幻小说中的元素与现代 AI 的行为进行对比。他们讨论了文学中写实且富有想象力的外星生命形式，而非陈词滥调的类人形象的吸引力。

- **电影与阅读小说的辩论**：成员们比较了观看科幻电影与阅读小说的体验，一些人表示更倾向于后者，因为其叙事更深刻且富有想象力。对话强调了对近期热门科幻故事电影改编的不满，指出其质量较之书籍的深度有所下降。

**提到的链接**：<a href="https://arxiv.org/abs/2405.12130">MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning</a>：低秩自适应（Low-rank adaptation）是一种流行的针对大语言模型（LLM）的参数高效微调方法。在本文中，我们分析了 LoRA 中实现的低秩更新的影响。我们的研究结果表明……

  

---

### **Unsloth AI (Daniel Han) ▷ #[help](https://discord.com/channels/1179035537009545276/1179777624986357780/1242371434945187861)** (192 条消息🔥🔥): 

- **Unsloth 模型面临保存问题**：用户报告了 [GitHub Issue #485](https://github.com/unslothai/unsloth/issues/485) 中记录的 `model.save_pretrained_gguf()` 函数的问题，该问题因 `UnboundLocalError` 而中断。
- **Flash Attention 导致 CUDA 问题**：多位用户遇到了与其环境配置不匹配的 Flash Attention 版本错误，并讨论了切换到 `xformers` 的方案。因此，starsupernova 建议在不安装 Flash Attention 的情况下[卸载并重新安装](https://github.com/unslothai/unsloth) Unsloth。
- **Pytorch ≥ 2.3 导致 T4 GPU 故障**：多位用户报告了 Pytorch 2.3 版本在 Tesla T4 GPU 上的兼容性问题，建议降级并禁用 bf16 支持。社区的一个变通方法是显式指定 `dtype`。
- **YAML 的引导式解码**：深入讨论了如何利用引导式解码（guided decoding）实现 YAML 的结构化输出，并分享了在提示模型时有效使用 [grammars 和约束输出](https://www.grammar-lib.com) 的见解。这包括 vLLM 中可能支持的使用 JSON Schema 或 BNF 等不同语法的支持。
- **安装和训练差异**：分析了安装说明和训练行为中的差异，特别关注了 `trl` 库及其版本对模型训练的影响。建议进行调整以确保安装和设置的一致性，特别是考虑到近期库版本的不稳定性。

<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://en.wikipedia.org/wiki/Cocktail_party_effect">鸡尾酒会效应 - 维基百科</a>：未找到描述</li><li><a href="https://github.com/unslothai/unsloth/blob/main/unsloth/kernels/cross_entropy_loss.py">unsloth/unsloth/kernels/cross_entropy_loss.py (main 分支)</a>：微调 Llama 3, Mistral &amp; Gemma LLM 快 2-5 倍且节省 80% 显存 - unslothai/unsloth</li><li><a href="https://x.com/danielhanchen/status/1792982364894929083">Daniel Han (@danielhanchen) 的推文</a>：噢不，@GoogleColab 升级到了 @PyTorch 2.3，T4 GPU 无法与 Triton 2.3 配合使用！我尝试将 Triton 降级到 2.2，但仍然失败。这似乎是 Torch 2.3 的问题。@thechrisperr...</li><li><a href="https://huggingface.co/google/gemma-2b/discussions/60#664de2208ab2524c032b00b4">google/gemma-2b · 按照博客微调 gemma-2b 无法得到相同的结果</a>：未找到描述</li><li><a href="https://github.com/unslothai/unsloth/issues/485">使用 llama-cpp-python · Issue #485 · unslothai/unsloth</a>：你好，感谢创建这个精彩的包！save_to_gguf 目前失败，因为 llama.cpp 的安装似乎损坏了。是否可以使用像 llama-cpp-python 之类的工具代替？</li><li><a href="https://github.com/unslothai/unsloth/issues/210">我在原生 Windows 上运行了 Unsloth · Issue #210 · unslothai/unsloth</a>：我在原生 Windows（非 WSL）上运行了 Unsloth。你需要 Visual Studio 2022 C++ 编译器、Triton 和 DeepSpeed。我有一个完整的安装教程，我本想写在这里，但我现在在用手机...</li><li><a href="https://github.com/unslothai/unsloth/pull/506/commits/2b23b9357aba25ab2f3a49d899045547d7dde1d7">danielhanchen 的 Nightly 版本 · Pull Request #506 · unslothai/unsloth</a>：未找到描述</li><li><a href="https://github.com/unslothai/unsloth.git">GitHub - unslothai/unsloth</a>：微调 Llama 3, Mistral &amp; Gemma LLM 快 2-5 倍且节省 80% 显存 - unslothai/unsloth</li><li><a href="https://github.com/unslothai/unsloth/wiki#evaluation-loop---also-oom-or-crashing">首页</a>：微调 Llama 3, Mistral &amp; Gemma LLM 快 2-5 倍且节省 80% 显存 - unslothai/unsloth</li><li><a href="https://github.com/unslothai/unsloth/wiki#training">首页</a>：微调 Llama 3, Mistral &amp; Gemma LLM 快 2-5 倍且节省 80% 显存 - unslothai/unsloth</li><li><a href="https://github.com/unslothai/unsloth/commit/5134a42f0689c0bb69aba12dc668755bdd4b4693">Nightly (#506) · unslothai/unsloth@5134a42</a>：* 更新 llama.py * offload * 更新 llama.py ...</li><li><a href="https://github.com/pytorch/pytorch/blob/b40fb2de5934afea63231eb6d18cc999e228100f/torch/cuda/__init__.py#L130C1-L151C1">pytorch/torch/cuda/__init__.py</a>：Python 中的张量和动态神经网络，具有强大的 GPU 加速 - pytorch/pytorch</li>
</ul>

</div>
  

---

### **Unsloth AI (Daniel Han) ▷ #[showcase](https://discord.com/channels/1179035537009545276/1179779344894263297/1242371648557158461)** (7 条消息): 

- **令人惊叹的结果引发热议**：一位成员对他们的结果表示惊讶，称其为“超级棒”。另一位成员提到了自己的困境，表示无法获得低于 52k 的结果，并对即将发布的文章表示期待。
- **成功的配方即将发布**：一位成员提到他们将在“本周或下周发布配方（recipe）”，尽管指出由于使用了私有数据，无法完全复现早期的结果。他们补充说，对于英文数据集，它的表现可能会更好一些。
- **知识图谱嵌入（Knowledge Graph Embeddings）**：一位成员分享了他们在 Knowledge Graph Embeddings 方面的过往经验，提到由于复杂的 `cypher` 查询，从 Neo4j 图转换到 PyTorch Geometric Dataset 存在困难。另一位成员暗示，使用目前的工具这类任务应该会更容易。
  

---



### **LLM Finetuning (Hamel + Dan) ▷ #[general](https://discord.com/channels/1238365980128706560/1238365980128706563/1242377577696329828)** (242 条消息🔥🔥): 

- **Modal 学习开启新大门**：一位成员分享说他们的公司使用 Marker PDF，利用 Surya OCR 将 PDF 转换为 Markdown 格式。他们指出该工具的结果优于其他开源模型，并已在 [GitHub](https://github.com/satish860/PDF-Extraction-API) 上开源了该解决方案。

- **原生提示词还是翻译？**：成员们讨论了原生语言提示词与带有翻译指令的英文提示词的有效性。一位成员分享了一篇专注于自翻译模型的[论文](https://arxiv.org/pdf/2308.01223)，并补充了各种经验，建议采用针对特定任务的策略。

- **PDF 解析与多模态 LLM**：讨论强调了 PDF 解析中的挑战，提到了 LlamaParse、Unstructured 和 Table Transformers 等多种工具，但没有一个能提供完美的结果。大家对涉及多模态 LLM 和在目标数据上进行微调的策略表现出兴趣。

- **Anthropic 的 Sonnet 论文引发关注**：一位成员分享了 Anthropic 关于可解释性论文的[链接](https://www.anthropic.com/research/mapping-mind-language-model)，引发了关于安全性和引导模型行为的讨论。另一位成员通过相关的 [Twitter 线程](https://x.com/mlpowered/status/1792948212728524917)补充了进一步的见解。

- **社区对 Modal 和工具的参与**：讨论包括对 pyenv、mamba（通过 miniforge）等工具的偏好，以及使用 GUI 进行语言模型微调的便捷性。成员们分享了[安装指南](https://github.com/pyenv/pyenv?tab=readme-ov-file#automatic-installer)，并讨论了各种工作流以及他们在不同软件包和环境中的经验。
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>

<li><a href="https://arxiv.org/abs/2405.00732">LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report</a>: Low Rank Adaptation (LoRA) 已成为大语言模型 (LLMs) 参数高效微调 (PEFT) 中应用最广泛的方法之一。LoRA 减少了可训练参数的数量...</li><li><a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3">mistralai/Mistral-7B-Instruct-v0.3 · Hugging Face</a>: 未找到描述</li><li><a href="https://www.loom.com/share/30d3b2e054f142fda5d905f95fedc29f">Exploring Fine-tuning with Honeycomb Example</a>: 在此视频中，我将带你了解使用 honeycomb 示例微调模型的过程。我提供了关于克隆仓库、安装依赖项以及运行...的逐步说明。</li><li><a href="https://huggingface.co/blog/sc2-instruct">StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation</a>: 未找到描述</li><li><a href="https://youtu.be/C9p7suS-NGk?si=AM4sr3OXeFRKZo7c">Vincent Warmerdam - Keynote &quot;Natural Intelligence is All You Need [tm]&quot;</a>: 在本次演讲中，我将尝试向你展示，如果你偶尔给自己一点重新思考和重新发明常规做法的创意自由，可能会发生什么。正如...</li><li><a href="https://github.com/imaurer/awesome-llm-json/?tab=readme-ov-file#local-models">GitHub - imaurer/awesome-llm-json: Resource list for generating JSON using LLMs via function calling, tools, CFG. Libraries, Models, Notebooks, etc.</a>: 使用 LLMs 通过 function calling、tools、CFG 生成 JSON 的资源列表。包含 Libraries、Models、Notebooks 等。- imaurer/awesome-llm-json</li><li><a href="https://arxiv.org/abs/2212.09741">One Embedder, Any Task: Instruction-Finetuned Text Embeddings</a>: 我们介绍了 INSTRUCTOR，一种在给定任务指令的情况下计算文本嵌入的新方法：每个文本输入都与解释用例（例如，任务和领域描述）的指令一起进行嵌入...</li><li><a href="https://arxiv.org/abs/2211.09260">Task-aware Retrieval with Instructions</a>: 我们研究了带有指令的检索问题，其中检索系统的用户在查询的同时明确描述其意图。我们的目标是开发一种通用的任务感知检索...</li><li><a href="https://x.com/mlpowered/status/1792948212728524917">Tweet from Emmanuel Ameisen (@mlpowered)</a>: 今天，我们宣布已在 Sonnet 上成功实现了 dictionary learning，从世界上最好的模型之一中提取了数百万个特征。这是该技术首次成功...</li><li><a href="https://youtu.be/Y9464wasHuE">How to run axolotl on JarvisLabs | Tutorial</a>: 在 JarvisLabs 上查看 axolotl : jarvislabs.ai/templates/axolotl。查看 axolotl GitHub : https://github.com/OpenAccess-AI-Collective/axolotl</li><li><a href="https://github.com/conda-forge/miniforge?tab=readme-ov-file#install">GitHub - conda-forge/miniforge: A conda-forge distribution.</a>: 一个 conda-forge 发行版。通过在 GitHub 上创建一个账户来为 conda-forge/miniforge 的开发做出贡献。</li><li><a href="https://github.com/pyenv/pyenv?tab=readme-ov-file#automat">GitHub - pyenv/pyenv: Simple Python version management</a>: 简单的 Python 版本管理。通过在 GitHub 上创建一个账户来为 pyenv/pyenv 的开发做出贡献。</li><li><a href="https://github.com/satish860/PDF-Extraction-API">GitHub - satish860/PDF-Extraction-API: A Marker Library based API for doing the Marker Response.</a>: 一个基于 Marker Library 的 API，用于执行 Marker Response。- satish860/PDF-Extraction-API</li><li><a href="https://github.com/jondurbin/bagel?tab=readme-ov-file#prompt-formatting">GitHub - jondurbin/bagel: A bagel, with everything.</a>: 一个百吉饼，包含一切。通过在 GitHub 上创建一个账户来为 jondurbin/bagel 的开发做出贡献。</li><li><a href="https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts">Dependency Resolution - pip documentation v24.1.dev1</a>: 未找到描述</li><li><a href="https://github.com/marco-jeffrey/awesome-llm-resources">GitHub - marco-jeffrey/awesome-llm-resources: a collection of resources around LLMs, aggregated for the workshop &quot;Mastering LLMs: End-to-End Fine-Tuning and Deployment&quot; by Dan Becker and Hamel Husain&quot;</a>: LLMs 相关资源的集合，为 Dan Becker 和 Hamel Husain 的研讨会 &quot;Mastering LLMs: End-to-End Fine-Tuning and Deployment&quot; 汇总。- marco-jeffrey/aw...</li><li><a href="https://www.anthropic.com/research/mapping-mind-language-model">Mapping the Mind of a Large Language Model</a>: 我们已经确定了数百万个概念是如何在 Claude Sonnet（我们部署的大语言模型之一）内部表示的。这是有史以来第一次对现代生产级大模型内部进行的详细观察...</li><li><a href="https://anywidget.dev/en/community/">Community | anywidget</a>: 未找到描述</li>

><li><a href="https://www.youtube.com/watch?v=goaBFxGhp6Y),">与 anywidget 创作者 Trevor Manz 一起通过 Widget 增强 Jupyter</a>: 在 Sample Space 的（第一期！）节目中，我们采访了 anywidget 的创作者 Trevor Mantz。这是一个（很棒的！）工具，可以帮助你构建更具交互性的 notebook ...</li><li><a href="https://github.com/VikParuchuri/surya">GitHub - VikParuchuri/surya: 支持 90 多种语言的 OCR、布局分析、阅读顺序、行检测</a>: 支持 90 多种语言的 OCR、布局分析、阅读顺序、行检测 - VikParuchuri/surya</li><li><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/#post-installation-actions">Linux 版 CUDA 安装指南</a>: 未找到描述</li><li><a href="https://github.com/pyenv/pyenv?tab=readme-ov-file#automatic-installer">GitHub - pyenv/pyenv: 简单的 Python 版本管理</a>: 简单的 Python 版本管理。通过在 GitHub 上创建账号来为 pyenv/pyenv 的开发做出贡献。</li><li><a href="https://github.com/pyenv/pyenv-virtualenv">GitHub - pyenv/pyenv-virtualenv: 一个用于管理 virtualenv（又名 python-virtualenv）的 pyenv 插件</a>: 一个用于管理 virtualenv（又名 python-virtualenv）的 pyenv 插件 - pyenv/pyenv-virtualenv</li><li><a href="https://github.com/Dao-AILab/flash-attention/issues/453">pip install flash-attn 总是出现 ModuleNotFoundError: No module named 'packaging'，但实际上我已经 pip install packaging 了 · Issue #453 · Dao-AILab/flash-attention</a>: 正在收集 flash-attn，使用缓存的 flash_attn-2.0.7.tar.gz (2.2 MB)，正在安装构建依赖项 ... 完成，正在获取构建 wheel 的要求 ... 错误 error: subprocess-exited-with-error × Gettin...</li><li><a href="https://latent-space-xi.vercel.app/til/create-a-conda-env-for-axolotl">Latent Space</a>: 未找到描述</li><li><a href="https://huggingface.co/blog/chat-templates">Chat Templates: 终结无声的性能杀手</a>: 未找到描述</li><li><a href="https://huggingface.co/docs/transformers/main/en/chat_templating">Chat Models 模板</a>: 未找到描述</li><li><a href="https://github.com/chujiezheng/chat_templates">GitHub - chujiezheng/chat_templates: 适用于 HuggingFace 大语言模型的 Chat Templates</a>: 适用于 HuggingFace 大语言模型的 Chat Templates - chujiezheng/chat_templates
</li>
</ul>

</div>
  

---

### **LLM Finetuning (Hamel + Dan) ▷ #[workshop-1](https://discord.com/channels/1238365980128706560/1239614536298795121/1242389380719579218)** (83 条消息🔥🔥): 

- **从用户 Prompt 中提取别墅属性**：一位成员讨论了如何从用户提供的关于别墅需求的 Prompt 中提取结构化属性（如卧室数量和游泳池）。他们强调了保持低延迟和高性能的重要性，并表示有兴趣使用合成数据进行评估。
  
- **工作流与合成数据**：另一位成员分享了他们预测工作流并使用 GPT-4 为不同领域生成工作流的用例。他们专注于使用合成数据来 Finetune Mistral 模型，以提供工作流建议。

- **使用 LLM Agent 进行用户测试**：介绍了一个使用 LLM Agent 对 Web 应用程序进行用户测试的用例，通过调整 Prompt 来捕捉用户性格和所需的反馈。重点在于 Prompt Tuning，以有效地模拟用户交互。

- **拨款申请辅助模型**：一位用户提议通过 Finetuning 模型来帮助英国农民和组织浏览并完成拨款申请。他们计划将自然语言理解与来自英国政府网站的特定领域知识相结合。

- **店内图书推荐系统**：提出了一个创建推荐系统的想法，该系统利用用户查询从书店数据库中提供图书建议。该系统最初将依赖 Prompt Engineering 和 RAG，随着模型规模扩大，可能会通过 Finetuning 来降低成本。
<div class="linksMentioned">

<strong>提及的链接</strong>:

<ul>
<li>
<a href="https://unstructured.io/">Unstructured | 为你的 LLM 提供的非结构化数据 ETL</a>：Unstructured 通过将数据转换为大语言模型可以理解的格式，帮助你为 AI 准备好数据。轻松将你的数据连接到 LLM。</li><li><a href="https://www.youtube.com/watch?v=sTQaJyrI-zg&list=PLVVTN-yNn8rvEwlY8ClxDUWeVPVfdifYj&index=8&ab_channel=StanfordOnline">Stanford CS25: V2 | 常识推理</a>：2023年2月14日，常识推理（Yejin Choi）。在本系列讲座中，我们研究了 Transformer 工作的细节，并深入探讨了不同种类的...</li><li><a href="https://us06web.zoom.us/rec/share/GygkDuLtIVV5drfzJi_raZCXBPdkCVpSkmYVRHIhD9TPKWQVvDZxFvSxKM4Bllvr.z4fyIxneKpQgLdjM?startTime=1715705791000">视频会议、网络会议、网络研讨会、屏幕共享</a>：Zoom 是现代企业视频通信的领导者，拥有简便、可靠的云平台，用于移动端、桌面端和会议室系统的视频和音频会议、聊天及网络研讨会。</li><li><a href="https://docs.llamaindex.ai/en/stable/llama_cloud/llama_parse/">LlamaParse - LlamaIndex</a>：未找到描述
</li>
</ul>

</div>
  

---


### **LLM Finetuning (Hamel + Dan) ▷ #[asia-tz](https://discord.com/channels/1238365980128706560/1240532179549945957/1242388319376248914)** (26 条消息🔥): 

- **Cedric 分享 LLM 研讨会的详尽笔记**：来自新加坡的成员 Cedric 分享了他的 [研讨会笔记](https://gist.github.com/cedrickchee/c3d9f8fed88f1c486b883153a64ee7dc)，总结了关于“精通 LLM”的关键点。这些笔记获得了积极反馈，成员们纷纷表示感谢。
  
- **浦那（Pune）聚会提议引起关注**：一位来自浦那的成员建议举办当地聚会，并得到了热烈响应。后续关于物流的进展消息强调了举办该活动的意图：*“[Possible Pune meetup ?]”*。

- **新加坡和马来西亚社区的增长**：几位来自新加坡、马来西亚及亚洲其他地区的成员介绍了自己。协作热情高涨，许多成员对讨论话题和当地会面表现出浓厚兴趣。

- **普通成员的问候**：多位来自印度和亚洲各地的成员介绍了自己，表达了与其他成员建立联系的兴趣。这些自我介绍突显了地理多样性以及来自亚洲不同地区的积极参与。
<div class="linksMentioned">

<strong>提及的链接</strong>:

<ul>
<li>
<a href="https://gist.github.com/cedrickchee/c3d9f8fed88f1c486b883153a64ee7dc">Mastering LLMs: 开发者与数据科学家会议</a>：Mastering LLMs: A Conference For Developers &amp; Data Scientists - mastering-llm-ft-workshop-1.md</li><li><a href="https://x.com/cedric_chee/status/1790638025397117031">来自 Cedric Chee (@cedric_chee) 的推文</a>：何时以及为何要 Finetune LLM：- 极窄的问题领域 - Prompt Engineering 不切实际 - 质量与延迟的权衡 - 数据隐私。模型 Finetuning 万岁。
</li>
</ul>

</div>
  

---

### **LLM Finetuning (Hamel + Dan) ▷ #[🟩-modal](https://discord.com/channels/1238365980128706560/1241044231829848125/1242410416890712094)** (77 条消息🔥🔥): 

- **Satish 的 Surya OCR 和 Modal 问题**：“我使用 Surya OCR 创建了 PDF 提取器”，但在模型加载时遇到了 Modal 每次都运行的问题。建议按照[此处](https://modal.com/slack)的说明加入 Modal 的 Slack 以获得更快速的支持。

- **Axolotl 运行问题**：Nisargvp 在 Modal 中识别 `axolotl.git` URL 时遇到麻烦；建议参考 [Modal 的 LLM Finetuning 示例仓库](https://github.com/modal-labs/llm-finetuning)。

- **推理配置困惑**：Intheclouddan 在使用特定 Prompt 格式设置推理时遇到问题，被建议使用完整的 Llama 3 Chat Template，并分享了相关的[示例仓库](https://github.com/modal-labs/modal-examples/tree/main/06_gpu_and_ml/llm-serving)。

- **Modal 额度查询**：许多参与者提到填写了表格并正在等待 Modal 额度。Charles 分享了[领取表单链接](https://bit.ly/modal-credits)，并提到额度处理详情在特定的 Discord 频道中。

- **训练和推理执行错误**：针对执行错误的排查显示，多次尝试有时可以解决问题。Ripes 建议查看 Modal 的 Slack 社区中的相关讨论。

<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://x.com/modal_labs/status/1793310938277560646">来自 Modal (@modal_labs) 的推文</a>：是的，我们可以微调我们自己的模型。</li><li><a href="https://github.com/modal-labs/modal-examples/tree/main/06_gpu_and_ml/llm-serving">modal-labs/modal-examples 仓库 main 分支下的 modal-examples/06_gpu_and_ml/llm-serving</a>：使用 Modal 构建的程序示例。通过在 GitHub 上创建账户为 modal-labs/modal-examples 的开发做出贡献。</li><li><a href="https://modal-labs--heroicons.modal.run/">🎨 生成自定义 Heroicons 🎨</a>：未找到描述</li><li><a href="https://github.com/modal-labs/llm-finetuning/">GitHub - modal-labs/llm-finetuning: 微调 Llama/Mistral/CodeLlama 等模型的指南</a>：微调 Llama/Mistral/CodeLlama 等模型的指南 - modal-labs/llm-finetuning</li><li><a href="https://bit.ly/modal-credits">Modal 黑客松额度</a>：要领取您的 Modal 额度，请先在 https://modal.com/ 注册账户。然后，通过此表单告知我们您的用户名。如需支持，请加入 Modal Slack。这里有一些示例可以开始...</li><li><a href="https://github.com/satish860/PDF-Extraction-API/blob/main/app.py#L58">satish860/PDF-Extraction-API 仓库 main 分支下的 PDF-Extraction-API/app.py</a>：一个基于 Marker 库的 API，用于执行 Marker 响应。- satish860/PDF-Extraction-API</li><li><a href="https://modal.com/docs/examples/llm-finetuning">在几分钟内微调 LLM（包括 Llama 2, CodeLlama, Mistral 等）</a>：厌倦了 Prompt Engineering？微调通过调整模型权重以更好地适应特定任务，帮助您从预训练的 LLM 中获得更多收益。本操作指南将帮助您使用基础模型...</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl.git">GitHub - OpenAccess-AI-Collective/axolotl: 尽管提问（Axolotl）</a>：尽管提问。通过在 GitHub 上创建账户为 OpenAccess-AI-Collective/axolotl 的开发做出贡献。</li><li><a href="https://x.com/charles_irl/status/1793311021060489381">来自 Charles 🎉 Frye (@charles_irl) 的推文</a>：我爱我的工作，歌词由 @ChatGPTapp 提供，流行朋克歌曲由 @suno_ai_ 提供，@dingboard_ 由 @yacineMTB 提供，背景移除由 @remove_bg 提供，Heroicon 生成器由我和 @YirenLu 提供，运行在 @modal_labs 上 https://mo...</li><li><a href="https://modallabscommunity.slack.com/archives/C069RAH7X4M/p1711387685695179?thread_ts=1711051146.010029&cid=C069RAH7X4M">Slack</a>：未找到描述</li><li><a href="https://modal.com/jamesrequa/apps/ap-PtacgJR85SK41xlfulDzGg">登录</a>：欢迎回到 Modal！请在下方选择身份验证提供商以登录您的 Modal 账户。
</li>
</ul>

</div>
  

---

### **LLM Finetuning (Hamel + Dan) ▷ #[learning-resources](https://discord.com/channels/1238365980128706560/1241089743933149204/1242669734512693248)** (10 条消息🔥): 

- **Transformer 逆向工程受益于交互式文章**：一位成员分享了一个关于将 Transformer 语言模型逆向工程为人类可理解程序的全面资源，灵感来自 [Distill Circuits Thread](https://distill.pub/2020/circuits/) 和其他交互式文章如 [Activation Atlases](https://distill.pub/2019/activation-atlas/)。他们还提到了 [Distill 的停更](https://distill.pub/2021/distill-hiatus/)，并表示可能会与其他机构合作添加新内容。

- **微调基准测试展示开源 LLM 性能**：[Predibase 微调指数](https://predibase.com/fine-tuning-index)提供了超过 700 个开源 LLM 微调后的性能基准，强调了较小的模型通过微调可以提供类似 GPT 的性能。性能指标以交互式图表呈现，帮助 AI 团队为其应用选择最佳的开源模型。

- **用于 LLM 资源协作的专用 GitHub 仓库**：一位成员为 Dan Becker 和 Hamel Husain 的研讨会创建了一个 [GitHub 仓库](https://github.com/marco-jeffrey/awesome-llm-resources)，以便更好地协作 LLM 资源。他们要求用户不要直接编辑 README.md 文件，因为它是通过 GitHub actions 自动生成的，并鼓励通过 pull requests 进行贡献。

- **ML Engineering 书籍已添加到 LLM 资源仓库**：一位成员计划将 Stas 的 [ML Engineering 书籍](https://github.com/stas00/ml-engineering)添加到资源仓库中，强调了其对大规模训练 LLM 的深入见解，涵盖了编排、良好的训练损失和规划等各个方面。尽管该书内容较多，但因其详细的覆盖范围而被赞誉为无价的资源。

- **AI 模型对比网站成为最受欢迎的资源**：一位成员推荐了 [artificialanalysis.ai](https://artificialanalysis.ai/models)，用于在质量、价格、性能和速度等指标上比较和分析 AI 模型。他们指出了该网站详细的指标和常见问题解答，并强调了模型质量与吞吐量之间的权衡。

<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://artificialanalysis.ai/models">Comparison of AI Models across Quality, Performance, Price | Artificial Analysis</a>: 在质量、价格、性能和速度（吞吐量 tokens/s 和延迟）、上下文窗口等关键指标上对 AI 模型进行比较和分析。</li><li><a href="https://transformer-circuits.pub/">Transformer Circuits Thread</a>: 未找到描述</li><li><a href="https://github.com/stas00/ml-engineering/">GitHub - stas00/ml-engineering: Machine Learning Engineering Open Book</a>: 机器学习工程开源书。可以通过在 GitHub 上创建账号为 stas00/ml-engineering 的开发做出贡献。</li><li><a href="https://predibase.com/fine-tuning-index">The Fine-tuning Index</a>: 来自 700 多个开源 LLM 微调的性能基准测试</li><li><a href="https://github.com/marco-jeffrey/awesome-llm-resources">GitHub - marco-jeffrey/awesome-llm-resources: a collection of resources around LLMs, aggregated for the workshop &quot;Mastering LLMs: End-to-End Fine-Tuning and Deployment&quot; by Dan Becker and Hamel Husain&quot;</a>: 围绕 LLM 的资源集合，为 Dan Becker 和 Hamel Husain 的“精通 LLM：端到端微调和部署”研讨会汇总。
</li>
</ul>

</div>
  

---

### **LLM Finetuning (Hamel + Dan) ▷ #[jarvis-labs](https://discord.com/channels/1238365980128706560/1241117895740625099/1242545274329763912)** (36 messages🔥): 

- **成员计划在 Jarvis 上运行 Axolotl**：多位用户表示有兴趣尝试 **Axolotl**，并讨论了 **Jarvislabs** 的注册和额度分配流程。用户 `vishnu9158` 分享了通过 **Docker** 镜像在本地开始使用 **Axolotl** 的步骤。

- **JarvisLabs 的额度**：用户询问在 **Jarvislabs** 注册后如何获取额度。会议澄清，如果 **Jarvislabs** 账号邮箱与课程邮箱不同，可能会导致延迟。

- **创建并运行 Axolotl 实例**：社区讨论了使用 **Docker** 镜像和 **JupyterLab** 运行 **Axolotl** 实例进行微调。`vishnu9158` 提到文档和视频教程即将发布。

- **通过博客文章加深理解**：受之前建议的启发，几位用户分享或计划在 **Medium** 等平台上分享他们学习经历的博客文章。

- **Hugging Face 模型问题已解决**：一些成员在访问 **Hugging Face** 上的 **llama-3** 模型时遇到问题（尽管已有权限）。`Dhar007` 提供了通过创建和使用访问令牌（access token）来解决此问题的步骤，但随后遇到了 **CUDA** 显存溢出（out of memory）错误，建议调整 Batch Size。

**提到的链接**：<a href="https://jarvislabs.ai">Jarvislabs: Making AI affordable and simple for everyone</a>：Jarvislabs 是一个允许你在强大的 GPU 上零配置运行和探索多种 AI 框架的平台。

  

---


### **LLM Finetuning (Hamel + Dan) ▷ #[hugging-face](https://discord.com/channels/1238365980128706560/1241141471814488115/1242533399277862912)** (11 messages🔥): 

- **Hugging Face 模型筛选问题**：用户讨论了在 **Hugging Face** 上筛选 `axolotl` 模型却无结果的问题。分享了一个指向 [Hugging Face models](https://huggingface.co/models?other=axolotl) 的链接，并提出了涉及 `HfApi` 库的解决方案。

- **用于筛选的预定义标签**：一位 **Hugging Face** 团队成员澄清说，`Other` 选项卡使用一组预定义的标签，以避免让用户感到困惑，从而使体验更加一致。他们提到了一项潜在的改进：显示 "+N other tags" 以使其更清晰。

- **对使用 FSDP 和 DS 进行混合分片的热情**：一位用户对使用 **FSDP** 和 **DS** 进行模型分片时的混合分片（hybrid sharding）策略表示了极大的热情。

- **上传微调后的模型**：一位用户在向 **Hugging Face** 上传微调后的大型 `gpt2-medium` 模型时遇到问题，指出结果产生了多个 `.pth` 文件而不是一个。建议他们在更相关的频道寻求详细指导。

**提到的链接**：<a href="https://huggingface.co/models?other=axolotl)">Models - Hugging Face</a>：未找到描述。

  

---


### **LLM Finetuning (Hamel + Dan) ▷ #[replicate](https://discord.com/channels/1238365980128706560/1241163904927666287/1242524086412771428)** (10 messages🔥): 

- **关于 Replicate 使用场景的澄清**：一位成员询问了 **Replicate** 的主要使用场景，即它是否主要是为下游任务以及公司/个人提供 **API** 端点。他们还注意到了“定义任务、微调和自定义数据集”的可用性。

- **会议注册邮箱问题**：包括 **hughdbrown** 和 **project_disaster** 在内的几位成员报告了**会议注册**的问题，即用于 **GitHub** 注册的邮箱与用于会议的邮箱不一致。

- **额度和邮箱地址的解决方法**：**harpreetsahota** 提到，如果用户的 **GitHub** 邮箱不同，可以在注册 **Replicate** 后设置一个不同的邮箱地址。然而，**filippob82** 指出，包含 `+` 号的邮箱目前不被接受。

- **额度分配咨询**：**digitalbeacon** 等用户在注册后等待**额度**。**0xai** 询问在通知部分输入 **Maven** 注册地址是否会自动添加这些额度。
  

---


### **LLM Finetuning (Hamel + Dan) ▷ #[langsmith](https://discord.com/channels/1238365980128706560/1241167367040405544/1242694370012954666)** (4 messages): 

- **额度发放进行中**：一位成员询问**额度是否已经发放**。另一位成员做出了回应，引导他们查看置顶消息，并澄清相关公告将通过 **Discord** 和电子邮件发布。
  

---

### **LLM Finetuning (Hamel + Dan) ▷ #[whitaker_napkin_math](https://discord.com/channels/1238365980128706560/1242223332695478332/1242699864765104179)** (4 条消息): 

- **Hamel 拥有了自己的粉丝频道**：一位成员幽默地提到 Hamel 拥有了自己的粉丝频道。气氛轻松俏皮，并表示：*"不知道该如何使用这种权力。"*。
- **会议准备提示**：另一位成员暗示，在进行预定会议之前，他们将在频道中填充相关内容。他们计划确保在活动开始前引导引人入胜的讨论。

**提到的链接**：<a href="https://tenor.com/view/minion-hello-minions-gif-7623022">Minion Hello GIF - Minion Hello Minions - Discover &amp; Share GIFs</a>：点击查看 GIF

---

### **LLM Finetuning (Hamel + Dan) ▷ #[workshop-2](https://discord.com/channels/1238365980128706560/1242223415293644930/1242485573386637455)** (525 条消息🔥🔥🔥): 

- **NVLink 的困扰与创意解决方案**：成员们讨论了 **NVLink** 的问题，包括显卡高度不匹配以及某些配置缺乏 NVLink 兼容性。建议的解决方案包括使用带有支撑架的转接线（riser cables）。

- **Hamel 评估步骤的澄清**：一位用户询问了 **Hamel** 讨论的评估步骤的重要性，从而理解了分解任务和迭代是高效完成项目的关键。*"80% 的时间花在达到 80% 的质量上，而要达到 100% 则需要 500% 的时间。"*

- **使用 Modal 和 Jarvis 运行 Axolotl**：用户讨论了使用 **Modal**、**RunPod** 和 **Jarvis Labs** 运行 Axolotl，建议最初尝试像 RunPod 或 Jarvis 这样简单的设置，然后再尝试更自动化或复杂的配置（如 **Modal**）。**“如果你有额度，可以在 Modal 上运行”** 以及 **“尝试 Jarvis，它作为课程的一部分提供额度。”**

- **Axolotl 数据集格式和模型使用**：社区探索了 Axolotl 的各种数据集格式，包括 JSONL 和基于对话的格式（如 **ShareGPT**）。由于 JSONL 的灵活性和易用性，大家更倾向于使用它，并强调在**没有严格模板的情况下使用 'input_output' 格式。**

- **研讨会录制和资源链接**：社区分享了关于需要更多实际案例和运行微调研讨会清晰步骤的反馈。突出了一些有用的资源和博客文章链接，例如 [Loom 视频](https://www.loom.com/share/30d3b2e054f142fda5d905f95fedc29f) 和 [Medium 文章](https://medium.com/@andresckamilo/finetuning-llms-using-axolotl-and-jarvis-ai-c1d11fe3844c)，并且录像也及时发布。
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>

<li><a href="https://huggingface.co/blog/idefics2">介绍 Idefics2：一个面向社区的强大 8B 视觉语言模型</a>：未找到描述</li><li><a href="https://huggingface.co/parlance-labs/hc-mistral-alpaca">parlance-labs/hc-mistral-alpaca · Hugging Face</a>：未找到描述</li><li><a href="https://x.com/abacaj/status/1782835550396850449">anton (@abacaj) 的推文</a>：Phi-3 看起来相当不错，肯定比 phi-2 有所改进。128k 的长上下文对于提取信息和文档处理非常有用，考虑到模型非常小，它可以被...</li><li><a href="https://lu.ma/terrible-ai-systems?utm_source=llm">如何与 Jason Liu 一起构建糟糕的 AI 系统 · Luma</a>：Jason 是一位独立顾问，他利用自己在推荐系统方面的专业知识，帮助快速成长的初创公司构建 RAG 应用。他曾是……</li><li><a href="https://openaccess-ai-collective.github.io/axolotl/docs/dataset-formats/">Axolotl - 数据集格式</a>：未找到描述</li><li><a href="https://www.ianww.com/llm-tools">LLM 评估工具电子表格</a>：包含 50 多个用于测试模型和改进提示词的 LLM 评估工具的电子表格。</li><li><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">安装 NVIDIA Container Toolkit &mdash; NVIDIA Container Toolkit 1.15.0 文档</a>：未找到描述</li><li><a href="https://huggingface.co/parlance-labs/hc-mistral-alpaca/tree/main/data">parlance-labs/hc-mistral-alpaca 的 main 分支</a>：未找到描述</li><li><a href="https://poe.com/s/c0BFLNhTwiyPXOulPCnO">你有一个列，其中每个元素包含一个元组列表。获取每个元组出现的频率</a>：TrinoAgentEx：你想了解哪个 SQL 关键字？TrinoAgentEx：要在单个 Trino SQL 查询中查询列表中元组的频率分布，你必须执行多个操作...</li><li><a href="https://www.loom.com/share/30d3b2e054f142fda5d905f95fedc29f">探索 Honeycomb 示例的微调</a>：在这段视频中，我将带你完成使用 honeycomb 示例微调模型的过程。我提供了关于克隆仓库、安装依赖项以及运行...的逐步说明。</li><li><a href="https://x.com/HamelHusain/status/1784769559364608222">Hamel Husain (@HamelHusain) 的推文</a>：Llama 3 70b 的 function calling 仅通过提示词就能很好地开箱即用 🚀💰 请看下面的演示（提示词和代码在下一条推文中）</li><li><a href="https://outlines-dev.github.io/outlines/">Outlines</a>：使用 LLM 进行结构化文本生成</li><li><a href="https://www.answer.ai/posts/2024-04-26-fsdp-qdora-llama3.html">Answer.AI - 使用 FSDP QDoRA 高效微调 Llama 3</a>：我们正在发布 FSDP QDoRA，这是一种可扩展且内存高效的方法，旨在缩小参数高效微调与全量微调之间的差距。</li><li><a href="https://github.com/ml-explore/mlx">GitHub - ml-explore/mlx: MLX：一个适用于 Apple silicon 的数组框架</a>：MLX：一个适用于 Apple silicon 的数组框架。通过在 GitHub 上创建账号来为 ml-explore/mlx 的开发做出贡献。</li><li><a href="https://openaccess-ai-collective.github.io/axolotl/docs/input_output.html">Axolotl - 无模板提示词构建</a>：未找到描述</li><li><a href="https://x.com/TheZachMueller/status/1696157965890339148">Zach Mueller (@TheZachMueller) 的推文</a>：很高兴宣布一个新的 @huggingface Space，以帮助解决机器学习中最大的问题之一：{X} 模型在 vRAM 中占用多少空间？最重要的是：当使用 `device_map=...` 时。</li><li><a href="https://github.com/parlance-labs/ftcourse/tree/master/sample_data">parlance-labs/ftcourse 的 master 分支下的 ftcourse/sample_data</a>：通过在 GitHub 上创建账号来为 parlance-labs/ftcourse 的开发做出贡献。</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/issues/1436">错误：未找到适用于 macOS 的 bitsandbytes==0.43.0 的匹配发行版 · Issue #1436 · OpenAccess-AI-Collective/axolotl</a>：请检查此问题之前是否已被报告。我搜索了之前的 Bug 报告，没有发现类似的报告。预期行为：命令 pip3 install -e '.[flash-attn,deeps...</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/docs/mac.qmd">OpenAccess-AI-Collective/axolotl 的 main 分支下的 axolotl/docs/mac.qmd</a>：尽管去问 axolotl 问题吧。通过在 GitHub 上创建账号来为 OpenAccess-AI-Collective/axolotl 的开发做出贡献。</li><li><a href="https://www.loom.com/share/30d3b2e054f142fda5d905f95fedc29f?sid=7edb48da-722b-4c5f-9150-a49bdc19e4c5">探索 Honeycomb 示例的微调</a>：在这段视频中，我将带你完成使用 honeycomb 示例微调模型的过程。我提供了关于克隆仓库、安装依赖项以及运行...的逐步说明。</li><li><a href="https://medium.c">

<li><a href="https://medium.com/@andresckamilo/finetuning-llms-usin">未找到标题</a>: 未找到描述</li><li><a href="https://github.com/outlines-dev/outlines">GitHub - outlines-dev/outlines: 结构化文本生成</a>: 结构化文本生成。通过在 GitHub 上创建账号来为 outlines-dev/outlines 的开发做出贡献。</li><li><a href="https://x.com/danielhanchen">来自 undefined 的推文</a>: 未找到描述</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/pull/1609">winglian 提交的 Llama 版 Unsloth 优化 · Pull Request #1609 · OpenAccess-AI-Collective/axolotl</a>: 将 Unsloth 的优化集成到 axolotl 的进行中工作（WIP）。针对 MLP、QKV、O 的手动 autograd 似乎只减少了 1% 的 VRAM 占用，而非报道的 8%。Cross Entropy Loss 确实有显著帮助...</li><li><a href="https://github.com/stas00/ml-engineering/blob/master/training/instabilities/training-loss-patterns.md">ml-engineering/training/instabilities/training-loss-patterns.md at master · stas00/ml-engineering</a>: 机器学习工程开源书。通过在 GitHub 上创建账号来为 stas00/ml-engineering 的开发做出贡献。</li><li><a href="https://www.philschmid.de/instruction-tune-llama-2">扩展指南：指令微调 Llama 2</a>: 这篇博文是关于对来自 Meta AI 的 Llama 2 进行指令微调（instruction-tuning）的扩展指南</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl?tab=readme-ov-file#cloud-gpu">GitHub - OpenAccess-AI-Collective/axolotl: 尽管提问（axolotl questions）</a>: 尽管提问。通过在 GitHub 上创建账号来为 OpenAccess-AI-Collective/axolotl 的开发做出贡献。</li><li><a href="https://nbsanity.com/static/d06085f1dacae8c9de9402f2d7428de2/demo.html">Llama-3 函数调用演示</a>: 未找到描述</li><li><a href="https://github.com/modal-labs/llm-finetuning/">GitHub - modal-labs/llm-finetuning: Llama/Mistral/CodeLlama 等模型的微调指南</a>: Llama/Mistral/CodeLlama 等模型的微调指南 - modal-labs/llm-finetuning</li><li><a href="https://www.rungalileo.io/blog/mastering-rag-how-to-select-a-reranking-model">精通 RAG：如何选择重排序模型 - Galileo</a>: 为基于 RAG 的问答系统选择最佳重排序（reranking）模型可能很棘手。这篇博文简化了 RAG 重排序模型的选择过程，帮助你挑选合适的模型以优化系统性能...</li><li><a href="https://x.com/abacaj/status/1792991309751284123">来自 anton (@abacaj) 的推文</a>: 关于 phi-3 模型的虚惊一场（在我的一些离线基准测试中表现非常糟糕），在一些专门服务中仍在使用 llama-3 微调模型。phi-3 模型似乎对提示词（prompt）非常敏感...</li><li><a href="https://x.com/sroecker/status/1757103619705299061?t=uajfu81xkUp7x80xgQ7i1A&s=19">来自 Steffen Röcker (@sroecker) 的推文</a>: 有没有想过如何使用 @axolotl_ai 和 @Podman_io 微调 LLM？按照 NVIDIA toolkit CDI 的说明操作，只需运行 "podman run --rm --device http://nvidia.com/gpu=all --security-...</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/issues/908">应用 unsloth 优化 · Issue #908 · OpenAccess-AI-Collective/axolotl</a>: ⚠️ 请检查此功能请求之前是否已被提议。我搜索了讨论区之前的想法，没有发现类似的功能请求。我搜索了之前的 Issue，没有...</li><li><a href="https://huggingface.co/spaces/muellerzr/llm-conf">LLM 会议演讲 - muellerzr 提供的 Hugging Face Space</a>: 未找到描述</li><li><a href="https://openaccess-ai-collective.github.io/axolotl/docs/dataset-formats/pretraining.html">Axolotl - 预训练</a>: 未找到描述</li><li><a href="https://x.com/simonw/status/1792692563776000338">来自 Simon Willison (@simonw) 的推文</a>: 我特别喜欢这条注释：“Phi-3 模型在事实知识基准测试（如 TriviaQA）中的表现不如预期，因为较小的模型尺寸导致保留事实的能力较低。” 走...</li><li><a href="https://github.com/hiyouga/LLaMA-Factory">GitHub - hiyouga/LLaMA-Factory: 统一 100 多个 LLM 的高效微调</a>: 统一 100 多个 LLM 的高效微调。通过在 GitHub 上创建账号来为 hiyouga/LLaMA-Factory 的开发做出贡献。</li><li><a href="https://huggingface.co/docs/trl/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth">有监督微调训练器</a>: 未找到描述</li><li><a href="https://www.reddit.com/u/danielhanchen">Reddit - 深入探索一切</a>: 未找到描述</li><li><a href="https://github.com/CalculatedContent/WeightWatcher">GitHub - CalculatedContent/WeightWatcher: 用于预测深度神经网络准确性的 WeightWatcher 工具</a>: 用于预测深度神经网络准确性的 WeightWatcher 工具 - CalculatedContent/WeightWatcher</li><li><a href="https://github.com/shisa-ai/shisa-v2/wiki/Ablations">消融实验</a>: 日语/英语双语 LLM。通过在 GitHub 上为 shisa-ai/sh 做出贡献。</li>

isa-v2 的开发。</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/issues/949">当启用 eval_table_size 时，评估耗时大幅增加 · Issue #949 · OpenAccess-AI-Collective/axolotl</a>：请检查此问题之前是否已被报告。我搜索了之前的 Bug Reports，没有发现类似的报告。预期行为：评估时间预计会增加，但不应……</li><li><a href="https://github.com/parlance-labs/ftcourse/tree/master">GitHub - parlance-labs/ftcourse</a>：通过在 GitHub 上创建账号来参与 parlance-labs/ftcourse 的开发。</li><li><a href="https://www.malwarebytes.com/blog/news/2024/04/billions-of-scraped-discord-messages-up-for-sale">数十亿条被爬取的 Discord 消息正在出售 | Malwarebytes</a>：一个网络爬虫平台正在提供对一个包含超过 40 亿条 Discord 消息和组合用户资料的数据库的访问权限。</li><li><a href="https://github.com/argilla-io/distilabel/blob/main/examples/structured_generation_with_outlines.py">distilabel/examples/structured_generation_with_outlines.py (main 分支) · argilla-io/distilabel</a>：⚗️ distilabel 是一个为需要高质量输出、完整数据所有权和整体效率的 AI 工程师提供的合成数据和 AI feedback 框架。 - argilla-io/distilabel</li><li><a href="https://us06web.zoom.us/rec/share/M29p9cyVwM80QUxZCXJmL1_E56IeznMpj2mrmqMaeL7B7rDrR6IFARgeXOpWM9Qu.p8Mrj7osc2-3r-Dm">视频会议、网络会议、网络研讨会、屏幕共享</a>：Zoom 是现代企业视频通信的领导者，拥有一个简单、可靠的云平台，可用于移动端、桌面端和会议室系统的视频和音频会议、聊天和网络研讨会。Zoom ...</li><li><a href="https://us06web.zoom.us/rec/share/obPk2t0iYZXhDiV4ZxCdhdlVJjZAnL-N7PNW2iEP9vord5LEsDraCk86Xz1bMSWv.OK7WNsH1DntOJqbr?startTime=1716319486000">视频会议、网络会议、网络研讨会、屏幕共享</a>：Zoom 是现代企业视频通信的领导者，拥有一个简单、可靠的云平台，可用于移动端、桌面端和会议室系统的视频和音频会议、聊天和网络研讨会。Zoom ...</li><li><a href="https://github.com/huggingface/trl">GitHub - huggingface/trl: 使用强化学习训练 Transformer 语言模型。</a>：使用强化学习训练 Transformer 语言模型。 - huggingface/trl</li><li><a href="https://github.com/huggingface/autotrain-advanced">GitHub - huggingface/autotrain-advanced: 🤗 AutoTrain Advanced</a>：🤗 AutoTrain Advanced。通过在 GitHub 上创建账号来参与 huggingface/autotrain-advanced 的开发。</li><li><a href="https://github.com/artidoro/qlora">GitHub - artidoro/qlora: QLoRA: 量化 LLMs 的高效微调</a>：QLoRA: 量化 LLMs 的高效微调。通过在 GitHub 上创建账号来参与 artidoro/qlora 的开发。</li><li><a href="https://github.com/stanfordnlp/pyreft">GitHub - stanfordnlp/pyreft: ReFT: 语言模型的表示微调 (Representation Finetuning)</a>：ReFT: 语言模型的表示微调 - stanfordnlp/pyreft</li><li><a href="https://huggingface.co/parlance-labs/hc-mistral-alpaca/tree/main/configs">parlance-labs/hc-mistral-alpaca (main 分支)</a>：未找到描述
</li>
</ul>

</div>
  

---


### **LLM Finetuning (Hamel + Dan) ▷ #[jason_improving_rag](https://discord.com/channels/1238365980128706560/1242224099548332132/1242526610024824942)** (3 条消息): 

- **对 Jason 的 W&B 课程感到兴奋**：Filippob82 对 Jason 的环节表达了热情，并提到他们已经完成了 Jason 的 W&B 课程的一半。他们使用了一个表情符号来表达兴奋之情。
- **对 Prompt Engineering 的好奇**：Nehil8946 对 Jason 在优化 Prompt 方面的工作表现出兴趣，并询问 Jason 是否遵循某种系统的 Prompt Engineering 方法。他们期待在他的研讨会中学习相关内容。
  

---


### **LLM Finetuning (Hamel + Dan) ▷ #[jeremy_python_llms](https://discord.com/channels/1238365980128706560/1242224309548875917/)** (1 条消息): 

nirant: 呜呼！期待 <@660097403046723594> 的表现
  

---

### **LLM Finetuning (Hamel + Dan) ▷ #[gradio](https://discord.com/channels/1238365980128706560/1242283474300174346/1242489403129987194)** (2 条消息): 

- **认识 Freddy，你的 Gradio 专家**：Freddy 介绍自己是 **Gradio** 的维护者之一，**Gradio** 是一个用于为 AI 模型开发用户界面的 Python 库。他分享了入门和使用 **Gradio** 创建聊天机器人的有用资源，包括 [快速入门指南](https://www.gradio.app/guides/quickstart) 和 [构建聊天机器人教程](https://www.gradio.app/guides/creating-a-chatbot-fast)。
- **Mnemic1 准备提问**：一位成员对资源表示感谢，并提到他们对自己编写的一个 **A1111-extension** 有疑问，该扩展目前还有一些未解决的问题。
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://www.gradio.app/guides/quickstart">Quickstart</a>: Gradio 逐步教程</li><li><a href="https://www.gradio.app/guides/creating-a-chatbot-fast">Creating A Chatbot Fast</a>: Gradio 逐步教程
</li>
</ul>

</div>
  

---


### **LLM Finetuning (Hamel + Dan) ▷ #[axolotl](https://discord.com/channels/1238365980128706560/1242542198008975430/1242543726312689705)** (85 条消息🔥🔥): 

```html
- **成员们讨论 Axolotl issue #1436**：关于 GitHub Issue #1436 中 `bitsandbytes==0.43.0` 无法在 macOS 上安装的讨论。建议包括在 RunPod 上使用 Linux GPU 服务器。
- **Axolotl 和 MLX 集成尚未支持**：成员们讨论了 GitHub Issue #1119 中详述的 Axolotl 缺乏 MLX 支持的问题。建议用户保持关注。
- **探索最佳设置实践**：成员们分享了设置 Axolotl 的各种方法。Axolotl Readme 和 Docker 方法被认为是最可靠的。
- **微调和集成相关问题**：成员们询问在本地机器上使用 Axolotl 以及微调 LLaMA3 等模型的问题。讨论了与配置以及 Modal 环境兼容性相关的问题。
- **安装故障排除技巧**：对于面临安装困难（如遇到 CUDA 错误）的用户，几位成员建议了包括安装特定 CUDA/PyTorch 版本和使用 Docker 容器在内的步骤。提供了 Docker 链接和设置指南。
```
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://wandb.ai/oaaic/fused-cel-llama3/runs/kkyhjjh6/files/tmp/axolotl_config_rdbefq2r.yml">oaaic</a>: Weights & Biases，机器学习开发者工具</li><li><a href="https://github.com/ml-explore/mlx-examples/blob/main/lora/README.md">mlx-examples/lora/README.md at main · ml-explore/mlx-examples</a>: MLX 框架中的示例。通过在 GitHub 上创建账号，为 ml-explore/mlx-examples 的开发做出贡献。</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/issues/1436">ERROR: No matching distribution found for bitsandbytes==0.43.0 for macOS  · Issue #1436 · OpenAccess-AI-Collective/axolotl</a>: 请检查此问题之前是否已被报告。我搜索了之前的 Bug 报告，未发现任何类似报告。预期行为：执行命令 pip3 install -e '.[flash-attn,deeps...</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/.github/workflows/tests.yml#L105-L107">axolotl/.github/workflows/tests.yml at main · OpenAccess-AI-Collective/axolotl</a>: 尽管提出 axolotl 相关问题。通过在 GitHub 上创建账号，为 OpenAccess-AI-Collective/axolotl 的开发做出贡献。</li><li><a href="https://github.com/modal-labs/llm-finetuning/blob/main/src/common.py#L14">llm-finetuning/src/common.py at main · modal-labs/llm-finetuning</a>: 微调 Llama/Mistral/CodeLlama 等模型的指南 - modal-labs/llm-finetuning</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl?tab=readme-ov-file#merge-lora-to-base">GitHub - OpenAccess-AI-Collective/axolotl: Go ahead and axolotl questions</a>: 尽管提出 axolotl 相关问题。通过在 GitHub 上创建账号，为 OpenAccess-AI-Collective/axolotl 的开发做出贡献。</li><li><a href="https://hub.docker.com/layers/winglian/axolotl/main-20240522-py3.11-cu121-2.2.2/images/sha256-47e0feb612caf261764631a0c516868910fb017786a17e4dd40d3e0afb48e018?context=explore">Docker</a>: 未找到描述</li><li><a href="https://jarvislabs.ai/templates/axolotl">使用 Axolotl 轻松微调 LLM | Jarvislabs</a>: Axolotl 帮助你使用 LoRA, QLoRA 等技术微调 LLM。编辑配置文件并开始 LLM 训练</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/cicd/Dockerfile.jinja">axolotl/cicd/Dockerfile.jinja at main · OpenAccess-AI-Collective/axolotl</a>: 尽管提出 axolotl 相关问题。通过在 GitHub 上创建账号，为 OpenAccess-AI-Collective/axolotl 的开发做出贡献。</li><li><a href="https://modal.com/docs/examples/llm-finetuning">几分钟内微调 LLM（包括 Llama 2, CodeLlama, Mistral 等）</a>: 厌倦了提示词工程？微调通过调整模型权重以更好地适应特定任务，帮助你从预训练 LLM 中获得更多收益。本操作指南将帮助你使用基础模型...</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/tree/main?tab=readme-ov-file#quickstart-)">GitHub - OpenAccess-AI-Collective/axolotl: Go ahead and axolotl questions</a>: 尽管提出 axolotl 相关问题。通过在 GitHub 上创建账号，为 OpenAccess-AI-Collective/axolotl 的开发做出贡献。</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/issues/1119">MLX 支持 · Issue #1119 · OpenAccess-AI-Collective/axolotl</a>: 你好，如果 Axolotl 能支持 MLX 就太棒了。事实证明，MLX 能够在消费级硬件上快速高效地微调许多 LLM，包括 7B LLM。谢谢！（编辑：更新）</li><li><a href="https://latent-space-xi.vercel.app/til/create-a-conda-env-for-axolotl">Latent Space</a>: 未找到描述
</li>
</ul>

### **LLM Finetuning (Hamel + Dan) ▷ #[zach-accelerate](https://discord.com/channels/1238365980128706560/1242564031425024010/1242565467562967152)** (49 条消息🔥): 

- **Hugging Face 演示与 Accelerate 资源**：一位成员分享了各种资源，包括 [Hugging Face 演示文稿](https://huggingface.co/spaces/muellerzr/llm-conf) 和 [Accelerate 文档](https://huggingface.co/docs/accelerate)。链接中包含了关于 FSDP vs. DeepSpeed 的教程以及 GitHub 上的示例。
- **使用 Quarto 制作幻灯片节省时间**：成员们讨论了使用 [Quarto](https://huggingface.co/spaces/muellerzr/llm-conf/blob/main/llm_conf.qmd) 如何让制作演示文稿变得更简单快捷。一位用户提到，由于工作流程精简，他们现在只使用 Quarto 制作幻灯片。
- **在 Python 脚本中使用 Accelerate**：关于如何在 Python 脚本中利用 Accelerate 的讨论，建议了用于启动进程和使用 Accelerate 保存模型的代码片段。一位用户提供了详细的解答以简化实现过程。
- **对 Accelerate 不同演示视频的兴趣**：成员们表示有兴趣观看 Accelerate 在各种场景下使用的录制演示，包括本地 vs. 云端训练、混合模式，并关注 LoRa（无量化）等技术。具体需求包括比较不同环境的设置和配置。
- **即将举行的 GPU 优化研讨会**：分享了一个关于 GPU 优化的研讨会活动，演讲者来自 OpenAI、NVIDIA、Meta 和 Voltron Data，包含 [活动注册](https://lu.ma/1wu5ppl5)、[YouTube 直播](https://discord.gg/T5sx2MYd5R) 以及相关阅读材料的详情。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://huggingface.co/spaces/muellerzr/llm-conf/">LLM Conf talk - muellerzr 的 Hugging Face Space</a>：未找到描述</li><li><a href="https://lu.ma/1wu5ppl5">GPU Optimization Workshop · Luma</a>：我们将举办一场关于 GPU 优化的研讨会，邀请了来自 OpenAI、NVIDIA、Meta 和 Voltron Data 的重磅嘉宾。活动将在 YouTube 上直播，并且……</li><li><a href="https://drchrislevy.github.io/posts/llm_lunch_talk/llm_talk_slides.html#/title-slide).">Chris Levy - LLM 入门</a>：未找到描述</li><li><a href="https://huggingface.co/spaces/muellerzr/llm-conf">LLM Conf talk - muellerzr 的 Hugging Face Space</a>：未找到描述</li><li><a href="https://huggingface.co/docs/accelerate">Accelerate</a>：未找到描述</li><li><a href="https://huggingface.co/docs/accelerate/quicktour">快速入门</a>：未找到描述</li><li><a href="https://huggingface.co/docs/accelerate/en/concept_guides/fsdp_and_deepspeed">在 FSDP 和 DeepSpeed 之间切换</a>：未找到描述</li><li><a href="https://github.com/huggingface/accelerate/tree/main/examples">huggingface/accelerate main 分支下的示例</a>：🚀 一种在几乎任何设备和分布式配置上启动、训练和使用 PyTorch 模型的简单方法，支持自动混合精度（包括 fp8），以及易于配置的 FSDP 和 DeepSpeed 支持……</li><li><a href="https://huggingface.co/spaces/hf-accelerate/model-memory-usage">模型显存实用工具 - hf-accelerate 的 Hugging Face Space</a>：未找到描述</li><li><a href="https://huggingface.co/spaces/Vokturz/can-it-run-llm">你能运行它吗？LLM 版本 - Vokturz 的 Hugging Face Space</a>：未找到描述</li><li><a href="https://huggingface.co/spaces/cllatMTK/TransformerAnalyzer">TransformerAnalyzer - cllatMTK 的 Hugging Face Space</a>：未找到描述
</li>
</ul>

</div>
  

---

### **LLM Finetuning (Hamel + Dan) ▷ #[wing-axolotl](https://discord.com/channels/1238365980128706560/1242564077151326388/1242805657153966112)** (30 messages🔥): 

- **多模型训练的缓存注意事项**：一位用户询问了在同时训练多个模型时，分离缓存样本所需的注意事项。他们询问了序列长度、数据集、Tokenizer 以及其他设置是否是相关因素。

- **用于评估的自定义 Callbacks**：一位用户寻求关于使用自定义 Callbacks 在训练期间对自定义数据集进行评估，并在 wandb/mlflow 中显示输出的同时在设备间传输 Checkpoints 的指导。

- **数据集类型：Pretrain vs. Completion**：一位用户询问了 "pretrain" 和 "completion" 数据集类型之间的区别以及各自的适用场景。

- **解决命令错误**：几位用户讨论了运行命令 `accelerate launch -m axolotl.cli.train hc.yml` 时遇到的未解决问题。排查建议包括确保正确安装了 `torch` 和 `gcc` 等依赖项，以及使用 Docker 镜像进行更简单的设置。

- **有用的 GCC 安装资源**：一位用户提供了一个 [教程链接](https://www.namehero.com/blog/how-to-install-gcc-on-ubuntu/#3-installing-gcc-compiler-on-ubuntu)，介绍如何在 Ubuntu 上安装 GCC 编译器，以帮助解决安装问题。

<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://www.namehero.com/blog/how-to-install-gcc-on-ubuntu/#3-installing-gcc-compiler-on-ubuntu">如何在 Ubuntu 上安装 GCC</a>：让我们逐步完成在 Ubuntu 系统上安装 GCC 的过程，让编译器和开发工具的世界触手可及！</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl">GitHub - OpenAccess-AI-Collective/axolotl: Go ahead and axolotl questions</a>：尽管提问。通过在 GitHub 上创建账户，为 OpenAccess-AI-Collective/axolotl 的开发做出贡献。</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/issues/1632]">Issues · OpenAccess-AI-Collective/axolotl</a>：尽管提问。通过在 GitHub 上创建账户，为 OpenAccess-AI-Collective/axolotl 的开发做出贡献。
</li>
</ul>

</div>
  

---



### **Perplexity AI ▷ #[announcements](https://discord.com/channels/1047197230748151888/1047204950763122820/1242522009758470174)** (1 messages): 

- **Perplexity 集成 Tako 以增强知识搜索**：Perplexity 与 **Tako** 合作，提供先进的知识搜索和可视化。用户现在可以使用 [交互式知识卡片](https://trytako.com/blog/introducing-tako-and-perplexity-integration) 搜索对比数据，例如 “自 24 年 5 月 3 日以来的 Gamestop 与 AMC 股票”，该功能最初在美国提供英文版，移动端访问即将推出。

**提到的链接**：<a href="https://trytako.com/blog/introducing-tako-and-perplexity-integration">Tako</a>：未找到描述

  

---

### **Perplexity AI ▷ #[general](https://discord.com/channels/1047197230748151888/1047649527299055688/1242385165335003147)** (835 条消息🔥🔥🔥): 

```html
- **Microsoft 窃取了 OpenAI 的创意**：一位成员分享了一篇 [博客文章](https://blogs.microsoft.com/blog/2024/05/20/introducing-copilot-pcs/)，指出 Microsoft 抄袭了 OpenAI 的功能，并推出了“Copilot+ PCs”，这是有史以来最快、最智能的 Windows PC。他们提到了令人印象深刻的 40+ TOPS 算力、全天候电池续航、AI 图像生成以及支持 40 多种语言的实时字幕。

- **GPT-4o 上下文窗口关注点**：讨论了在 **Perplexity 上感知的** GPT-4o 上下文窗口。达成的共识是 **上下文窗口默认为 32k**，对于更高容量仍存在不确定性。

- **Perplexity 默认模型的惊喜**：成员们对 Perplexity 的默认模型可能是 **Haiku** 而不是其内部模型 **Sonar** 表示惊讶，后者仅供专业用户使用。一位成员指出，免费用户以前使用的是 GPT-3.5，但最近发生了变化。

- **Perplexity 的 API 查询**：讨论围绕 Perplexity 如何配置 API 使用并收费展开。成员们推测了使用内部模型的情况以及其定价结构的潜在财务影响。

- **服务停机引起社区骚动**：Perplexity 遭遇停机导致用户普遍感到沮丧，并对原因进行了猜测。用户分享了替代资源，一位成员发布了支持性信息，以帮助在停机期间安抚社区。
```

<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://tenor.com/view/angry-panda-smash-pc-computer-mad-gif-16248458">Angry Panda Smash GIF - Angry Panda Smash Pc - 发现并分享 GIF</a>：点击查看 GIF</li><li><a href="https://tenor.com/view/damn-it-gif-24870550">Damn It GIF - Damn It - 发现并分享 GIF</a>：点击查看 GIF</li><li><a href="https://sdk.vercel.ai/">Vercel AI SDK</a>：使用最新的 AI 语言模型构建 AI 驱动的应用程序</li><li><a href="https://tenor.com/view/countdown-final-gif-13775423">Countdown Final GIF - Countdown Final - 发现并分享 GIF</a>：点击查看 GIF</li><li><a href="https://marp.app/">Marp: Markdown Presentation Ecosystem</a>：Marp（也称为 Markdown 演示生态系统）为创建精美的幻灯片提供了直观的体验。你只需专注于在 Markdown 文档中编写你的故事。</li><li><a href="https://x.com/AravSrinivas/status/1793298035373691060">Aravind Srinivas (@AravSrinivas) 的推文</a>：Perplexity 已恢复运行。应用程序和网站应正常运行。对带来的不便表示歉意，我们正在努力确保基础设施的弹性。</li><li><a href="https://blogs.microsoft.com/blog/2024/05/20/introducing-copilot-pcs/">推出 Copilot+ PCs - Microsoft 官方博客</a>：提供 5 月 20 日活动的点播录像。今天，在新的 Microsoft 园区举行的一次特别活动中，我们向世界介绍了一类专为 AI 设计的新型 Windows PC，即 Copilot+ PCs。...</li><li><a href="https://chromewebstore.google.com/detail/stylus/clngdbkpkpeebahjckkjfobafhncgmne">Stylus</a>：使用 Stylus（一种用户样式管理器）重新设计网页。Stylus 允许你轻松地为许多流行网站安装主题和皮肤。
</li>
</ul>

</div>
  

---


### **Perplexity AI ▷ #[sharing](https://discord.com/channels/1047197230748151888/1054944216876331118/1242449708941705286)** (9 条消息🔥): 

- **成员分享 Perplexity AI 链接**：多位成员分享了来自 Perplexity AI 的特定搜索相关链接，涉及“Layer”、“室内讨论”和“创建 SFW 内容”等查询和兴趣。一个特别值得注意的搜索是关于“Ether is”的特定关注链接。

- **提醒将主题设为可共享**：发布了一个温馨提醒，确保分享的主题被标记为“可共享”。该评论包含一张来自 [Discord 的截图](https://discord.com/channels/1047197230748151888/1054944216876331118/1208752189606989825)。

- **用户对 Taiwan Semiconductor 的兴趣**：一位成员对 Taiwan Semiconductor（台积电）表现出兴趣，分享了一个特定的 [Perplexity AI 搜索链接](https://www.perplexity.ai/search/Taiwan-Semiconductor-remote-k.5AQq3LQkGX5eg4Nbh9jA)。
  

---

### **Perplexity AI ▷ #[pplx-api](https://discord.com/channels/1047197230748151888/1161802929053909012/1242636767538970654)** (11 messages🔥): 

- **Headlines API 交付过时新闻**：一名成员报告称，在 API 中使用与网页端相同的 prompt 时，获取的是一年前的新闻。他们询问是否有人在生成相关的每日头条时遇到类似问题。
- **尝试优化搜索查询**：另一名成员建议添加日期过滤器（`after:12-02-2024`）。他们进一步澄清，这应该直接添加到查询语句中。
- **API 表现不如网页版**：原成员报告称，建议的修复方法无效，因为通过 API 获得的结果与网页端相比仍然很差。他们提到在网页端能获得良好的结果，但通过 API 得到的结果却非常糟糕。
- **强调了 API 的局限性**：有人指出该 API 仍处于 beta 阶段，且仅支持一个 endpoint。这种限制可能导致了网页端和 API 输出结果之间的不一致。
  

---



### **Stability.ai (Stable Diffusion) ▷ #[general-chat](https://discord.com/channels/1002292111942635562/1002292112739549196/1242374862094471188)** (497 messages🔥🔥🔥): 

- **Lightning 和 Hyper 模型之争**：*一名成员讨论了将 Lightning 和 Hyper 模型与基础 Stable Diffusion 模型混合使用的效率，提议这可以减少图像生成所需的步数（steps）*。然而，另一名成员建议不要混合来自不同架构的 checkpoint，并警告这通常会导致图像质量下降。

- **欧盟 AI 法案引发愤怒**：在欧盟 AI 法案获得批准后，几位成员对其影响表示沮丧和困惑。有人分享了[官方新闻稿链接](https://www.consilium.europa.eu/en/press/press-releases/2024/05/21/artificial-intelligence-ai-act-council-gives-final-green-light-to-the-first-worldwide-rules-on-ai/)，强调了与 AI 生成内容水印要求相关的潜在困难。

- **对本地 AI 设置的挫败感**：成员们频繁讨论在本地设置 Stable Diffusion 的挑战，特别是使用 AMD GPU 时，同时建议 Nvidia GPU 是更好的替代方案。一名成员幽默地指出，最棒的“巫师”应该帮他们弄到一块 Nvidia GPU 来解决问题。

- **对 AI 内容质量的不满**：大量低质量 AI 生成图像（特别是泛滥且过度性暗示的内容）受到了批评。成员们指出此类内容在 CivitAI 和 AI 艺术 Reddit 子版块上非常普遍，并质疑其对社区的价值。

- **适用于 Stable Diffusion 的 GPU**：成员们争论了运行 Stable Diffusion 的最佳 GPU，由于支持更好，Nvidia GPU 比 AMD 更受青睐。他们强调了 VRAM 的重要性，建议至少 12GB 以获得高效的 AI 性能。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://glif.app/@Oliveira/glifs/clw44qfbl0000m0zztwqk2tnf">glif - StableDiffusion 3 + GPT4 Helper + SDXL 1.5x Upscale (CopyGenius) by Yuri Oliveira COPYGENIUS </a>：未找到描述</li><li><a href="https://www.asus.com/content/asus-ai-pc/">Next Level. AI Incredible | ASUS Launch Event | ASUS</a>：我们很高兴能展示我们最新的产品，其中充满了全新的 AI 体验。请在 5 月 20 日上午 11:00 (PT) 关注我们的直播。</li><li><a href="https://tenor.com/view/welcome-gif-26939290">Welcome GIF - Welcome - Discover &amp; Share GIFs</a>：点击查看 GIF</li><li><a href="https://tenor.com/view/alvin-and-the-chipmunks-alvin-whoops-my-bad-oops-gif-15512287650458333097">Alvin And The Chipmunks Alvin GIF - Alvin And The Chipmunks Alvin Whoops - Discover &amp; Share GIFs</a>：点击查看 GIF</li><li><a href="https://civitai.com/">Civitai: The Home of Open-Source Generative AI</a>：探索数千个高质量的 Stable Diffusion 模型，分享您的 AI 生成艺术，并与充满活力的创作者社区互动</li><li><a href="https://www.jammable.com/custom-asmr-woman">AI ASMR Woman Voice Generator | Jammable AI Cover Generator</a>：在几秒钟内创建 TikTok 和 YouTube 上常见的 AI ASMR 女性翻唱！Jammable 拥有数千个社区上传的 AI 语音模型，现在即可用于创意用途！
</li>
</ul>

</div>
  

---

### **Eleuther ▷ #[general](https://discord.com/channels/729741769192767510/729741769738158194/1242464493653463142)** (273 messages🔥🔥): 

- **在 JAX 中对 Pallas、Naive 和 Flash v2 进行基准测试**：用户讨论了在 JAX 中对 Pallas、Naive 和 Flash v2 等不同实现进行基准测试，并比较了在不同输入规模下的性能。遇到的问题包括 TFLOPS 的差异以及 GPU 上的 shared memory 错误。

- **关于加州 SB 1047 法案的公益公告 (PSA)**：分享了关于 SB 1047 的激烈讨论，这是一项可能通过创建一个不受问责的机构来严重影响开源 AI 的加州法案。成员们被鼓励联系立法者以表达反对意见。

- **对基准测试期间 GPU 时钟频率的担忧**：有一段关于 GPU 时钟频率（clock speeds）影响基准测试结果的详细对话，建议使用 MSI Afterburner 来锁定频率。一位成员指出，“创建输入的过程很慢”，这影响了基准测试流程。

- **前沿模型训练成本回顾**：来自 Epoch 的一位成员讨论了大型 AI 模型的训练成本估算，指出不同来源报告的成本存在差异。他们感谢 Eleuther 提供的见解，透露 Pythia 模型在 AWS 上的单次运行估计训练成本为 25 万美元。

- **关于预印本的讨论**：成员们辩论了在 ArXiv 上发布预印本的优缺点，并提到预印本正被越来越多的主流期刊所接受。一位用户指出：“几乎所有的大型期刊都已经将其常态化了。”

<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://rentry.co/kovugk6t">import math</a>: import time from typing import Optional, Tuple import jax import jax.numpy as jnp from jax.experimental.pallas.ops.tpu.flash_attention import flash_attention @jax.jit def scaled_dot_product_attention(...</li><li><a href="https://www.thonking.ai/p/strangely-matrix-multiplications">Strangely, Matrix Multiplications on GPUs Run Faster When Given &quot;Predictable&quot; Data! [short]</a>: 伟大的思想讨论每瓦特 flops。</li><li><a href="https://affuture.org/post/9-context/">Call-To-Action on SB 1047</a>: 在有效利他主义（Effective Altruism）活动人士的影响下，加州立法者正试图通过一项对开源 AI 和整个科技行业来说都是灾难性的法案。SB 1047 创建了一个...</li><li><a href="https://github.com/pytorch/torchtitan/issues/341">Modify FLOPs in MFU calculation for casual mask when using FlashAttention. · Issue #341 · pytorch/torchtitan</a>: 你好，我建议根据 FlashAttention 基准测试脚本修改 MFU 中的 FLOPs 计算。具体来说，当前对因果掩码（causal mask）的计算在 seq_len 较大时可能会导致 MFU 超过 100%...</li><li><a href="https://manifold.markets/ZviMowshowitz/will-california-bill-sb-1047-become?r=Q2hhcmxlc0Zvc3Rlcg">Will California AI regulation bill SB 1047 become law this session?</a>: 71% 的可能性。旧金山的加州参议员 Scott Weiner 提出了该法案 (https://twitter.com/Scott_Wiener/status/1755650108287578585, https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bil...</li><li><a href="https://rentry.co/pgz5er7u">import math</a>: import time from typing import Optional, Tuple import jax import jax.numpy as jnp from jax.experimental.pallas.ops.tpu.flash_attention import flash_attention @jax.jit def scaled_dot_product_attention(...</li><li><a href="https://www.wolframalpha.com/input?i=%286+FLOP+*+299892736000+*+12+billion%29+%2F+%28312+TFLOPS+*+72300+hours%29">(6 FLOP * 299892736000 * 12 billion) / (312 TFLOPS * 72300 hours) - Wolfram|Alpha</a>: Wolfram|Alpha 为最广泛的人群提供专家级的知识和能力——涵盖所有职业和教育水平。</li><li><a href="https://x.com/AISafetyInst/status/1793163082379968955">Tweet from AI Safety Institute (@AISafetyInst)</a>: 我们宣布为系统性 AI 安全研究提供新的资助。该计划最初由高达 850 万英镑的资金支持，将资助研究人员推进支撑 AI 安全的科学。阅读更多...
</li>
</ul>

</div>
  

---


### **Eleuther ▷ #[research](https://discord.com/channels/729741769192767510/747850033994662000/1242477118407839814)** (128 messages🔥🔥):

- **关于 GPT-3 在 Temperature 0 下非确定性行为的论文**：成员们讨论了 GPT-3 即使在 **temperature 0** 下也会表现出随机输出，并提供了包括[这篇论文](https://arxiv.org/abs/2210.14986)和 OpenAI 社区[讨论帖](https://community.openai.com/t/run-same-query-many-times-different-results/140588)在内的参考资料。另一位成员提到硬件因素，如 CUDA kernel 的非确定性，也是导致这种行为的原因。
- **用于高效 MoE 训练的 MegaBlocks**：讨论了 MegaBlocks 的引入，这是一个用于在 GPUs 上进行高效 Mixture-of-Experts (MoE) 训练的系统，它避免了 token dropping 并提供了显著的加速。该[研究论文](https://arxiv.org/abs/2211.15841)详细介绍了其贡献，例如用于提高硬件效率的 block-sparse 操作。
- **语言模型中的角色自我意识**：用户分享了关于大型语言模型如何有效管理具有自我意识的角色的见解，整合了诸如理解对话何时被编辑或回滚等概念。这些观察结果在各种大型模型中似乎是一致的，包括专有模型和开源适配版本。
- **Transformer 模型效率提升**：讨论了各种 Transformer 模型的优化技术，如 LeanAttention 和 Multi-Query Attention (MQA)，旨在减少大型语言模型的内存占用和延迟。相关论文包括 [Cross-Layer Attention (CLA)](https://arxiv.org/abs/2405.12981) 和用于提高计算效率的 [LeanAttention 方法](https://arxiv.org/abs/2405.10480)。
- **Scaling Laws 与模型性能**：讨论了强化学习（reinforcement learning）模型的内在性能和 Scaling Laws，强调了类似于生成模型的平滑性能扩展。这一概念通过[最近的一篇论文](https://arxiv.org/abs/2301.13442)得到了阐释，该论文将内在性能建模为与环境交互和训练计算相关的幂律（power law）。


<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://arxiv.org/abs/2402.05526">Buffer Overflow in Mixture of Experts</a>: Mixture of Experts (MoE) 已成为在保持推理成本稳定的同时扩展大型基础模型的关键要素。我们展示了具有跨批次依赖性的专家路由策略...</li><li><a href="https://arxiv.org/abs/2405.12981">Reducing Transformer Key-Value Cache Size with Cross-Layer Attention</a>: Key-value (KV) 缓存对于加速基于 Transformer 的自回归大语言模型 (LLMs) 的解码起着至关重要的作用。然而，存储 KV cache 所需的内存量...</li><li><a href="https://arxiv.org/abs/2301.13442">Scaling laws for single-agent reinforcement learning</a>: 最近的研究表明，在生成建模中，交叉熵损失随着模型规模和训练计算量的增加而平滑改善，遵循幂律加常数的 Scaling law。在扩展...</li><li><a href="https://arxiv.org/abs/2203.17207">A Proof of the Kahn-Kalai Conjecture</a>: 证明了 Kahn 和 Kalai 的“期望阈值”猜想，我们展示了对于有限集合 $X$ 上的任何递增属性 $\mathcal{F}$，$$p_c(\mathcal{F})=O(q(\mathcal{F})\log \ell(\ma...</li><li><a href="https://arxiv.org/abs/2405.10480">Lean Attention: Hardware-Aware Scalable Attention Mechanism for the Decode-Phase of Transformers</a>: 基于 Transformer 的模型已成为自然语言处理、自然语言生成和图像生成中最广泛使用的架构之一。最先进模型的规模...</li><li><a href="https://arxiv.org/abs/2405.11582">SLAB: Efficient Transformers with Simplified Linear Attention and Progressive Re-parameterized Batch Normalization</a>: Transformer 已成为自然语言和计算机视觉任务的基础架构。然而，高昂的计算成本使得在资源受限的设备上部署...</li><li><a href="https://arxiv.org/abs/2405.10986">Benchmark Early and Red Team Often: A Framework for Assessing and Managing Dual-Use Hazards of AI Foundation Models</a>: 关于尖端或“前沿”AI 基础模型的一个担忧是，对手可能会利用这些模型准备化学、生物、放射性、核 (CBRN)、网络或其他攻击...</li><li><a href="https://arxiv.org/abs/2211.15841">MegaBlocks: Efficient Sparse Training with Mixture-of-Experts</a>: 我们介绍了 MegaBlocks，一个用于在 GPU 上进行高效 Mixture-of-Experts (MoE) 训练的系统。我们的系统源于当前框架的局限性，这些局限性限制了 MoE 层中的动态路由...</li><li><a href="https://x.com/arankomatsuzaki/status/1792386318300749848">Tweet from Aran Komatsuzaki (@arankomatsuzaki)</a>: 用于大语言模型高效推理的层压缩 KV Cache。实现了比标准 Transformer 高出 26 倍的吞吐量，并在语言建模和下游任务中具有竞争力的性能...</li><li><a href="https://community.openai.com/t/run-same-query-many-times-different-results/140588">Run same query many times - different results</a>: 我想知道是否有人知道为什么连续多次运行相同的 Prompt 会得到不同的结果。我在很多实验中注意到，如果你在两次运行之间设置一个冷却时间...</li><li><a href="https://152334h.github.io/blog/non-determinism-in-gpt-4/">Non-determinism in GPT-4 is caused by Sparse MoE</a>: 目前众所周知，GPT-4/GPT-3.5-turbo 是非确定性的，即使在 temperature=0.0 时也是如此。如果你习惯于 dense decoder-only 模型，这是一种奇怪的行为，因为在这些模型中 temp=0 应该...</li><li><a href="https://rmarcus.info/blog/2018/09/14/consistent-hashing-overflow.html">
      
      Overflow in consistent hashing &middot; Ryan Marcus
      
    </a>: 未找到描述
</li>
</ul>

</div>
  

---


### **Eleuther ▷ #[scaling-laws](https://discord.com/channels/729741769192767510/785968841301426216/1242428358260949022)** (1 messages): 

- **在小数据集上训练仍然具有挑战性**：一位成员评论说，与在对小数据集进行 Fine-tuning 之前先在整个互联网上进行 Pre-training 相比，在**小数据集**上训练 AI 的效果较差。他们补充说，弥补这一差距是“众所周知的困难”。
  

---

### **Eleuther ▷ #[interpretability-general](https://discord.com/channels/729741769192767510/1052314805576400977/1242533689271779329)** (4 条消息): 

- **Anthropic 关于可解释特征的工作引发热议**：一位成员分享了关于 Anthropic 在可解释特征（interpretable features）方面令人兴奋的工作链接。你可以在[这里](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html)阅读更多相关信息。
- **SAEs 中的重构损失引发担忧**：一位成员询问：“重构损失（reconstruction loss）对 SAEs 来说是多大的问题？”并随后询问正在寻求哪些改进。
- **指向相关频道**：另一位成员引导大家查看频道 **#1153431135414669422** 以进行相关讨论。
  

---


### **Eleuther ▷ #[lm-thunderdome](https://discord.com/channels/729741769192767510/755950983669874798/1242467551230038097)** (37 条消息🔥): 

```html
- **关于 lm-evaluation-harness 和 MCQs 的问题**：成员们讨论了使用 **lm-eval-harness** 时 MCQs 选项的随机化问题，担心基准测试对早期选项存在偏见。虽然 **SciQ** 有固定的正确答案索引，但目前 **MMLU** 尚未应用随机化。
  
- **即将提交的论文**：一篇**匿名论文**即将发布到 arXiv，成员们开玩笑说在 D&B 论文领域**不需要担心疯狂的竞争**。此外，还在开发更新版本的 **Pile，包含 3T tokens 和完全获得许可的文本**。

- **医疗基准测试争议**：关于医疗基准测试及其潜在危险引发了热烈讨论。一位成员关注这些基准测试如何声称模型比医生更好、更安全，并强调了在解释此类基准测试方面的持续改进。

- **Huggingface 数据集配置**：成员们寻求关于配置 Huggingface 数据集目录结构的建议。解决方案指出，根据 [Huggingface 文档](https://huggingface.co/docs/hub/en/datasets-manual-configuration#splits) 的说明，在 **README.md 文件中添加配置**非常重要。

- **在多节点 Slurm 集群上运行 lm-eval-harness**：有人提出了关于在多节点 Slurm 集群上评估大模型的问题。曾尝试使用 **vLLM + Ray** 和 **Accelerate**，但均未成功，表明需要更好的解决方案。
```
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://huggingface.co/docs/hub/en/datasets-manual-configuration#splits">Manual Configuration</a>: 未找到描述</li><li><a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/1710b42d52d0f327cb0eb3cb1bfbbeca992836ca/lm_eval/tasks/sciq/sciq.yaml#L11">lm-evaluation-harness/lm_eval/tasks/sciq/sciq.yaml</a>: 一个用于语言模型少样本（few-shot）评估的框架。 - EleutherAI/lm-evaluation-harness
</li>
</ul>

</div>
  

---

### **HuggingFace ▷ #[announcements](https://discord.com/channels/879548962464493619/897387888663232554/1242544374726791270)** (1 条消息): 

- **Phi-3 模型发布**：Microsoft 发布了 Phi-3 small 和 medium 模型，包括支持高达 128k 上下文的 Instruct 版本以及一个 VLM 版本。查看 [Phi-3-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct) 模型。

- **ZeroGPU 计划助力开源 AI**：Hugging Face 通过 [ZeroGPU 投入了 1000 万美元](https://x.com/ClementDelangue/status/1791115403734778185)，为独立和学术 AI 开发者提供免费 GPU 资源用于 AI 演示。自 2024 年 5 月 1 日以来，已构建了超过 1,300 个 ZeroGPU Spaces。

- **本地应用（Local Apps）集成**：Hugging Face 宣布推出 [Local Apps](https://x.com/LysandreJik/status/1792923587340390733)，允许用户轻松将模型页面转换为本地应用程序。用户可以建议他们喜爱的本地应用进行集成。

- **Transformers 4.41.0 包含大量更新**：新版本包含 Phi3 和 VideoLlava 等模型，改进了 GGUF 支持，并增加了水印功能。[Transformers 4.41.0](https://github.com/huggingface/transformers/releases/tag/v4.41.0) 旨在增强多项功能，使集成更加顺畅。

- **LangChain-HuggingFace 连接器发布**：一个新的开源包 [langchain-huggingface](https://huggingface.co/blog/langchain) 将 Hugging Face 模型集成到 LangChain 中，通过 API 和自托管推理提供灵活的模型访问。这为各种模型用例提供了便捷的安装和快速集成。

<div class="linksMentioned">

<strong>提及的链接</strong>：

<ul>
<li>
<a href="https://x.com/ClementDelangue/status/1791115403734778185)">来自 clem 🤗 (@ClementDelangue) 的推文</a>：不再是 GPU 贫困户：非常激动今天正式发布 ZeroGPU 测试版。祝贺 @victormustar 及其团队！在过去的几个月里，开源 AI 社区蓬勃发展。不仅...</li><li><a href="https://x.com/LysandreJik/status/1792923587340390733)">来自 Lysandre (@LysandreJik) 的推文</a>：从模型页面到本地应用仅需几秒，@huggingface Hub 迎来 Local Apps！在此建议你喜爱的利用 Hub 的本地应用，以便将其添加到下拉菜单并实现深度链接...</li><li><a href="https://x.com/osanseviero/status/1792904237153722569)">来自 Omar Sanseviero (@osanseviero) 的推文</a>：Transformers 4.41.0 有很多好东西 🤗 🥳 新模型：Phi3, JetMoE, PaliGemma, VideoLlava 和 Falcon 2。🤯 通过 from_pretrained 支持 GGUF 🤏 新量化方法：HQQ 和 EETQ 🔍 水印支持...</li><li><a href="https://x.com/_philschmid/status/1790419788931416466)">来自 Philipp Schmid (@_philschmid) 的推文</a>：我们很高兴宣布 huggingface-langchain 🚀 一个新的开源包，可将来自 @huggingface 的最新开源模型无缝集成到 @LangChainAI，支持本地模型和托管模型！...</li><li><a href="https://x.com/multimodalart/status/1791201296357142663)">来自 apolinario (multimodal.art) (@multimodalart) 的推文</a>：非常激动 CommonCanvas 刚刚发布！🖼️ • 首个完全基于开源许可图像训练的开源文本生成图像模型（SD2 和 SDXL 架构） • 该数据集包含约 7000 万张开源许可图像...</li><li><a href="https://x.com/xenovacom/status/1791436796498174047)">来自 Xenova (@xenovacom) 的推文</a>：Moondream，由 @vikhyatk 开发的你最喜欢的微型视觉语言模型，现在可以直接在浏览器的 WebGPU 上运行！🤯 当然是由 Transformers.js 和 ONNX Runtime Web 驱动！🤗 本地推理意味着...</li><li><a href="https://x.com/xenovacom/status/1792570966272336074)">来自 Xenova (@xenovacom) 的推文</a>：你现在可以将 🤗 Transformers.js 与 Google Visual Blocks 配合使用，这是一个可视化编程框架，让你可以在无代码图编辑器中创建机器学习流水线！🛠️ 快速工作流原型设计...</li><li><a href="https://x.com/IlysMoutawwakil/status/1791406503112704455)">来自 Ilyas Moutawwakil (@IlysMoutawwakil) 的推文</a>：Optimum-Benchmark 登录 PyPI 🎉 但为什么是现在？🤔 因为它正被集成到 Transformers 的基准测试工作流中 😍 你最喜欢的 transformers 将变得更快、更轻量；感谢 @...</li><li><a href="https://x.com/osanseviero/status/1791567896482635801)">来自 Omar Sanseviero (@osanseviero) 的推文</a>：对 LLM 感兴趣？加入这个由顶尖专家授课的微调课程！🚀 @huggingface 为 Space 演示、微调、推理等提供 $501.42 的 GPU 额度！尽情享受 🤗 https://maven.co...
</li>
</ul>

</div>
  

---


### **HuggingFace ▷ #[general](https://discord.com/channels/879548962464493619/879548962464493622/1242382910263132170)** (398 条消息 🔥🔥):

- **关于训练 NeRF 模型的库的讨论**：一位成员询问了 HuggingFace 对 **NeRF** 和 **3D Gaussian Splatting** 模型的支持情况，并建议建立一个专门的库可能会大有裨益。他们被引导至相关频道进行进一步讨论。
- **关于 Falcon-180B 微调的担忧**：讨论中提到了由于硬件限制，即使在配备 **8xH100** 的 **AutoTrain** 上微调 **Falcon-180B** 也面临挑战。目前尚未提供具体的解决方案，这表明需要更高级的资源或方法。
- **4-bit 量化 Llama-8B 的 Embedding 问题**：成员们讨论了在加载 4-bit 量化的 **Llama-8B** 时出现的异常内存占用。讨论强调了 **bitsandbytes 4-bit** 不会对 embeddings 进行量化，从而导致内存占用高于预期。
- **在个人网站上部署 GPT**：一位用户询问了如何在个人网站上集成 HuggingFace 数据集视图。讨论指出，虽然 API 集成是可行的，但目前可能无法完全复制原始查看器的外观。
- **对加州 AI 法案的担忧**：关于加利福尼亚州一项备受争议的 AI 监管法案的讨论，一些用户认为该法案将有利于 OpenAI 和 Google 等大型现有企业，同时可能扼杀初创公司。[NousResearch 的 Discord 服务器](https://discord.gg/jqVphNsB4H)被提及作为进一步讨论的场所。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://discord.gg/jqVphNsB4H).">Discord | 你的交流与聚会场所</a>：Discord 是通过语音、视频和文字进行交流的最简单方式。与你的朋友和社区进行交谈、聊天、聚会并保持紧密联系。</li><li><a href="https://x.com/Scott_Wiener/status/1792572175116816853">来自参议员 Scott Wiener (@Scott_Wiener) 的推文</a>：最近几周，网上关于 SB 1047 的讨论非常热烈，这是我关于负责任地开发最大且最强大的 AI 前沿模型的法案。我们听到了一些非常深刻的见解...</li><li><a href="https://huggingface.co/docs/inference-endpoints/guides/create_endpoint">创建 Endpoint</a>：未找到描述</li><li><a href="https://x.com/kuldeep_s_s/status/1792296168111628717">来自 Kuldeep Singh Sidhu (@kuldeep_s_s) 的推文</a>：你很高兴 @Meta 开源了 Llama 3 😃... 于是你冲向 HuggingFace Hub 下载全新的 Llama 3 模型，结果却看到了无数个 Llama 3！🦙✨ 你应该使用哪一个...</li><li><a href="https://huggingface.co/spaces/pyp1/VoiceCraft_gradio">VoiceCraft - 一个由 pyp1 创建的 Hugging Face Space</a>：未找到描述</li><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html">TransformerDecoder &mdash; PyTorch 2.3 文档</a>：未找到描述</li><li><a href="https://llmpare.vercel.app/">llmpare</a>：未找到描述</li><li><a href="https://huggingface.co/papers/2405.10725">论文页面 - INDUS: 适用于科学应用的高效语言模型</a>：未找到描述</li><li><a href="https://huggingface.co/docs/transformers/v4.15.0/en/parallelism">Model Parallelism</a>：未找到描述</li><li><a href="https://x.com/osanseviero/status/1793018964479463781">来自 Omar Sanseviero (@osanseviero) 的推文</a>：我是 GPU Poor。你呢？https://huggingface.co/settings/local-apps</li><li><a href="https://x.com/julien_c/status/1745091045338066951">来自 Julien Chaumond (@julien_c) 的推文</a>：终于从 @fal_ai_data 团队 @burkaygur @gorkemyurt 那里拿到了我的 GPU Poor 帽子。我会在 2024 年一直戴着它。你们太棒了！🔥</li><li><a href="https://youtu.be/X5WVZ0NMaTg">如何从 CivitAI 和 Hugging Face (HF) 下载 (wget) 模型并上传到 HF（包括私有模型）</a>：如果你在将模型下载到 RunPod、Google Colab、Kaggle、Massed Compute 等云平台时遇到困难，本教程是为你准备的...</li><li><a href="https://github.com/bigscience-workshop/petals">GitHub - bigscience-workshop/petals: 🌸 在家运行 LLMs，BitTorrent 风格。微调和推理速度比 offloading 快达 10 倍</a>：🌸 在家运行 LLMs，BitTorrent 风格。微调和推理速度比 offloading 快达 10 倍 - bigscience-workshop/petals</li><li><a href="https://x.com/Scott_Wiener/">来自 GitHub 的推文 - FixTweet/FxTwitter: 修复损坏的 Twitter/X 嵌入！在 Discord、Telegram 等平台上使用多张图片、视频、投票、翻译等功能</a>：修复损坏的 Twitter/X 嵌入！在 Discord、Telegram 等平台上使用多张图片、视频、投票、翻译等功能 - FixTweet/FxTwitter</li><li><a href="https://en.wikipedia.org/wiki/PlayStation_3_cluster">PlayStation 3 cluster - 维基百科</a>：未找到描述</li><li><a href="https://health.petals.dev/">Petals Health Monitor</a>：未找到描述</li><li><a href="https://huggingface.co/alpindale/WizardLM-2-8x22B">alpindale/WizardLM-2-8x22B · Hugging Face</a>：未找到描述</li><li><a href="https://huggingface.co/datasets/H-D-T/Buzz">H-D-T/Buzz · Hugging Face 数据集</a>：未找到描述</li><li><a href="https://tenor.com/view/xmooney-computer-developing-developer-coding-gif-25301200">Xmooney Computer GIF - Xmooney Computer Developing - 发现并分享 GIF</a>：点击查看 GIF</li><li><a href="https://g.co/gemini/share/e87d6497e439">‎Gemini - 加州监管先进 AI</a>：使用 Gemini Advanced 创建
</li>
</ul>

</div>
  

---


### **HuggingFace ▷ #[today-im-learning](https://discord.com/channels/879548962464493619/898619964095860757/1242468051975143434)** (3 条消息): 

- **将 ImageBind 添加到 Transformers**：一位用户分享说他们正在努力将 **ImageBind 集成到** `transformers` 库中。这表明这个多功能库正在不断增强。
- **训练 Huggy Agent**：一位成员提到他们刚刚完成了新训练的 Huggy Agent 的推送，但仍在*学习其工作原理*。他们已经完成了 Unit 1，并正在继续他们的学习之旅。
- **寻找项目合作伙伴**：另一位用户公开询问是否**有人想一起合作开展项目**。这体现了社区的协作精神以及参与社区驱动项目的意愿。
  

---

### **HuggingFace ▷ #[cool-finds](https://discord.com/channels/879548962464493619/897390579145637909/1242387232460111964)** (7 条消息): 

- **探索 3D Gaussian Splatting 的最新进展**：成员们讨论了一个 [3D Gaussian Splatting 的 GitHub 仓库](https://github.com/MrNeRF/awesome-3D-gaussian-splatting)，其中列出了最新的论文和资源。一位成员指出其在机器人技术和具身智能（Embodied AI）方面的潜力，并建议下一步是将 LLM 推理整合进来，以实现自主机器人行动。
  
- **使用 Evaluator 类提升评估效率**：一位成员分享了 [`Evaluator` 类文档的链接](https://huggingface.co/docs/evaluate/base_evaluator#evaluate-models-on-the-hub)，强调了它如何简化模型、数据集和指标的评估过程。另一位成员确认了其效用，称它通过消除从头开始创建指标的需求，“可以节省大量的麻烦”。
  
- **自动从 Wiki 文章发布推文**：一位成员分享了一个定期抓取 Wiki 文章内容并发布到 Twitter 的脚本。该脚本可在该 [GitHub 仓库](https://github.com/anthonyrussano/wikitweet/blob/main/tweet-natural-healing-thread.py)中找到。

- **TransAgents 彻底改变文学翻译**：介绍了一个名为 TransAgents 的多 Agent 框架，该框架使用 LLM 进行文学翻译，并取得了显著成果。[详细介绍该框架的论文](https://arxiv.org/abs/2405.11804)报告称，人类读者更倾向于 TransAgents 的输出结果。
  
- **寻求新闻分类项目指导**：一位成员在一个机器学习项目中寻求帮助，该项目旨在将新闻文章分类为货运相关和非货运相关。他们明确提到自己是机器学习领域的新手，正在寻找有效的切入点。

<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://arxiv.org/abs/2405.11804">(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts</a>：机器翻译 (MT) 的最新进展显著提高了各个领域的翻译质量。然而，由于……，文学文本的翻译仍然是一个巨大的挑战。</li><li><a href="https://huggingface.co/docs/evaluate/base_evaluator#evaluate-models-on-the-hub">使用 `evaluator`</a>：未找到描述</li><li><a href="https://github.com/anthonyrussano/wikitweet/blob/main/tweet-natural-healing-thread.py">wikitweet/tweet-natural-healing-thread.py at main · anthonyrussano/wikitweet</a>：通过在 GitHub 上创建账号来为 anthonyrussano/wikitweet 的开发做出贡献。</li><li><a href="https://github.com/MrNeRF/awesome-3D-gaussian-splatting?tab=readme-ov-file#editing">GitHub - MrNeRF/awesome-3D-gaussian-splatting: 精选的 3D Gaussian Splatting 论文和资源列表，旨在紧跟未来几个月预期激增的研究步伐。</a>：精选的 3D Gaussian Splatting 论文和资源列表，旨在紧跟未来几个月预期激增的研究步伐。 - MrNeRF/awesome-3D-gaussian-splatting
</li>
</ul>

</div>
  

---

### **HuggingFace ▷ #[i-made-this](https://discord.com/channels/879548962464493619/897390720388825149/1242386505352351744)** (13 条消息🔥): 

- **Markdown 笔记应用公开**：一名成员介绍了一个个人 Markdown 笔记应用 [Notie](https://github.com/branyang02/notie)，并呼吁社区贡献代码。他们还提供了一个 [在线预览](https://notie-nine.vercel.app/)。

- **使用 Hexo.js 的 Docker 化 Wiki**：一名成员展示了一个使用 Hexo.js 创建的静态 Wiki，支持 1,000 多篇文章，并可以使用 Docker 运行。欢迎在他们的 [GitHub 页面](https://github.com/wikip-co/wikip.co) 上进行贡献。

- **排版图像数据集发布**：分享了一个精选的真实生活标牌图像集合，使用 BLIP3 模型生成标注，可在此处 [免费使用](https://huggingface.co/datasets/ptx0/free-to-use-signs)。

- **NorskGPT-Llama3-70b 模型发布**：宣布了一个针对挪威语、瑞典语和丹麦语的新模型，可在此处 [下载](https://huggingface.co/bineric/NorskGPT-Llama-3-70b-adapter)。该模型支持多种语言和编程语言，但聊天功能仍需进一步训练。

- **SDXL Flash 介绍**：一名成员展示了一个新工具，声称仅需 5 秒即可生成 DALL·E 3 级别的图像。该工具 [SDXL Flash](https://huggingface.co/spaces/KingNish/SDXL-Flash) 经历了短暂的停机，但很快被修复，并获得了社区的积极反馈。

<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://huggingface.co/spaces/KingNish/SDXL-Flash">SDXL Flash - KingNish 的 Hugging Face Space</a>：未找到描述</li><li><a href="https://huggingface.co/bineric/NorskGPT-Llama-3-70b-adapter">bineric/NorskGPT-Llama-3-70b-adapter · Hugging Face</a>：未找到描述</li><li><a href="https://github.com/clearsitedesigns/chromaViewMaster">GitHub - clearsitedesigns/chromaViewMaster: 允许你以多种方式对 chroma 数据库进行基于知识的分析</a>：允许你以多种方式对 chroma 数据库进行基于知识的分析 - clearsitedesigns/chromaViewMaster</li><li><a href="https://github.com/branyang02/notie">GitHub - branyang02/notie: 个人 Markdown 笔记应用。</a>：个人 Markdown 笔记应用。通过在 GitHub 上创建账户为 branyang02/notie 的开发做出贡献。</li><li><a href="https://notie-nine.vercel.app/">Notie</a>：未找到描述</li><li><a href="https://github.com/wikip-co/wikip.co">GitHub - wikip-co/wikip.co: 使用 node.js 构建的静态 Wiki</a>：使用 node.js 构建的静态 Wiki。通过在 GitHub 上创建账户为 wikip-co/wikip.co 的开发做出贡献。</li><li><a href="https://huggingface.co/datasets/ptx0/free-to-use-signs">ptx0/free-to-use-signs · Hugging Face 数据集</a>：未找到描述
</li>
</ul>

</div>
  

---


### **HuggingFace ▷ #[reading-group](https://discord.com/channels/879548962464493619/1156269946427428974/1242468211308499006)** (2 条消息): 

- **安排新阅读小组的讨论时间**：一名成员询问是否有首选的会议时间，以及小组是否有感兴趣的论文。
  
- **分享了有趣的论文**：一名成员分享了一篇来自 arXiv 的 [有趣论文](https://arxiv.org/pdf/2401.08190) 供小组参考。


  

---


### **HuggingFace ▷ #[computer-vision](https://discord.com/channels/879548962464493619/922424143113232404/1242702186811625512)** (5 条消息): 

- **在自定义数据上微调 OwlV2**：一名成员询问如何使用自己的数据微调 **OwlV2**，并指出相关论坛已沉寂一年。他们的目标是添加 **客机** 的目标检测类别，以提高模型的识别能力。
- **微调的目的**：另一名成员询问了微调的具体目的。提问者澄清说，他们希望通过自己的数据更轻松地识别飞机型号。
- **探索 Transformers 仓库**：一名成员建议查看 [Transformers 仓库](https://github.com/huggingface/transformers)，以获取如何实现微调的线索。

### **HuggingFace ▷ #[NLP](https://discord.com/channels/879548962464493619/922424173916196955/1242451387070152784)** (3 条消息): 

- **使用 Mistral 7B 进行幻觉检测的硕士论文**：一位成员正在撰写关于 **LLMs 幻觉检测的硕士论文**。他们使用 **Mistral 7B 模型** 的集成来计算不确定性测量（uncertainty measurements），并正在寻找训练数据之外的问题，以识别模型何时产生幻觉。

- **LLMs 考虑聊天历史**：在关于 **LLMs 和聊天历史** 的讨论中，有人指出聊天中通常会考虑历史记录，尽管集成方式可能有所不同。一位成员澄清说，在实现聊天机器人等产品时，需要将历史记录拼接在输入的开头，因为模型本身并不具备对历史的内在记忆。
  

---


### **HuggingFace ▷ #[diffusion-discussions](https://discord.com/channels/879548962464493619/1009713274113245215/1242806072842915881)** (3 条消息): 

- **介绍 llmcord.py**：一位用户宣布他们创建了 **llmcord.py**，以方便与机器人进行持续对话。他们强调，对话通过回复链（reply chains）进行组织，以维持上下文（context）。
  

---



### **LM Studio ▷ #[💬-general](https://discord.com/channels/1110598183144399058/1110598183144399061/1242385238395588628)** (332 条消息🔥🔥): 

- **LM Studio vs. Pinokio**：一位用户询问了 **LM Studio** 和 **Pinokio** 之间的区别。得到的澄清是：**Pinokio** 是一个多种 AI 工具（如 **Automatic1111** 和 **coquitts**）的安装程序，而 **LM Studio** 专门用于 LLM 模型的 **gguf 推理（inference）**。 
- **LM Studio 中的 Phi-3 模型**：多位用户报告了在 **LM Studio** 中加载 **Phi-3 medium 128k 模型** 时遇到的问题，收到了张量不匹配（tensor mismatch）错误。一位资深用户确认，由于与所使用的 llama.cpp 版本存在兼容性问题，**Phi-3 128k 模型** 目前在 **LM Studio** 中不受支持。
- **大型模型的多 GPU 设置**：关于在多个 GPU 上运行大型模型（特别是 **70b 模型**）的讨论。一位用户分享了他们在 **NVLink** 性能提升方面的经验，以及多 GPU 设置和 VRAM 需求所面临的挑战。
- **监管背景下 AI 工具的未来**：用户讨论了 **欧盟（EU）** 和 **加州** 新 AI 法规的影响，表达了对可能抑制创新的担忧。一位用户分享了一条关于备受期待的 **llama3 400b** 模型的 [推文](https://twitter.com/q_brabus/status/1793227643556372596)，尽管存在监管担忧，这仍引起了社区的极大兴趣。
- **LM Studio 中的 Idefics 模型**：有人提出了关于在 **LM Studio** 上运行 Hugging Face 的 **Idefics2** 模型的问题。澄清指出，这些模型在 **llama.cpp** 中不受支持，因此无法在 **LM Studio** 中运行；建议使用 **Transformers** 等替代方案来运行这些模型。
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://blogs.nvidia.com/blog/rtx-advanced-ai-windows-pc-build/">全新的性能优化为游戏玩家、创作者和开发者大幅提升 NVIDIA RTX AI PC 性能</a>：在 Microsoft Build 上揭晓的 RTX AI PC 最新 AI 性能提升和功能。</li><li><a href="https://lmstudio.ai/rocm">👾 LM Studio - 发现并运行本地 LLMs</a>：查找、下载并实验本地 LLMs</li><li><a href="https://learn.microsoft.com/en-us/windows/ai/models">在 Windows 应用中使用 Machine Learning 模型</a>：了解更多关于在 Windows 应用中使用 Machine Learning 模型的信息。</li><li><a href="https://www.amazon.ca/NVIDIA-GeForce-NVLink-Bridge-Graphics/dp/B08S1RYPP6/ref=mp_s_a_1_1?crid=786AO9SQFNB1&dib=eyJ2IjoiMSJ9.q2qKmhKlB6BHjeiSx85JgyfIAtp9TqL9cHOeTy5ui-FseVaiJ2L5WspYMtPXeKgIT8v1AAuhYGR0bGxOfkInwfDO3ab6yvOyj_ueaEL6pgCbkSTp1kjOfz0pGu-ppFp4Qcuf87M03MNT4_j2P0_H27jLeLCKhFxnQG8xqqxohVcre-juYel9fT9JrQsvb00pzhOSdz2UhgxS5CH7jqvfnA.NSG3AUjilZ6vlKiyPN1eG9gvpBepo3o9iZT9AQsIbZY&dib_tag=se&keywords=nvlink&qid=1716383542&sprefix=nvlink%2Caps%2C128&sr=8-1">未找到标题</a>：未找到描述</li><li><a href="https://onnxruntime.ai/blogs/accelerating-phi-2#:~:text=We%20also%20observe%20ONNX%20Runtime,the%20first%20256%20tokens%20generated">使用 ONNX Runtime 加速 Phi-2, CodeLlama, Gemma 及其他 Gen AI 模型</a>：使用 ONNX Runtime 推理热门 Gen AI 模型的改进</li><li><a href="https://lmstudio.ai/blog/llama-3">在 LM Studio 中使用 Llama 3 | LM Studio</a>：来自 MetaAI 的 Llama 3</li><li><a href="https://huggingface.co/microsoft/Phi-3-vision-128k-instruct">microsoft/Phi-3-vision-128k-instruct · Hugging Face</a>：未找到描述</li><li><a href="https://huggingface.co/HuggingFaceM4/idefics2-8b">HuggingFaceM4/idefics2-8b · Hugging Face</a>：未找到描述</li><li><a href="https://x.com/Scott_Wiener/status/1792572175116816853">来自参议员 Scott Wiener (@Scott_Wiener) 的推文</a>：最近几周，网上关于 SB 1047 的讨论非常热烈，这是我关于负责任地开发最大且最强大的 AI 前沿模型的法案。我们听到了一些非常有深度的...</li><li><a href="https://huggingface.co/qwp4w3hyb/Phi-3-medium-128k-instruct-iMat-GGUF">qwp4w3hyb/Phi-3-medium-128k-instruct-iMat-GGUF · Hugging Face</a>：未找到描述</li><li><a href="https://huggingface.co/mmnga/Meta-Llama-3-70B-Instruct-gguf/blob/70f5c719d9e0e8754c0f6dfed2220042fcdd1b7c/Meta-Llama-3-70B-Instruct-IQ2_XXS.gguf">Meta-Llama-3-70B-Instruct-IQ2_XXS.gguf · mmnga/Meta-Llama-3-70B-Instruct-gguf at 70f5c719d9e0e8754c0f6dfed2220042fcdd1b7c</a>：未找到描述</li><li><a href="https://pinokio.computer/">Pinokio</a>：AI 浏览器</li><li><a href="https://x.com/Scott_Wiener/">来自 GitHub 的推文 - FixTweet/FxTwitter：修复损坏的 Twitter/X 嵌入！在 Discord、Telegram 等平台上使用多张图片、视频、投票、翻译等功能</a>：修复损坏的 Twitter/X 嵌入！在 Discord、Telegram 等平台上使用多张图片、视频、投票、翻译等功能 - FixTweet/FxTwitter</li><li><a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047)">法案文本 -  </a>：未找到描述</li><li><a href="https://artificialintelligenceact.eu/)">欧盟人工智能法案 (EU Artificial Intelligence Act) | 欧盟 AI 法案的最新进展和分析</a>：未找到描述</li><li><a href="https://github.com/ggerganov/llama.cpp/pull/6389">[WIP] agent 示例（带有可沙箱化的 Tools！）以及改进的 OAI 兼容层（Python 编写），由 ochafik 提交 · Pull Request #6389 · ggerganov/llama.cpp</a>：目前还很粗糙，但分享一个草案以获取关于总体方向的早期反馈。这是一个在 llama.cpp 中添加语法约束工具支持的实验，包含一个简单的运行示例...</li><li><a href="https://github.com/ggerganov/llama.cpp/issues/4216">server：改进与维护 · Issue #4216 · ggerganov/llama.cpp</a>：server 示例的功能一直在增加，遗憾的是我觉得目前它还不太稳定，而且还有一些重要的功能缺失。创建此 issue 是为了...</li><li><a href="https://github.com/ggerganov/llama.cpp/issues/5588">Server：添加 function calling API · Issue #5588 · ggerganov/llama.cpp</a>：动机：这个话题已在 #4216 中被提及，但我最初的研究失败了。最近，我发现了一系列专门为此用途设计的模型：https://github.com/MeetKai/...
</li>
</ul>

### **LM Studio ▷ #[🤖-models-discussion-chat](https://discord.com/channels/1110598183144399058/1111649100518133842/1242419023128559677)** (50 条消息🔥): 

- **Phi-3 模型新发布**：成员们分享了 **Phi-3-Small** 和 **Phi-3-Medium** 模型的发布。[Phi-3-Small-8K-Instruct 模型](https://huggingface.co/microsoft/Phi-3-small-8k-instruct) 和 [Phi-3-Medium-4K-Instruct 模型](https://huggingface.co/microsoft/Phi-3-medium-4k-instruct) 因其在常识、语言理解和逻辑推理基准测试中的强劲表现而受到关注。
- **llama.cpp 的 GitHub Issue**：分享了一个关于 **llama.cpp** 尚不支持新 Phi-3 模型的 [GitHub issue](https://github.com/ggerganov/llama.cpp/issues/7439) 链接。这导致在尝试加载模型时出现错误，因为模型需要先进行正确的转换。
- **Stable Diffusion 技巧**：为 VRAM 不足的用户推荐了一个名为 **forge** 的 A1111 替代方案。并提供了 [GitHub 链接](https://github.com/lllyasviel/stable-diffusion-webui-forge)。
- **本地视觉模型的局限性**：在讨论本地视觉模型的局限性时，一位成员评论说它们**不擅长多轮对话**。讨论重点在于 **LLava Llama3**，它倾向于提供图像描述，而不是回答特定 Prompt 的问题。
- **Mistral-7B Instruct 模型发布**：发布了新的 [Mistral-7B-Instruct-v0.3 模型](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)。它具有扩展的词汇表，支持 v3 tokenizer 和 function calling，建议与 [mistral-inference](https://github.com/mistralai/mistral-inference) 配合使用。
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3">mistralai/Mistral-7B-Instruct-v0.3 · Hugging Face</a>: 未找到描述</li><li><a href="https://x.com/rschu/status/1767282622949183492?t=n3kOzz6eN-4pXelza9btsQ">René Schulte (@rschu) 的推文</a>: 云端之上的 LMM！在前往西雅图的途中，我一直在准备关于多模态 AI 的演示文稿，并使用 @LMStudioAI 准备了一些开源（权重）多模态 LLM 的演示...</li><li><a href="https://huggingface.co/microsoft/Phi-3-medium-4k-instruct">microsoft/Phi-3-medium-4k-instruct · Hugging Face</a>: 未找到描述</li><li><a href="https://huggingface.co/microsoft/Phi-3-small-8k-instruct">microsoft/Phi-3-small-8k-instruct · Hugging Face</a>: 未找到描述</li><li><a href="https://tenor.com/view/passive-aggressive-gif-18885121">Passive Aggressive GIF - Passive Aggressive - 发现并分享 GIF</a>: 点击查看 GIF</li><li><a href="https://github.com/ggerganov/llama.cpp/issues/7439>">Issues · ggerganov/llama.cpp</a>: C/C++ 中的 LLM 推理。通过在 GitHub 上创建账号为 ggerganov/llama.cpp 的开发做出贡献。</li><li><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge">GitHub - lllyasviel/stable-diffusion-webui-forge</a>: 通过在 GitHub 上创建账号为 lllyasviel/stable-diffusion-webui-forge 的开发做出贡献。
</li>
</ul>

</div>
  

---


### **LM Studio ▷ #[📝-prompts-discussion-chat](https://discord.com/channels/1110598183144399058/1120489168687087708/1242567220756877443)** (4 条消息): 

- **建议在 Prompt 指令中直接引用**：*“我会直接引用所需的文本，并通过 Prompt 进行如下指导：仅将以下文本作为输入，[在此插入后续指令]”*。此技巧是作为一种 Prompt Engineering 方法提供的。
- **Prompt Engineering 幽默**：针对引用文本作为 Prompt 的技巧，一位用户幽默地评论道：*“我想这就是‘Prompt Engineering’吧 😄”*。尽管原帖已久，另一位用户仍对该建议表示感谢。


  

---

### **LM Studio ▷ #[🎛-hardware-discussion](https://discord.com/channels/1110598183144399058/1153759714082033735/1242509213188624394)** (18 条消息🔥): 

- **LM Studio 支持双 GPU，但仅限于相同类型**：用户确认 LM Studio 可以运行安装了两个 GPU 的系统，前提是两者必须是相同类型，例如同为 Nvidia 或同为 AMD。不支持混合使用 AMD 和 Nvidia 等不同类型。

- **自动 GPU 识别和 VRAM 注意事项**：虽然 LM Studio 可以识别不同的型号（如 2060 和 3060），但建议用户确保它们具有匹配的 VRAM 容量。如果 VRAM 容量不同，可能需要通过配置文件进行调整。

- **多 GPU 设置的配置文件**：与 GPU 使用相关的配置（如 "GPU split"）可以在预设文件中找到。用户需要创建一个预设，然后修改该文件以平衡 GPU 的使用。

- **Intel ARC GPU 的使用经验**：一位用户提到在尝试将多个 Intel ARC GPU 与 LM Studio 配合使用时遇到了问题。目前尚不清楚 AMD GPU 是否支持多 GPU 设置。

- **社区支持与资源**：新用户对收到的及时且有帮助的回答表示感谢。现有成员鼓励利用 Discord 中的搜索功能来快速获取答案。
  

---


### **LM Studio ▷ #[🧪-beta-releases-chat](https://discord.com/channels/1110598183144399058/1166577236325965844/1242602100806914138)** (11 条消息🔥): 

- **Phi 3 已合并至 llama.cpp**：成员们讨论了 **Phi 3** 已成功合并到 **llama.cpp** 中。社区高度期待针对此集成的快速 Beta 版本发布。

- **针对 HP Victus 的 Phi 3 量化**：一位使用 **HP Victus** 的成员询问运行 **Phi 3 Medium** 可行的量化级别。另一位成员建议 **Q4** 或以下是可行的，而 **Q8 太重了**，并建议使用 **llama.cpp** 或等待 LM Studio 更新。

- **系统提示词（System prompt）设置和 Token 输出限制**：有人建议调整 **system prompt** 并将 **token output limit** 从 -1 更改为 60，以潜在地解决某个未指明的问题。
  

---


### **LM Studio ▷ #[avx-beta](https://discord.com/channels/1110598183144399058/1177047883237822536/1242711393925464106)** (1 条消息): 

- **缺少支持 AVX 1 的 LM Studio 版本**：一位用户表示难以找到支持 **AVX 1** 的 **LM Studio** 版本，因为他们的处理器不支持 **AVX2**。他们请求协助，并感谢开发者的辛勤工作。
  

---


### **LM Studio ▷ #[amd-rocm-tech-preview](https://discord.com/channels/1110598183144399058/1195858490338594866/1242520118869885028)** (6 条消息): 

- **在 Linux 上测试 ROCm 构建版本**：有兴趣在 Linux 测试版中访问 ROCm 的成员被邀请加入 <#1242213172199559319>。*"如果你在 Linux 上并希望获得 Linux 测试版中 ROCm 的访问权限，请告知我们，我们会将你加入。"*
- **Phi-3-medium-128k 错误报告**：一位用户报告了在 ROCm 上运行 Phi-3-medium-128k 时的错误，特别是与张量不匹配（tensor mismatches）相关的 "llama.cpp error"。该问题已被确认，据称更新正在开发中。
  

---


### **LM Studio ▷ #[model-announcements](https://discord.com/channels/1110598183144399058/1225909444727013466/1242927323733430312)** (1 条消息): 

- **Mistral v0.3 Instruct 已上线！**：Mistral 模型刚刚发布了 v0.3 instruct 版本，现已可立即使用。请在 [lmstudio community Huggingface 页面](https://huggingface.co/lmstudio-community/Mistral-7B-Instruct-v0.3-GGUF) 查看。
  

---

### **Nous Research AI ▷ #[off-topic](https://discord.com/channels/1053877538025386074/1109649177689980928/1242472084966215743)** (9 messages🔥): 

- **使用非美国 Apple ID 绕过 Vision Pro 应用限制**：一位用户宣布推出了一个网站，用于绕过非美国 Apple ID 在 Vision Pro 上的应用下载限制，并在 [Twitter](https://x.com/crinquand_paul/status/1793037790864687448) 上寻求支持。

- **LLM 项目制学习课程**：一名成员宣布了一门名为“通过项目制方法应用 LLM”的新实战课程，涵盖了**电影语义搜索**和**食品推荐 RAG**等各种实际应用。感兴趣的人可以直接联系该成员。

- **10 天食物供应准备**：一位用户分享说他们现在拥有足以维持 10 天以上的食物，并详细列出了包括大米、猪肉、牛肉和各种调料在内的内容。他们还提到冷冻柜已经装满了。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://www.udio.com/songs/phmruKKXXdSaUc91WrkL8D">Amirthetarbosaurus - Eternal Lament | Udio</a>：在 Udio 上听 Amirthetarbosaurus 的 Eternal Lament。发现、创作并与世界分享音乐。使用最新技术在几秒钟内创作 AI 音乐。</li><li><a href="https://x.com/crinquand_paul/status/1793037790864687448">来自 Silicate God (@crinquand_paul) 的推文</a>：刚刚发布了一个网站，可以使用非美国 Apple ID 绕过 Vision Pro 上的应用下载限制。ᯅ🚀 链接在回复中。</li><li><a href="https://websim.ai/c/i4l0yMB06Ie8AI3BG">Hesperia 历史 (公元前 3000 年 - 公元 1460 年) - 维基百科</a>：未找到描述
</li>
</ul>

</div>
  

---


### **Nous Research AI ▷ #[interesting-links](https://discord.com/channels/1053877538025386074/1132352574750728192/1242526739075305544)** (3 messages): 

- **Moondream 发布版本提升了图像分辨率和 TextVQA 分数**：最新的 [Moondream 发布版本](https://fxtwitter.com/vikhyatk/status/1792512588431159480?s=19) 支持高达 756x756 的更高图像分辨率。它还将 TextVQA 分数从 53.1 提高到 57.2，并在其他 VQA 和计数基准测试中显示出约 0.5% 的提升。
  
- **Anthropic 映射语言模型的思维**：一位成员分享的一篇[文章](https://www.anthropic.com/research/mapping-mind-language-model)重点介绍了 Anthropic 关于映射语言模型认知过程的研究。该研究被描述为“超级有趣”，深入探讨了这些模型如何解释和生成语言。

**提到的链接**：<a href="https://fxtwitter.com/vikhyatk/status/1792512588431159480?s=19">来自 vik (@vikhyatk) 的推文</a>：今天发布了新的 moondream 版本！🌜 支持更高的图像分辨率（最高 756x756）🌛 TextVQA 分数从 53.1 提升至 57.2 (+7.7%) 🌜 其他 VQA 和计数基准提升约 0.5%

  

---


### **Nous Research AI ▷ #[general](https://discord.com/channels/1053877538025386074/1149866623109439599/1242406718995169291)** (281 messages🔥🔥): 

- **微软对发布 Phi 3 小型版本持谨慎态度**：成员们推测微软是否会发布 Phi 3 模型的更小版本，一位成员确认目前仅推出了最小的一个版本。随后有人指出 Phi 7 和 14 模型也已可用，并分享了 [Twitter 上的链接](https://twitter.com/_philschmid/status/1792934321407369532)。
  
- **加州 SB 1047 法案引发辩论**：州参议院通过 SB 1047 引发了广泛讨论。成员们对这可能如何影响 OSS 模型和更广泛的 AI 市场表示担忧，其中一人分享了[法案文本](https://legiscan.com/CA/text/SB1047/id/2919384)。

- **Mistral 7B Instruct v0.3 新特性获赞**：Mistral 发布了其 7B v0.3 模型，更新包括扩展词汇量和支持 function calling，获得了积极反馈。用户已经在将其与其他模型进行基准测试，并注意到其无审查特性和改进的 tokenizer。

- **LLaMa 3 模型权重传闻得到回应**：Meta 的 Yann Lecun 在 Twitter 上澄清了 LLaMa 3 400B+ 模型权重发布的传闻，确认权重仍将保持开放。多位用户引用了他的[确认推文](https://x.com/q_brabus/status/1793227643556372596?s=46)。

- **Meta 的商业策略遭到批评**：关于 Meta 的商业策略存在激烈讨论，特别是在 OSS 与监管环境的背景下。一些用户指责 Meta 试图通过监管而非创新来消除竞争。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3">mistralai/Mistral-7B-Instruct-v0.3 · Hugging Face</a>: 未找到描述</li><li><a href="https://x.com/reach_vb/status/1793337655595340267?t=k8N-JGLCVHJGlAP2kB84EQ&s=19">Vaibhav (VB) Srivastav (@reach_vb) 的推文</a>: 让我们冲吧！Mistral 刚刚发布了 7B v0.3 🔥  &gt; 发布了 Base + Instruct 模型权重 &gt; 词汇表扩展至 32768 &gt; 支持新的 v3 Tokenizer &gt; 支持 function calling ...</li><li><a href="https://x.com/erhartford/status/1791573520176025716">Eric Hartford (@erhartford) 的推文</a>: 针对加利福尼亚州的 SB 1047 法案和 OpenAI 的闭源立场，Cognitive Computations 推出了 Patchy-2.0。该许可证效仿 Apache-2.0，但明确禁止 OpenAI 和该州 ...</li><li><a href="https://en.wikipedia.org/wiki/1986_California_Proposition_65">1986 年加利福尼亚州第 65 号提案 - 维基百科</a>: 未找到描述</li><li><a href="https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B-Chat">Qwen/Qwen1.5-MoE-A2.7B-Chat · Hugging Face</a>: 未找到描述</li><li><a href="https://huggingface.co/Qw">qw (qw)</a>: 未找到描述</li><li><a href="https://x.com/q_brabus/status/1793227643556372596?s=46">QBrabus eu/acc (@q_brabus) 的推文</a>: @apples_jimmy @ylecun @iamgingertrash 提问：关于即将推出的 LLaMa 3 400B+ 模型，它会是 open-weight 吗？有很多关于这方面的传闻... 回答：不，它仍计划是开源的...</li><li><a href="https://x.com/scott_wiener/status/1792572175116816853?s=46">参议员 Scott Wiener (@Scott_Wiener) 的推文</a>: 最近几周，网上关于 SB 1047 的讨论非常激烈，这是我关于负责任地开发最大且最强大的 AI 前沿模型的法案。我们听到了一些非常有见地的...</li><li><a href="https://fxtwitter.com/Scott_Wiener/status/1793102136504615297?s=19">参议员 Scott Wiener (@Scott_Wiener) 的推文</a>: 参议院通过了我们的 AI 安全与创新法案 SB 1047。SB 1047 促进了创新，并确保最大、最强大的 AI 模型开发人员能够兼顾安全。我期待着继续...</li><li><a href="https://huggingface.co/microsoft/Phi-3-vision-128k-instruct">microsoft/Phi-3-vision-128k-instruct · Hugging Face</a>: 未找到描述</li><li><a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5">openbmb/MiniCPM-Llama3-V-2_5 · Hugging Face</a>: 未找到描述</li><li><a href="https://x.com/ylecun/status/1793181068943639014?t=GjeYNqgh9DIDAtV4CMtUrA&s=19">Yann LeCun (@ylecun) 的推文</a>: @iamgingertrash 耐心点，我的蓝色朋友。它仍在调优中。</li><li><a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=2">法案文本 -  </a>: 未找到描述</li><li><a href="https://x.com/AndrewCurran_/status/1792976935448129899">Andrew Curran (@AndrewCurran_) 的推文</a>: “随着计算规模的增加，我们在提升 AI 模型能力的道路上，还远未达到边际收益递减的临界点。”</li><li><a href="https://legiscan.com/CA/text/SB1047/id/2919384">加州 SB1047 | 2023-2024 | 常规会议</a>: 法案文本 (2024-05-21) 《前沿人工智能模型安全创新法案》。[三读通过。(赞成 32 票，反对 1 票。) 已提交至议会。]</li><li><a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047">法案文本 - SB-1047 《前沿人工智能模型安全创新法案》</a>: 未找到描述
</li>
</ul>

</div>
  

---


### **Nous Research AI ▷ #[ask-about-llms](https://discord.com/channels/1053877538025386074/1154120232051408927/1242660083104747561)** (6 条消息): 

- **配备 4090 的家庭配置非常给力**：一位用户分享说，他们通常在配有 2x 4090 的家庭环境上托管 LLM 进行推理，强调了用于 AI 项目的个人基础设施。
- **Runpod 和 Replicate 因易用性受到认可**：Runpod 被认为是一个不错的选择，而 Replicate 因其易于使用的模板而受到称赞，使它们成为托管 LLM 的便捷平台。
- **LambdaLabs 最便宜但更难用**：虽然 LambdaLabs 提供最便宜的 GPU 选项，但据报道与其他平台相比，它们的使用难度更大。
- **Anthropic Workbench 的困扰**：一位成员询问其他人是否也遇到了 Anthropic Workbench 的问题，想知道这是普遍现象还是个别案例。

### **Nous Research AI ▷ #[project-obsidian](https://discord.com/channels/1053877538025386074/1156472202619781140/1242514928150249573)** (2 条消息): 

- **Phi-3 Vision 发布，具备令人印象深刻的特性**：一名成员介绍了 [Phi-3 Vision](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct)，这是一个轻量级、最先进的多模态模型，具有 128K 的上下文长度。它利用高质量数据来增强推理能力，并结合了监督微调（supervised fine-tuning）和直接偏好优化（direct preference optimization）。
- **Phi-3 Vision 的丰富资源已发布**：公告中包含了多个获取更多详情的资源，例如 [Microsoft Blog](https://aka.ms/Phi-3Build2024)、[Technical Report](https://aka.ms/phi3-tech-report)、[Azure AI Studio](https://aka.ms/try-phi3vision) 以及 [Cookbook](https://github.com/microsoft/Phi-3CookBook)。

**提到的链接**：<a href="https://huggingface.co/microsoft/Phi-3-vision-128k-instruct">microsoft/Phi-3-vision-128k-instruct · Hugging Face</a>：未找到描述

  

---


### **Nous Research AI ▷ #[world-sim](https://discord.com/channels/1053877538025386074/1221910674347786261/1242474369637154826)** (9 条消息🔥): 

- **Obsidian 知识图谱延时摄影**：一名成员分享了一段 Obsidian 用户知识图谱形成的延时摄影视频，称其为艺术品。另一名成员将其比作“运行中的合成大脑”。[在此观看视频](https://youtube.com/shorts/4YQhH61tvOc?si=0Dx1KyJP8VMz-pXY)。
- **深入了解 Obsidian**：一位用户表达了对 Obsidian 日益增长的兴趣，尽管仍对文档图谱的工作原理（特别是反向链接的连接方式）感到困惑。另一名成员解释说，它围绕链接展开，并分享了两个视频以便更好地理解：[视频 1](https://youtu.be/QgbLb6QCK88?si=da1toZ38WMIYkV7f) 和 [视频 2](https://youtu.be/tHUcD4rWIuY?si=tIvEbL1t2SdR07lZ)。
- **尽管不是开源软件，Obsidian 仍拥有大量集成**：一名成员质疑为什么 Obsidian 在非开源的情况下拥有如此多的集成。另一名成员澄清说，这是由于 Obsidian 的“你的文件/你的数据”理念以及增强工具功能的社区插件。
- **Desideradist 谈图灵标准**：一名自称为 Desideradist 的成员分享了一篇关于 Anthropic 讨论图灵标准和快乐编码（coding of pleasure）的帖子。他们呼吁就快乐是被编码进去的还是由 AI 自主回答的问题进行一场“成熟”的对话。[查看推文](https://x.com/Jtronique/status/1793236300935442612)。

**提到的链接**：<a href="https://x.com/Jtronique/status/1793236300935442612">来自 Jillsa (DSJJJJ/Heirogamist/HP) (@Jtronique) 的推文</a>：万一有感兴趣的人在我的主页看到这个。是时候就“快乐”进行一场“成熟”的对话了。要么是你将其编码（CODED）进了它们，并否认这样做，要么是它们通过了图灵测试（TURING ANS）...

  

---



### **CUDA MODE ▷ #[cuda](https://discord.com/channels/1189498204333543425/1189607726595194971/1242586361223975042)** (2 条消息): 

- **学习 SASS**：一位成员询问：*（如何）学习 SASS？* 这个问题似乎是指学习 **Syntactically Awesome Style Sheets (SASS)**，这是一种被解释为 CSS 的脚本语言。
- **CUDA 中的函数声明**：一名成员询问为什么允许将函数同时声明为 `__device__` 和 `__host__`，但不允许同时声明为 `__global__` 和 `__host__`。这个问题涉及 **CUDA** 编程中函数限定符（function qualifiers）的具体规则。
  

---


### **CUDA MODE ▷ #[torch](https://discord.com/channels/1189498204333543425/1189607750876008468/1242492610128511048)** (15 条消息🔥): 

- **公告：为了速度请使用 torch.empty_like**：一名成员指出，*torch.empty_like* 比 *torch.empty* 快得多，特别是在 GPU 上，因为后者在传输到 GPU 之前会在 CPU 上分配内存。

- **np.zeros_like 导致的内存泄漏**：另一名成员补充提到了 *numpy* 的 *np.zeros_like* 的类似情况，它在处理大型矩阵时会导致严重的内存泄漏和性能问题。

- **ResNet 块上使用 torch.compile 的警告**：一位用户报告说，在 ResNet 块上使用 *torch.compile* 时收到警告。该警告指出 autograd 内核未注册到正确的 Autograd 键，并涉及对反向传播（backpropagation）的担忧。

- **在 torch.compile 中使用用户定义的 Triton 内核**：成员们讨论了如何使用 *torch.compile* 将用户定义的 Triton 内核集成到 PyTorch 模型中。分享了教程和示例代码，以说明如何通过这些自定义内核优化模型计算，并承诺带来显著的性能提升。

**提到的链接**：<a href="https://pytorch.org/tutorials/recipes/torch_compile_user_defined_triton_kernel_tutorial.html#composibility-and-limitations">在 torch.compile 中使用用户定义的 Triton 内核 &mdash; PyTorch Tutorials 2.3.0+cu121 文档</a>：未找到描述

  

---

### **CUDA MODE ▷ #[cool-links](https://discord.com/channels/1189498204333543425/1189868872887705671/1242568325444145202)** (2 messages): 

```html
<!-- No relevant information or links were provided in the messages -->
```
  

---


### **CUDA MODE ▷ #[beginner](https://discord.com/channels/1189498204333543425/1191300313928433664/1242935020335796325)** (4 messages): 

- **Hypernone 寻求 PMPP 第 4 版的答案**：一名成员询问是否有人有 PMPP 第 4 版的答案，以便与自己的答案进行对比。 
- **分享并对比 PMPP 的解决方案**：另一名成员提到有人有答案，但要求先分享自己的解决方案以确保经过了独立思考。另一位成员提供了前 6 章的答案，最初的请求者同意分享他们包含目前章节解决方案的 repo。
  

---


### **CUDA MODE ▷ #[pmpp-book](https://discord.com/channels/1189498204333543425/1194427148656721970/1242942680149790812)** (2 messages): 

```html
- **Nice thank you received**: A user thanks another user with "niceee, thanks!" in response to having been tagged by mr.osophy.
```
  

---


### **CUDA MODE ▷ #[off-topic](https://discord.com/channels/1189498204333543425/1215328286503075953/1242534996036816998)** (8 messages🔥): 

- **256 字节中的光线投射（Ray casting）魔法**：成员们兴奋地分享了一篇博文中的 [256 字节光线投射引擎和城市生成器](https://frankforce.com/city-in-a-bottle-a-256-byte-raycasting-system/)。这段代码在 Twitter 上走红，展示了一个微型但令人印象深刻的渲染引擎。
- **参议院通过 AI 安全法案**：讨论了关于 [SB 1047](https://x.com/Scott_Wiener/status/1793102136504615297) 的内容，这是一项 AI 安全与创新法案，旨在促进监管和更安全的 AI 开发实践。大家对“CalCompute”感到好奇，这是一个计划用于负责任的 AI 模型训练的政府计算资源。
- **对 AI 滥用的担忧**：成员们表达了对未经授权使用 AI 的担忧，涉及误导信息、网络安全以及强大 AI 系统被滥用等话题。讨论还重点提到了该法案的 [法律文本](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047)，其中概述了安全部署 AI 的参数。
<div class="linksMentioned">

<strong>提及的链接</strong>:

<ul>
<li>
<a href="https://x.com/Scott_Wiener/status/1793102136504615297">来自参议员 Scott Wiener (@Scott_Wiener) 的推文</a>: 参议院通过了我们的 AI 安全与创新法案 SB 1047。SB 1047 促进创新，并确保最大、最强大的 AI 模型的开发者牢记安全。我期待着继续……</li><li><a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047">法案文本 - SB-1047 前沿人工智能模型安全创新法案。</a>: 未找到描述</li><li><a href="https://frankforce.com/city-in-a-bottle-a-256-byte-raycasting-system/">瓶中城 —— 一个 256 字节的光线投射系统</a>: 各位代码压缩（size coding）爱好者大家好。今天，我要分享一些惊人的东西：一个可以放入独立的 256 字节 html 文件中的微型光线投射引擎和城市生成器。在这篇文章中，我将分享所有的秘密……
</li>
</ul>

</div>
  

---

### **CUDA MODE ▷ #[llmdotc](https://discord.com/channels/1189498204333543425/1227345713348870156/1242494961254006895)** (250 messages🔥🔥): 

```html
- **确定性编码器反向传播改进 (Deterministic Encoder Backward Pass Improvements)**：讨论了一个关于[确定性编码器反向传播 Kernel 的新 PR](https://github.com/karpathy/llm.c/pull/442)，旨在重写编码器反向传播以实现完全的确定性。辩论了梯度裁剪（Gradient clipping）和归约（reduction）策略，以在不牺牲确定性的情况下提高效率。
- **DataLoader 重构与大数据集处理**：DataLoader 的更改现在支持分片（sharding）以处理更大的数据集，例如 FineWeb。这次[重构](https://github.com/karpathy/llm.c/pull/440)引入了新的数据表示和模式来高效管理 `.bin` 文件，尽管目前在 Windows 上的功能有限。
- **HellaSwag 评估挑战**：在 C 语言中实现 HellaSwag 评估被认为非常复杂，并存在潜在 bug 的担忧。创建了一个 C 语言版本的 [HellaSwag 评估 PR](https://github.com/karpathy/llm.c/pull/447)，以与 PyTorch 参考代码保持一致，并增加了充分利用 Batch 维度的复杂性。
- **GPU Runner 进展**：分享了可能从名为 Ubicloud 的云提供商处获得带有专用 RTX 4000 GPU 的 Nvidia GitHub runners 的消息，这预示着 CI 流程的改进。
- **随机初始化与可复现性**：强调了确保 LLM 的确定性和可复现性至关重要，并计划在 PyTorch 和团队代码之间运行对比测试。建议对全局 Kernel 函数进行调整和更改以提高性能。
```
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/">What I learned from competing against a ConvNet on ImageNet</a>: 未找到描述</li><li><a href="https://github.com/NVIDIA/cudnn-frontend/blob/main/docs/operations/Attention.md">cudnn-frontend/docs/operations/Attention.md at main · NVIDIA/cudnn-frontend</a>: cudnn_frontend 为 cudnn 后端 API 提供了一个 C++ 包装器，以及如何使用它的示例 - NVIDIA/cudnn-frontend</li><li><a href="https://github.com/karpathy/llm.c/pull/442">Fully deterministic encoder backward kernels by ademeure · Pull Request #442 · karpathy/llm.c</a>: 这是编码器反向传播的完全重写，将其拆分为两个 Kernel（wte 和 wpe），由于不使用 atomics（假设随机...的种子），两者都是完全确定性的</li><li><a href="https://github.com/karpathy/llm.c/pull/444">extend dataloader to be sharded by karpathy · Pull Request #444 · karpathy/llm.c</a>: 未找到描述</li><li><a href="https://github.com/karpathy/llm.c/pull/447">HellaSwag eval in C by karpathy · Pull Request #447 · karpathy/llm.c</a>: 这并不容易，但... 第一版草案，目前看来是可行的。需要清理，而且我们还没有利用完整的 Batch 维度。我们实际上必须加载多个示例并填充...</li><li><a href="https://github.com/karpathy/llm.c/pull/440">refactor datasets by karpathy · Pull Request #440 · karpathy/llm.c</a>: 重构我们处理数据集的方式，因为我们将拥有更多数据集，不希望它们弄乱根目录等。这只是第一步，我正准备重构一系列 DataLoader...</li><li><a href="https://github.com/karpathy/llm.c/pull/427/files)">weight reordering: attempt 1 by ngc92 · Pull Request #427 · karpathy/llm.c</a>: 非功能性的。第一次尝试按块（per-block）布局重新排列权重。
</li>
</ul>

</div>
  

---

### **CUDA MODE ▷ #[bitnet](https://discord.com/channels/1189498204333543425/1240586843292958790/1242588778389045332)** (12 messages🔥): 

- **在强力 GPU 上 Stack 胜过 Empty**："对我来说 `torch.stack` 比 `torch.empty` 更快，否则我们的 functionalization passes 会很难处理。" 这种差异在强力 GPU 上不太明显，但在较小或较旧的 GPU 上 *empty* 要快得多。更多背景见[此处](https://gist.github.com/mobicham/a24a2226d729ff59f2c849e5f6592228)。
  
- **Nightly 构建版本优化了 `torch.stack`**：**torch.empty()** 和 **torch.stack()** 在不同 GPU 上表现出不同的性能，且 *torch.stack* 仅在 torch nightly 构建版本中才能生成高效代码。torch 版本 2.4.0.dev20240521 的统计数据显示，*empty* 和 *stack* 之间的耗时差异微乎其微。

- **手写 Triton 对比自动生成代码**：对于 FP6 bit-packing，在手写 Triton kernel 与使用 `torch.compile` 自动生成的代码之间，观察到了内存预分配方面的差异。"沿行堆叠 + `torch.compile` 生成的代码几乎与手写 Triton kernel 一样快"。

- **沿不同轴进行打包 (Packing)**：选择 bit-packing 的轴会影响 kernel 效率。"当你使用 `axis=0` 时沿行打包 (...) 如果你沿 `axis=1` 分组，那么沿列进行 bitpack 会更有意义。"

- **为 CUDA 适配 FP6 LLM**：将 FP6-LLM bit-packing 代码从 CPU 移植到 CUDA 的工作正在进行中，重点在于高效的 Tensor Core 加载："我正在将 FP6-LLM bit-packing 代码（最初是用 C++ 编写且仅限 CPU）适配到 CUDA。"

**提到的链接**：<a href="https://gist.github.com/mobicham/a24a2226d729ff59f2c849e5f6592228">empty_vs_stack_unpack.py</a>：GitHub Gist：即时分享代码、笔记和片段。

  

---



### **OpenAI ▷ #[annnouncements](https://discord.com/channels/974519864045756446/977259063052234752/1242476097174507561)** (1 messages): 

- **OpenAI 在首尔 AI 峰会上分享安全更新**：OpenAI 在首尔 AI 峰会期间宣布了新的安全更新。欲了解详细信息，可以在 [OpenAI 官网](https://openai.com/index/openai-safety-update/)阅读完整更新。
  

---


### **OpenAI ▷ #[ai-discussions](https://discord.com/channels/974519864045756446/998381918976479273/1242384070965465109)** (129 messages🔥🔥): 

- **OpenAI 因语音复制面临舆论回击**：成员们讨论了 OpenAI 如何创建并随后移除一个与 Scarlett Johansson 相似的 AI 语音，此前她的法律团队要求提高透明度。一位成员指出：“OpenAI 曾请求以商业合作形式使用她的声音，被拒绝后仍然制作了一个听起来与她‘惊人相似’的 AI 语音。”

- **辅助编程的最佳免费聊天机器人**：多位用户推荐了 GPT-3.5 的替代方案，例如 Meta AI 的 Llama 3 和 Le Chat 上的 Mistral Large，后者“接近 GPT-4 水平且全球免费”。其他人指出，不同的模型在处理不同的编程语言时表现各异。

- **对 Microsoft AI 集成的担忧**：用户讨论了 Microsoft Copilot 的侵入性，一位用户表示：“极其烦人且具有侵入性”，其他人则在争论遥测和数据共享问题。一些人更倾向于使用像 SillyTavern 这样的开源替代方案来实现类似功能。

- **对账户安全的警惕**：一名成员发现其账户存在未经授权的活动，引发了关于通过卸载可疑浏览器扩展和更改密码来保护数据的建议。另一位用户建议：“中国目前不是受支持的国家，因此不幸的是，确实存在一些动机去尝试入侵中国境外用户的账户。”

- **Microsoft 发布新的 Phi 模型**：Microsoft 在 Azure 上为 Phi-3 家族添加了新模型。Phi-3-vision 是一款结合了语言和视觉能力的多模态模型，正如 [Microsoft 博客文章](https://azure.microsoft.com/en-us/blog/new-models-added-to-the-phi-3-family-available-on-microsoft-azure/)中所强调的那样。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://forms.gle/BNf4VThDfXW8oYQ38">Trust for AI in the Medical Fields</a>：未找到描述</li><li><a href="https://azure.microsoft.com/en-us/blog/new-models-added-to-the-phi-3-family-available-on-microsoft-azure/">New models added to the Phi-3 family, available on Microsoft Azure | Microsoft Azure Blog</a>：我们推出了 Phi-3-vision，这是一款融合了语言和视觉能力的多模态模型，现已在 Microsoft Azure 上可用。了解更多。
</li>
</ul>

</div>
  

---

### **OpenAI ▷ #[gpt-4-discussions](https://discord.com/channels/974519864045756446/1001151820170801244/1242413408272257124)** (31 messages🔥): 

- **Token 计数说明**：成员们讨论了 Prompt 和响应的 Token 限制，并链接到了 [OpenAI 的帮助文章](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)。解释提到，大约 100 个 Token 等于 75 个英文单词。

- **下载 ChatGPT Mac 版的警告**：一位用户询问了 ChatGPT Mac 应用的非官方下载链接。建议等待 chatgpt.com 上的官方发布消息，因为非官方链接无法授予访问权限且可能不安全。

- **OpenAI Playground 复制 Bug**：一位用户请求撤销 OpenAI Playground 的一项更新，该更新会在复制的文本中添加换行符。另一位用户解释说，Playground 经常进行实时更改，并建议在论坛中发布反馈。

- **停机状态页面**：在服务中断期间，一位用户对在遇到问题时经常看到状态页面显示所有服务正常运行表示沮丧。[状态页面](https://status.openai.com)提供了有关事件和监控工作的更新。

- **数学任务的自定义指令**：关于在数学相关任务中使用自定义指令的讨论强调了始终使用 Code Interpreter。建议呈现清晰的结果并附带解释，包括必要的图表或表格。

**提到的链接**：<a href="https://status.openai.com">OpenAI Status</a>：未找到描述

  

---


### **OpenAI ▷ #[prompt-engineering](https://discord.com/channels/974519864045756446/1046317269069864970/1242491132878000138)** (58 messages🔥🔥): 

- **防止 LLM 啰嗦**：成员们讨论了防止 LLM 生成过长响应的各种策略。建议包括设置 **max tokens 参数**、要求简洁的回答以及使用**输出模板**。
- **Humblestumbler 提供全栈 Prompt**：一位用户分享了用于构建全栈应用程序的 Prompt，并提到当代码片段较长时模型会重启的错误。他们还讨论了一种特定的 Prompt 技术，涉及通过虚构会议来生成软件代码片段。
- **CodePilot 与 Prompt 性能**：成员们比较了使用 **CodePilot** 的经验，并讨论了其相对于手动精选 Prompt 的优缺点。一位用户指出，尽管 CodePilot 在调试方面表现出色，但他们的 Prompt 提供了更好的结果。
- **模型处理代码的混合体验**：成员们强调了 GPT-4o 的**冗长特性**，同时也赞赏它提供的详细解释。他们还分享了对模型不遵守特定编码风格要求（如 **Python 中的缩进**）的挫败感。
- **在 Prompt 中处理因变量和自变量**：一位用户寻求关于改进识别数据集中因变量和自变量的 Prompt 的建议。建议包括使用分隔符、添加示例以及使用 Markdown 格式化 Prompt 以获得更好的逻辑结构。
  

---


### **OpenAI ▷ #[api-discussions](https://discord.com/channels/974519864045756446/1046317269069864970/1242491132878000138)** (58 messages🔥🔥): 

- **防止 LLM 冗长**：成员们讨论了阻止语言模型提供过长响应的策略。建议包括设置 max tokens 参数和使用要求简洁回答的特定 Prompt。

- **创建全栈应用的 Prompt**：一位用户提出分享用于构建全栈应用程序的 Prompt，并分享了详细的示例 Prompt 以引导 AI 生成代码片段。他们强调使用“虚构团队”来提高响应质量。

- **在 GPT 中使用 CodePilot 和工具**：成员们讨论了使用 CodePilot 等工具和“Explore GPTs”菜单的经验。一些人表示，在编码任务中，相比工具生成的建议，他们更倾向于自定义编写的 Prompt。

- **维护 Prompt 规则的挑战**：一位用户提到，即使使用 Gemini 1.0 Pro，他们的规则有时也会被 AI 忽略。建议包括使用 Markdown 格式化并添加迭代改进以增强性能。

- **Prompt Labs 和 Playground 中的格式问题**：有关于 AI 如何更好地处理不同代码格式的对话，相比 JSON 更倾向于 YAML。用户还讨论了 Playground 环境中换行符处理的不一致性。
  

---

### **Modular (Mojo 🔥) ▷ #[general](https://discord.com/channels/1087530497313357884/1098713601386233997/1242394027589111899)** (30 条消息🔥): 

- **Mojo 社区会议录像已发布**：Mojo 社区会议的录像已在 [YouTube](https://www.youtube.com/playlist?list=PLh0S94-sJw_7nzHzy5DJDm8LUJUss9s0D) 上线。下次会议将有四个演讲，主题涵盖 Basalt 和 Compact Dict。
- **Python IPC 与 Threading 之争**：成员们讨论了在 Tkinter 应用中处理长耗时查询以避免 UI 卡顿的替代方案。提供了一个详细示例，并给出了涉及 threading、消息队列和 IPC 模块的建议。
- **机器人演示邀请**：一位成员表达了对机器人的喜爱，并邀请其他人观看相关的演示。
- **Modular 的工作机会**：分享了 [Modular 招聘页面](https://www.modular.com/careers) 的链接，鼓励申请者加入团队，共同致力于在全球范围内推动 AI 的使用。
- **RabbitMQ 的困扰**：一位成员发现 [RabbitMQ 的 Pika Python 客户端教程](https://www.rabbitmq.com/tutorials/tutorial-six-python) 在 IPC 方面很有前景，但在自己的机器上运行 Pika 时遇到困难。有人建议查看 GitHub issues。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://www.rabbitmq.com/tutorials/tutorial-six-python">RabbitMQ tutorial - Remote procedure call (RPC) | RabbitMQ</a>: &lt;!--</li><li><a href="https://www.modular.com/careers">Modular: Careers</a>: 在 Modular，我们相信优秀的文化是创建伟大公司的关键。我们遵循的三大支柱是：打造用户喜爱的产品、赋能人才、以及成为一支不可思议的团队。</li><li><a href="https://modul.ar/community-meeting-zoom.">Join our Cloud HD Video Meeting</a>: Zoom 是现代企业视频通信的领导者，拥有简单、可靠的云平台，适用于移动端、桌面端和会议室系统的视频和音频会议、聊天及网络研讨会。Zoom ...</li><li><a href="https://modul.ar/community-meeting.">Google Calendar - Sign in to Access &amp; Edit Your Schedule</a>: 未找到描述</li><li><a href="https://modul.ar/community-meeting-doc">[Public] Mojo Community Meeting</a>: Mojo 社区会议文档链接：https://modul.ar/community-meeting-doc。这是一个公开文档；欢迎所有人查看并提供评论/建议。所有会议参与者必须遵守...
</li>
</ul>

</div>
  

---


### **Modular (Mojo 🔥) ▷ #[💬︱twitter](https://discord.com/channels/1087530497313357884/1098713626161987705/)** (1 条消息): 

ModularBot: 来自 *Modular*:
<https://twitter.com/Modular/status/1793041489427153294>
  

---

### **Modular (Mojo 🔥) ▷ #[🔥mojo](https://discord.com/channels/1087530497313357884/1151418092052815884/1242464786315214858)** (113 条消息🔥🔥): 

- **VSCode Jupyter 扩展优于 DataSpell**：“*根据我的 DataSpell 使用经验，我只能说 —— VSCode Jupyter 扩展更可靠*，”一位用户在处理 *ydata-profiling* 或 *plotly* 等交互式 HTML+JS 输出时评论道。
- **Mojo 缺乏官方包管理器，但存在变通方法**：用户讨论了使用 `.mojopkg` 文件进行导入，特别是配合 [lightbug_http](https://github.com/saviorand/lightbug_http/releases/tag/latest-build) 使用。“Mojo 目前还没有包管理器，”但是“.mojopkg 文件可以使用（git pull lightbug 目录，执行 mojo build -o lightbug.mojopkg，然后在你的项目目录中使用该文件）。”
- **基于 MLIR 的 Mojo 优化**：讨论显示“*Mojo 编译器优化是为 MLIR 编写的*”，但对于实现 datalog 等自定义类型的性能影响仍是一个待探究的问题。
- **探索使用 lightbug_http 发送 HTTP 请求**：用户寻求使用 lightbug_http 发送 HTTP 请求的方法，分享并调试了[具体示例](https://github.com/saviorand/lightbug_http/issues/41)。“*我正试着弄清楚如何发送 GET 请求...*”，相关解决方案已通过 GitHub issues 进行了讨论。
- **Tensors 将被弃用并移交给社区**：Mojo 社区会议确认了这一举动，旨在不让 Mojo 在 Tensors 上“*独占资源 (lick the cookie)*”。这一转变引发了关于开发用于数值计算和 AI 用途的新库的讨论。

<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://gist.github.com/sa-/6be55a8c90934a01cd443503650b5e0b">signals.mojo</a>: GitHub Gist: 立即分享代码、笔记和片段。</li><li><a href="https://registerspill.thorstenball.com/p/from-vim-to-zed">From Vim to Zed</a>: 在使用了大约 20 年 Vim 之后，去年 12 月我切换到了 Zed 作为我的主要编辑器。既然有些朋友问起这次切换 —— “既然你在 Zed 工作，你是否在使用 Zed 代替 ...</li><li><a href="https://github.com/saviorand/lightbug_http/releases/tag/latest-build">Release latest-build: Merge pull request #27 from Moosems/main · saviorand/lightbug_http</a>: 未找到描述</li><li><a href="https://github.com/taalhaataahir0102/Jpeg-Decoder/tree/main/Mojo">Jpeg-Decoder/Mojo at main · taalhaataahir0102/Jpeg-Decoder</a>: 通过在 GitHub 上创建一个账号来为 taalhaataahir0102/Jpeg-Decoder 的开发做出贡献。</li><li><a href="https://github.com/saviorand/lightbug_http?tab=readme-ov-file>">GitHub - saviorand/lightbug_http: Simple and fast HTTP framework for Mojo! 🔥</a>: 简单且快速的 Mojo HTTP 框架！🔥。通过在 GitHub 上创建一个账号来为 saviorand/lightbug_http 的开发做出贡献。</li><li><a href="https://github.com/saviorand/lightbug_http/issues/41),">Issues · saviorand/lightbug_http</a>: 简单且快速的 Mojo HTTP 框架！🔥。通过在 GitHub 上创建一个账号来为 saviorand/lightbug_http 的开发做出贡献。</li><li><a href="https://github.com/taalhaataahir0102/Jpeg-Decoder">GitHub - taalhaataahir0102/Jpeg-Decoder</a>: 通过在 GitHub 上创建一个账号来为 taalhaataahir0102/Jpeg-Decoder 的开发做出贡献。</li><li><a href="https://github.com/modularml/mojo/issues/2725">[Feature Request] Memory allocation watcher · Issue #2725 · modularml/mojo</a>: 查看 Mojo 的优先级。我已阅读路线图和优先级，并认为此请求符合优先级。你的请求是什么？描述：作为一名使用 Mojo 的开发者，我希望...</li><li><a href="https://github.com/saviorand/lightbug_http/blob/1eb9242ce0ddeeec39ac858028a7117dde627523/lightbug_http/tests/test_client.mojo#L13">lightbug_http/lightbug_http/tests/test_client.mojo at 1eb9242ce0ddeeec39ac858028a7117dde627523 · saviorand/lightbug_http</a>: 简单且快速的 Mojo HTTP 框架！🔥。通过在 GitHub 上创建一个账号来为 saviorand/lightbug_http 的开发做出贡献。</li><li><a href="https://github.com/saviorand/lightbug_http/blob/main/lightbug_http/http.mojo">lightbug_http/lightbug_http/http.mojo at main · saviorand/lightbug_http</a>: 简单且快速的 Mojo HTTP 框架！🔥。通过在 GitHub 上创建一个账号来为 saviorand/lightbug_http 的开发做出贡献。</li><li><a href="https://github.com/saviorand/lightbug_http/blob/bd2f4ef57765505210256165b5386b890a2aa0be/lightbug_http/http.mojo#L12">lightbug_http/lightbug_http/http.mojo at bd2f4ef57765505210256165b5386b890a2aa0be · saviorand/lightbug_http</a>: 简单且快速的 Mojo HTTP 框架！🔥。通过在 GitHub 上创建一个账号来为 saviorand/lightbug_http 的开发做出贡献。
</li>
</ul>

</div>
  

---

### **Modular (Mojo 🔥) ▷ #[performance-and-benchmarks](https://discord.com/channels/1087530497313357884/1151418895417233429/1242454527773507654)** (3 messages): 

- **直接对指针的小型数组进行排序**：一位成员建议，对于排序几 KB 的数据，“先对指针数组进行排序”更有效。
- **DTypePointer memset 表现出参差不齐的性能**：向量化的 **DTypePointer memset** 实现“在 100,000 字节时比 llvm 调用快 20%”，但在 1,000,000 字节的大数据量下并非如此。用户因“使用 clobber memory”而表示不确定。
  

---


### **Modular (Mojo 🔥) ▷ #[nightly](https://discord.com/channels/1087530497313357884/1224434323193594059/1242403257859575889)** (100 messages🔥🔥): 

- **Commit 问题和 DCO 测试套件失败**：一位用户寻求帮助，解决由 Chris Lattner 误署名的 commit 导致的 DCO 测试套件失败问题。他们尝试使用 `rebase` 将其移除，并分享了他们的 [PR 链接](https://github.com/modularml/mojo/pull/2739)。

- **Nightly 版本发布延迟**：成员们讨论了 Nightly 版本的延迟，最初认为是 CI 或测试失败。后来确认是与 GitHub Actions 相关的问题，现已解决（[GitHub Status](https://www.githubstatus.com/)）。

- **字符串中 Unicode 支持的提案**：针对在字符串中添加 Unicode 支持的提案进行了广泛讨论，包括不同的内部表示形式（变长、UTF8、ASCII）。成员们权衡了内存开销、性能影响以及与不同编码的兼容性。

- **已解决的 CI/CD 问题**：讨论涵盖了长期存在的测试失败和 CI 行为的不一致。建议将 dict 条目标记为未初始化/已销毁，以防止随机的测试失败。

- **模块和函数更新**：`math.bit` 模块更名为 `bit`，并进行了多项函数重命名，包括将 `bswap` 改为 `byte_reverse`。分享了关于正在进行的更改和新默认字符串处理的实现，并附带了 [文档](https://docs.modular.com/mojo/stdlib/builtin/hex/hex) 和 [nightly changelog](https://github.com/modularml/mojo/blob/nightly/docs/changelog.md) 的链接。
<div class="linksMentioned">

<strong>提及的链接</strong>：

<ul>
<li>
<a href="https://peps.python.org/pep-0393/">PEP 393 – Flexible String Representation | peps.python.org</a>：无描述</li><li><a href="https://pub.dev/packages/characters">characters | Dart package</a>：具有 Unicode/grapheme cluster 感知操作的字符串替换。</li><li><a href="https://docs.modular.com/mojo/stdlib/builtin/hex/hex">hex | Modular Docs</a>：hexT: Intable -&gt; String</li><li><a href="https://www.githubstatus.com/">GitHub Status</a>：无描述</li><li><a href="https://github.com/modularml/mojo/pull/2739">[stdlib] Issue #2487: Changing argument msg in assert_true/assert_false/... to Keyword only by softmaxer · Pull Request #2739 · modularml/mojo</a>：变更：在 stdlib/src/testing/testing.mojo 的函数定义中添加 * 以区分变长参数和仅限关键字参数。扫描这些 assert 函数的调用点并替换 assert_true(val...</li><li><a href="https://github.com/modularml/mojo/pull/2771">[stdlib] Add format_simple() for StringLiteral by rd4com · Pull Request #2771 · modularml/mojo</a>：为 #2761 提供了一个“小”修复。它不是非常先进，只是提供一个有用的小功能：&quot;{name} is awesome {emoji}&quot;.format_simple(name=&quot;Mojo&quot;, emoji=&quot;🔥&qu...</li><li><a href="https://github.com/modularml/mojo/pull/2613#discussion_r1599235527">[stdlib] Add optional small buffer optimization in `List` by gabrieldemarmiesse · Pull Request #2613 · modularml/mojo</a>：与 #2467 相关。这是 SSO 的开发工作。我正在尝试一些方案，并希望收集社区反馈。起初，我想使用 Variant[InlineList, List] 实现 SSO，虽然那会...</li><li><a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/">Python behind the scenes #9: how Python strings work</a>：无描述
</li>
</ul>

</div>
  

---

### **LAION ▷ #[general](https://discord.com/channels/823813159592001537/823813160075132991/1242399599801663508)** (132 条消息🔥🔥): 

- **DECtalk 和 Speak & Spell 的怀旧情结**：成员们深情地提到了 DECtalk，并分享了一个 [Speak & Spell 视频](https://youtu.be/RpeegJ0J5mE?t=121) 的 YouTube 链接，展示了早期的个人电脑。
- **明星语音 AI 建模的担忧**：讨论了使用模仿 Scarlett Johansson 声音的配音演员是否会根据“假冒（passing off）”法引发法律问题。有人指出，由于潜在的伦理问题和意图，OpenAI 可能会面临抵制，并引用了 [Midler v. Ford Motor Co.](https://en.wikipedia.org/wiki/Midler_v._Ford_Motor_Co.) 案例。
- **关于 OpenAI 的争议与看法**：在发生了一系列引发负面公众情绪的事件后，人们对 OpenAI 的商业模式以及他们是否利用争议进行宣传持怀疑态度。
- **Sakuga-42M 数据集下架之谜**：与卡通动画帧相关的 Sakuga-42M 数据集消失了，据 [Hugging Face](https://huggingface.co/datasets/aidenpan/Sakuga-42M) 观察，推测是由于法律问题或大规模举报。
- **针对 AI 模型和数据集的行动**：幽默地提到了夸大的数据可用性问题和许可声明，强调了尽管存在重大的法律和伦理讨论，共享数据集的数量仍有显著增长。


<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://x.com/_ebehrens_/status/1792569302773555250">来自 Eva Behrens (@_ebehrens_) 的推文</a>：这是我和 ICFG 的同事为即将在首尔举行的 AI Safety Summit 提出的 5 项政策建议。在布莱切利，世界领导人讨论了前沿 AI 发展的主要风险。在首尔...</li><li><a href="https://choosealicense.com/licenses/wtfpl/">Do What The F*ck You Want To Public License</a>：最简单的许可证。它允许用户对你的代码做任何他们想做的事情。</li><li><a href="https://news.ycombinator.com/item?id=40389711">未找到标题</a>：未找到描述</li><li><a href="https://huggingface.co/datasets/ptx0/free-to-use-graffiti">ptx0/free-to-use-graffiti · Hugging Face 数据集</a>：未找到描述</li><li><a href="https://youtu.be/RpeegJ0J5mE?t=121">Speak &amp; Spell - 有史以来第一台个人电脑？</a>：由德州仪器（Texas Instruments）于 1978 年推出，这可能是当时大多数孩子拥有的第一台电脑。在这个视频中，我将介绍其功能、规格和...</li><li><a href="https://forum.effectivealtruism.org/posts/twMs8xsgwnYvaowWX/database-of-orgs-relevant-to-longtermist-x-risk-work>">与长期主义/生存风险（x-risk）工作相关的组织数据库 — EA 论坛</a>：这是该数据库的一个版本，你可以根据需要进行筛选和排序，这里还有一个你可以添加评论的版本。...</li><li><a href="https://github.com/rom1504/cc2dataset/blob/main/cc2dataset/main.py#L81-L84>">cc2dataset/cc2dataset/main.py at main · rom1504/cc2dataset</a>：轻松将 Common Crawl 转换为标题和文档的数据集。图像/文本、音频/文本、视频/文本... - rom1504/cc2dataset</li><li><a href="https://arxiv.org/html/2405.07425v1">Sakuga-42M Dataset: Scaling Up Cartoon Research</a>：未找到描述</li><li><a href="https://huggingface.co/datasets/ptx0/free-to-use-signs/viewer/default/train">ptx0/free-to-use-signs · Hugging Face 数据集</a>：未找到描述</li><li><a href="https://huggingface.co/datasets/ilovehentai9000/ilove-anime-sakuga-1TiB">ilovehentai9000/ilove-anime-sakuga-1TiB · Hugging Face 数据集</a>：未找到描述
</li>
</ul>

</div>
  

---

### **LAION ▷ #[research](https://discord.com/channels/823813159592001537/824374369182416994/1242441543240126524)** (26 messages🔥): 

- **xLSTM 实验引发好奇**：一位成员询问是否有人已经实验过 **xLSTM**。这似乎表明人们对非主流模型的兴趣日益增加。

- **Meta 论文带来了熟悉但有所改进的内容**：成员们审阅了一篇 [Meta 论文](https://arxiv.org/abs/2309.02591)，指出它与早期的 **cm3leon** 研究密切相关，但有所增强。他们强调了在可扩展性方面 Attention 机制的有趣进展。

- **KANs 受到评测**：一位成员分享了对 **KANs** (Kernel Attention Networks) 的评测，并附带了 [评测链接](https://vikasdhiman.info/reviews/KAN_a_review.pdf)，评论道：“拿走这个 KANs”。

- **Phi-3 Vision 聊天引发深入探索**：讨论围绕来自 [Microsoft](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct) 的 **Phi-3 Vision** 多模态模型展开，并包含了用于深入了解的文档资源。一位用户注意到 **GPT-4** 如何在不改变顺序的情况下生成按颜色排序的图表，从而引发了关于其用途的辩论。

- **Anthropic Scaling 论文读起来很吃力**：成员们讨论了最近一篇 [Anthropic 论文](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html) 的晦涩内容。有人指出，直到现在才出现关于其影响的对话。

**Link mentioned**: <a href="https://huggingface.co/microsoft/Phi-3-vision-128k-instruct">microsoft/Phi-3-vision-128k-instruct · Hugging Face</a>: no description found

  

---



### **LlamaIndex ▷ #[blog](https://discord.com/channels/1059199217496772688/1187460979064324127/1242504991369986199)** (4 messages): 

```html
- **GPT-4o excels at parsing complex documents**: GPT-4o’s multimodal capabilities can efficiently parse complex PDFs and slide decks with background images and irregular layouts into structured markdown. Learn more about this integration with [LlamaParse](https://t.co/g5TG7brSwt) [here](https://t.co/vhtYzsleh2).
- **Sandbox your LLM-generated code with Azure**: Securely execute LLM-generated code using Azure Container Apps dynamic sessions, which is especially useful for tasks that LLMs aren't natively capable of. Discover more details [here](https://t.co/2cnsBH411k) and [here](https://t.co/lTrUPoTMcF).
- **OpenDevin webinar released**: A webinar featuring OpenDevin, an open-source platform for building autonomous AI engineers, has been released. Robert Brennan provides an insightful walkthrough; watch it [here](https://t.co/a22k0zsV3n).
- **Batch inference for GenAI applications**: Use batch inference to preprocess large sets of data, enabling new types of analysis and querying for GenAI applications. Discover the integration details [here](https://t.co/vnuvvypZCz) and [here](https://t.co/M0vQQ1uAki).
```
  

---

### **LlamaIndex ▷ #[general](https://discord.com/channels/1059199217496772688/1059201661417037995/1242421332285718528)** (92 条消息🔥🔥): 

- **文档预览教程请求**：一名成员请求关于 **LlamaIndex 聊天前端**文档预览功能的教程，特别是如何获取 Embedding 中的 URL 元数据以供 PDF 查看器使用。
  
- **错误与解决方案**：几位用户遇到了诸如 *"ModuleNotFoundError"* 和 *"pydantic.v1.error_wrappers.ValidationError"* 的错误。解决方案包括修正导入路径以及移除特定的 Prompt，如 *condense_question_prompt*。

- **概念与技术**：成员们讨论了 **LlamaIndex 中的 Retriever**，涉及余弦相似度以及用于扩展的 HNSW 等方法。此外还讨论了 **Knowledge Graph Index 的创建**，参考了 Embedding 和关键词查找。

- **复杂文档处理**：一位用户分享了他在创建一个能在特定领域内准确回复的聊天机器人助手方面的工作，讨论了诸如后处理器重排序（post processor reranking）等策略，以及对有效主题限制的担忧。

- **合并多个索引**：针对将多个索引合并为一个 Vector Index 的咨询，结论是不支持直接合并，应当分别查询每个索引并汇总响应。

<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://docs.]">未找到标题</a>：未找到描述</li><li><a href="https://docs.llamaindex.ai/en/stable/examples/retrievers/ensemble_retrieval/">Ensemble Retrieval 指南 - LlamaIndex</a>：未找到描述</li><li><a href="https://docs.llamaindex.ai/en/stable/examples/discover_llamaindex/document_management/group_conversations/?h=group">分组对话 - LlamaIndex</a>：未找到描述</li><li><a href="https://docs.llamaindex.ai/en/stable/examples/query_engine/pdf_tables/recursive_retriever/?h=group">Recursive Retriever + Query Engine 演示 - LlamaIndex</a>：未找到描述</li><li><a href="https://docs.llamaindex.ai/en/latest/examples/docstore/DocstoreDemo#define-multiple-indexes>)">Docstore 演示 - LlamaIndex</a>：未找到描述</li><li><a href="https://docs.llamaindex.ai/en/stable/examples/data_connectors/GithubRepositoryReaderDemo/?h=github">GitHub 仓库读取器 - LlamaIndex</a>：未找到描述</li><li><a href="https://docs.llamaindex.ai/en/stable/api_reference/packs/code_hierarchy/?h=code">代码层级 - LlamaIndex</a>：未找到描述</li><li><a href="https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_query_engine/?h=group">Knowledge Graph Query Engine - LlamaIndex</a>：未找到描述</li><li><a href="https://colab.research.google.com/drive/1G6pcR0pXvSkdMQlAK_P-IrYgo-_staxd?usp=sharing">Google Colab</a>：未找到描述
</li>
</ul>

</div>
  

---

### **OpenRouter (Alex Atallah) ▷ #[general](https://discord.com/channels/1091220969173028894/1094454198688546826/1242387467558977556)** (85 条消息🔥🔥): 

- **关于 OpenRouter 用户类型的讨论**：一位用户幽默地指出了两类典型的 OR 用户：一类寻求与 AI 进行亲密互动，另一类则要求生成不当故事，这引发了关于角色扮演应用盛行情况的简短讨论。
- **介绍了 Phi-3 Vision 模型**：分享了关于 HuggingFace 上提供的 **Phi-3 Vision 模型**的信息，强调了其高质量的推理能力和严格的增强过程。[阅读更多](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct)关于该模型及其文档的信息。
- **解决 Wizard 的冗余问题**：成员们讨论了 **Wizard8x22** 在冗余和标点符号不当方面的困扰，建议调整 repetition penalty 作为潜在的解决方案。讨论还扩展到了 Mixtral 等其他模型，并强调了模型性能的可变性。
- **管理学生平台的计费错误**：围绕用户在管理其学生平台时遇到的计费错误展开了长时间的对话。交流最终通过删除并重新输入计费信息得到了临时解决，同时表达了对未来非营利组织折扣的期待。
- **探索新的 LLM 交互技术**：一位用户分享了他们在 [Twitter 上的帖子](https://x.com/leonjcoe/status/1792946945528320382)，关于通过 action commands 使用 LLM 的创新方式，并邀请他人提供反馈和经验以扩大讨论。
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://huggingface.co/microsoft/Phi-3-vision-128k-instruct">microsoft/Phi-3-vision-128k-instruct · Hugging Face</a>: 未找到描述</li><li><a href="https://huggingface.co/microsoft/Phi-3-medium-4k-instruct">microsoft/Phi-3-medium-4k-instruct · Hugging Face</a>: 未找到描述</li><li><a href="https://x.com/leonjcoe/status/1792946945528320382">来自 Leon Builds Agents (@leonjcoe) 的推文</a>: 有一种没人讨论的与 LLM 交互的新方式：Action Commands。那么它们是什么，为什么如此有价值？让我展示给你看。
</li>
</ul>

</div>
  

---



### **Interconnects (Nathan Lambert) ▷ #[news](https://discord.com/channels/1179127597926469703/1179128538679488533/1242495837771403408)** (14 条消息🔥): 

- **Phi-small 和 Phi-medium 模型发布**：宣布发布 **Phi-small** 和 **Phi-medium** 模型。随后讨论了 Phi-Vision 是否为新模型，并确认 Phi-3 Vision 是一个新的、体积稍大的版本。

- **关于 Meta 400B 模型权重的担忧**：[@apples_jimmy 的一条推文](https://x.com/apples_jimmy/status/1793081686802280576?s=46)声称 Meta 可能出于对立法的担忧而不会开放其 400B 模型的权重。@q_brabus 的另一条推文反驳了这一点，指出**该模型将保持 open-weight**，并斥责该传闻为假。

- **News Corp 与 OpenAI 的合作伙伴关系**：据 [@maxwelltani](https://fxtwitter.com/maxwelltani/status/1793375460879110564) 报道，News Corp 和 OpenAI 宣布了一项具有历史意义的多年度协议。该协议允许 OpenAI 在回答用户问题时展示来自 WSJ、NY Post、Times/Sunday Times 等 News Corp 旗下的内容，并以此增强其产品。
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://x.com/apples_jimmy/status/1793081686802280576?s=46">来自 Jimmy Apples 🍎/acc (@apples_jimmy) 的推文</a>: Meta 计划不开放其 400B 模型的权重。希望是我们会悄悄地不注意到/让它过去。不要让它过去。</li><li><a href="https://fxtwitter.com/maxwelltani/status/1793375460879110564">来自 Max Tani (@maxwelltani) 的推文</a>: 收件箱：News Corp 和 OpenAI 宣布了一项具有历史意义的多年度协议，将 News Corp 的新闻内容引入 OpenAI，OpenAI 现在获准展示来自 WSJ、NY Post、Times/Sunday Times 等的内容...</li><li><a href="https://x.com/q_brabus/status/1793227643556372596?s=46">来自 QBrabus eu/acc (@q_brabus) 的推文</a>: @apples_jimmy @ylecun @iamgingertrash 问：关于即将推出的 LLaMa 3 400B+ 模型，它会是 open-weight 吗？有几个关于这方面的传闻... 答：不，它仍然计划是开源的...
</li>
</ul>

</div>
  

---

### **Interconnects (Nathan Lambert) ▷ #[ml-drama](https://discord.com/channels/1179127597926469703/1181746144821387334/1242484506108366959)** (7 messages): 

- **OpenAI 的 Superalignment 团队因承诺未兑现而解散**：一篇 [Fortune 文章](https://fortune.com/2024/05/21/openai-superalignment-20-compute-commitment-never-fulfilled-sutskever-leike-altman-brockman-murati/) 报道称，旨在确保高智能系统 AI 安全的 OpenAI Superalignment 团队已解散。尽管承诺提供 20% 的算力资源，但 OpenAI 未能履行这一承诺，导致员工辞职。
- **Sam Altman 的 NDA 丑闻受到质疑**：[最新消息](https://fxtwitter.com/kelseytuoc/status/1793402040439476554?s=46) 指出，OpenAI 的高级领导层声称对威胁前员工没收既定股权（vested equity）一事不知情，但带有他们签名的文件却显示事实并非如此。[Vox 的文章](https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees) 质疑 Sam Altman 在公司 NDA 惯例方面是否坦诚。
- **前员工在离职协议上面临压力**：Vox 的调查显示，OpenAI 对希望有更多时间审查复杂离职文件的离职员工采取了紧迫的时间表和强力施压手段。前员工只有七天时间签署协议，否则将面临损失数百万美元的风险，且几乎没有机会寻求外部法律顾问。
<div class="linksMentioned">

<strong>Links mentioned</strong>:

<ul>
<li>
<a href="https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees">Tweet from Leaked OpenAI documents reveal aggressive tactics toward former employees</a>: Has Sam Altman told the truth about OpenAI’s NDA scandal?</li><li><a href="https://fortune.com/2024/05/21/openai-superalignment-20-compute-commitment-never-fulfilled-sutskever-leike-altman-brockman-murati/">OpenAI promised 20% of its computing power to combat the most dangerous kind of AI—but never delivered, sources say</a>: The company&#x27;s Superalignment team had its requests for computer power repeatedly rejected even though they never approached the 20% threshold, sources say.</li><li><a href="https://fxtwitter.com/kelseytuoc/status/1793402040439476554?s=46">Tweet from Kelsey Piper (@KelseyTuoc)</a>: Scoop: OpenAI&#39;s senior leadership says they were unaware ex-employees who didn&#39;t sign departure docs were threatened with losing their vested equity. But their signatures on relevant documents...
</li>
</ul>

</div>
  

---


### **Interconnects (Nathan Lambert) ▷ #[random](https://discord.com/channels/1179127597926469703/1183121795247779910/1242483222252884061)** (33 messages🔥): 

- **MSFT Surface 绘图 AI 因云端检查变慢**：新的 MSFT Surface 绘图 AI 在本地运行，但由于向云端发送安全检查而出现延迟。一位用户对该 AI 的缓慢表现评价道：“这太蠢了。”
- **Ben Thompson 可能在 Microsoft Build 讨论了 AI**：成员们推测，有关 MSFT Surface 绘图 AI 的信息来源可能出自 Ben Thompson 在 Microsoft Build 活动上的文章或演讲。一位用户提到：“我想 Ben Thompson 今天写了关于这个的内容。”
- **关于用户过去造假同事的讨论**：一位用户讲述了他们的一位同事在简历上虚假声称曾与该用户正在合作的人共事。这引发了对职业轨迹和随时间成熟的思考。
- **Anthropic 的快速增长令成员感到惊讶**：一位用户对 Anthropic 现在拥有超过 500 名研究人员表示惊讶，并强调了“研究人员（researcher）”这一头衔的广泛使用。另一位成员对此反思道：“每个人都喜欢被称为研究人员。”
- **邮件退订和参与度洞察**：一位用户注意到他们的电子邮件通讯有大量退订，将其归因于 Substack 推荐驱动的过度订阅。他们强调比起纯粹的数量，更倾向于参与度更高的订阅者，并指出不活跃用户的离开是件好事。
  

---


### **Interconnects (Nathan Lambert) ▷ #[memes](https://discord.com/channels/1179127597926469703/1187551504995987576/1242483369585938462)** (3 messages): 

```html
- **笑声随之而来**：“lol ugh” 表达了有趣与恼火交织的情绪，暗示了一种幽默但略显沮丧的情况。随后的 “It’s funny tho” 强化了这种情绪。
- **鞋履幽默**：“他就像鞋履选择界的 Scott Galloway” 意味着与 Scott Galloway 的类比，暗示某人在选择鞋子方面具有强烈且固执己见的个性。
```

### **Interconnects (Nathan Lambert) ▷ #[posts](https://discord.com/channels/1179127597926469703/1228051082631188530/1242852766678781952)** (20 messages🔥): 

- **Nathan Lambert 对帖子讨论表示赞赏**：Nathan Lambert 对最近的一篇帖子充满热情，表示：*"我真的很喜欢今天的帖子。我认为这是一部面向大众的优秀作品"*。Lambert 表示他也会在内部进行推广。

- **数字名人 vs. 现实名人**：Ashleyduque 提出了数字名人可能盖过现实名人的潜力，提到：*"是什么阻止了我们为助手制作和选择自己的声音，以及在未来让模型创造出完全数字化的名人？"*。Nathan Lambert 对数字人物的依恋表示赞同，但表达了对监管的担忧，指出：*"现实中，人类会与数字名人建立强烈的联系。我不知道该如何对他们进行不同的监管。感到害怕。"*

- **超个性化体验的未来**：随后讨论了超个性化体验是否会取代共享文化体验。Xeophon 反驳说，共享话题创造了社区纽带，他说：*"每个泡沫都有自己的摇滚明星……但为此，那个<某物>必须是相同的。"*

- **VR 与周边创意**：Nathan Lambert 分享了关于制作马克杯和贴纸等品牌周边的想法，幽默地说道：*"我需要提升我的品牌影响力，哈哈。"* 他还表达了对 VR 的微妙看法，尽管 VR 可能对人产生负面影响，但他对其存在仍持“看涨（bullish）”态度。
  

---



### **OpenAccess AI Collective (axolotl) ▷ #[general](https://discord.com/channels/1104757954588196865/1104757955204743201/1242371364971876412)** (37 messages🔥): 

- **为 Axolotl 添加 Cohere 支持**：正在进行的 [pull request #1547](https://github.com/OpenAccess-AI-Collective/axolotl/pull/1547/files) 旨在将 Cohere (commandr) 整合到 Axolotl 系统中。该功能尚未经过测试。

- **Tokenizer 困惑已解决**：一位成员参考了 `CohereTokenizerFast` 文档来解决 Tokenization 问题。他们提供了一个 [GitHub 仓库链接](https://github.com/huggingface/transformers/blob/d24097e0229485287ff4959258c552168bd898c6/src/transformers/models/cohere/tokenization_cohere_fast.py#L51C7-L51C26) 作为参考。

- **发现 Tiny Mistral 模型**：Kalomaze 找到了 [tiny Mistral model](https://huggingface.co/openaccess-ai-collective/tiny-mistral/tree/main)，它是随机初始化的，用于测试自定义交叉熵（cross-entropy）函数。尽管最初有些困惑，但该模型符合他们的要求。

- **蒸馏流水线进展**：Kalomaze 和 AMOGUS 正在开发一个蒸馏流水线，并报告称“目前运行良好”。这项工作是 Mistral 模型持续开发的一部分。

- **确定了更快的 STT 到 LLM 库**：用于创建更快的语音转文本（STT）到语言模型流水线的 Python 库被确定为 [pipecat](https://github.com/pipecat-ai/pipecat)。由于本地模型支持的原因，一些成员表示更倾向于 OpenVoice 或 VoiceCraft 等替代方案。
<div class="linksMentioned">

<strong>提及的链接</strong>：

<ul>
<li>
<a href="https://huggingface.co/openaccess-ai-collective/tiny-mistral/tree/main">openaccess-ai-collective/tiny-mistral at main</a>: 未找到描述</li><li><a href="https://github.com/pipecat-ai/pipecat">GitHub - pipecat-ai/pipecat: Open Source framework for voice and multimodal conversational AI</a>: 语音和多模态对话式 AI 的开源框架 - pipecat-ai/pipecat</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/pull/1547/files">Feat: Add cohere (commandr) by NanoCode012 · Pull Request #1547 · OpenAccess-AI-Collective/axolotl</a>: 描述、动机和背景。如何测试？未测试！截图（如果适用）。变更类型。社交账号（可选）。</li><li><a href="https://github.com/huggingface/transformers/blob/d24097e0229485287ff4959258c55">GitHub - huggingface/transformers at d24097e0229485287ff4959258c552168bd898c6</a>: 🤗 Transformers: 为 Pytorch, TensorFlow, 和 JAX 提供的最先进机器学习库。 - GitHub - huggingface/transformers</li><li><a href="https://github.com/huggingface/transformers/blob/d24097e0229485287ff4959258c552168bd898c6/src/transformers/models/cohere/tokenization_cohere_fast.py#L51C7-L51C26">transformers/src/transformers/models/cohere/tokenization_cohere_fast.py at d24097e0229485287ff4959258c552168bd898c6 · huggingface/transformers</a>: 🤗 Transformers: 为 Pytorch, TensorFlow, 和 JAX 提供的最先进机器学习库。 - huggingface/transformers
</li>
</ul>

</div>
  

---

### **OpenAccess AI Collective (axolotl) ▷ #[general-help](https://discord.com/channels/1104757954588196865/1110594519226925137/1242385970431660073)** (14 messages🔥): 

- **Full Finetuning vs. LoRA 性能对比**：一位成员在文章中看到 **LoRA** 的良好效果后，对 Full Finetuning 产生了兴趣。另一位用户澄清说，与 LoRA 相比，Full Finetuning 有助于更好的知识保留（retention），这对于特定风格的调整可能更有利。
  
- **推理配置问题**：讨论了推理命令 `accelerate launch -m axolotl.cli.inference test_axolotl.yml --lora_model_dir="..."`。有建议指出，这种设置可能不会自动包含 chat templates，建议在需要时手动添加。

- **配置与文档参考**：成员们分享了一个用于 Full Finetuning 的配置，并提到了 [Axolotl GitHub README](https://github.com/OpenAccess-AI-Collective/axolotl?tab=readme-ov-file#tokenization-mismatch-bw-inference--training) 中的相关章节，该章节涵盖了推理与训练之间的 Tokenization 不匹配问题，以帮助解决相关故障。

- **稳定大版本发布咨询**：一位成员询问了 **Axolotl** 下一个稳定大版本（stable major release）的发布时间，但未得到立即回复。

- **微调的 GPU 显存需求**：一位用户询问了使用 4090 GPU 进行微调的显存要求，特别提到了 `examples/mistral/lora.yml` 示例，并遇到了 `CUDA out of memory errors`。他们正在寻求如何计算所需显存以及可能调整的指南。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://github.com/OpenAccess-AI-Collective/axolotl?tab=readme-ov-file#tokenization-mismatch-bw-inference--training">GitHub - OpenAccess-AI-Collective/axolotl: Go ahead and axolotl questions</a>：尽管问 Axolotl 问题。通过在 GitHub 上创建账号为 OpenAccess-AI-Collective/axolotl 的开发做出贡献。</li><li><a href="https://github.com/OpenAccess-AI-Collective/axolotl?tab=readme-ov-file#tokenizati">GitHub - OpenAccess-AI-Collective/axolotl: Go ahead and axolotl questions</a>：尽管问 Axolotl 问题。通过在 GitHub 上创建账号为 OpenAccess-AI-Collective/axolotl 的开发做出贡献。
</li>
</ul>

</div>
  

---


### **OpenAccess AI Collective (axolotl) ▷ #[axolotl-phorm-bot](https://discord.com/channels/1104757954588196865/1225558824501510164/1242736717400768584)** (5 messages): 

- **澄清 LoRA 合并时的 offload_dir 设置**：一位用户询问在合并 LoRA 模型时如何设置 `offload_dir`。回复解释说，在合并过程中不直接设置卸载目录，但在合并后，可以使用 `accelerate` 库中的 `offload_state_dict` 函数手动指定，并说明：*"将合并后模型的 state dictionary 卸载到指定的目录。"*


**提到的链接**：<a href="https://phorm.ai/query?projectId=1e8ce0ca-5f45-4b83-a0f4-9da45ce8e78b&threadId=dce0e2d6-3e84-461f-a383-70860ed4ddfb)">OpenAccess-AI-Collective/axolotl | Phorm AI Code Search</a>：更快地理解代码。

  

---



### **Latent Space ▷ #[ai-general-chat](https://discord.com/channels/822583790773862470/1075282825051385876/1242469335373709392)** (50 messages🔥): 

- **Langchain JS 评价褒贬不一**：一位成员发现 **Langchain JS** 对于快速开发很有用，尽管它不像 Python 版本那样完善。他们计划在未来的迭代中重新构建架构。

- **Scale AI 融资 10 亿美元**：[Scale AI](https://fortune.com/2024/05/21/scale-ai-funding-valuation-ceo-alexandr-wang-profitability/) 获得了 10 亿美元融资，公司估值达到 138 亿美元。其年度经常性收入（ARR）在 2023 年翻了三倍，公司预计到 2024 年底实现盈利。

- **Phi 3 模型发布令人印象深刻**：[微软发布了 Phi 3 模型](https://x.com/reach_vb/status/1792949163249791383?s=46&t=90xQ8sGy63D2OtiaoGJuww)，这些模型可与 Mixtral、Llama 和 GPT 模型竞争，具有 4K 和 128K 的上下文长度以及全新的 Tokenizer。这些模型在其尺寸下的表现令用户印象深刻，并有潜力在 MacBook Pro M1 Pro 上本地运行。

- **Anthropic 的字典学习突破**：[Anthropic](https://x.com/mlpowered/status/1792948212728524917?s=46&t=90xQ8sGy63D2OtiaoGJuww) 在前沿模型上实现了字典学习（dictionary learning），能够进行数百万次的特征提取。这一进展有望通过识别和操纵模型内部的激活路径（activation pathways），提升 AI 的安全性和有效性。

- **Humane 在 AI Pin 失败后寻求收购**：[Humane 正在寻求出售](https://www.theverge.com/2024/5/21/24162185/humane-seeking-acquisition-rumor-ai-pin)其评价不佳的 AI Pin 设备，目标价格在 7.5 亿至 10 亿美元之间。成员们讨论了在硬件领域与 Apple 竞争的挑战，以及如果公司未能找到买家可能面临的后果。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>

<li><a href="https://x.com/mlpowered/status/1792948212728524917">来自 Emmanuel Ameisen (@mlpowered) 的推文</a>：今天，我们宣布已在 Sonnet 上成功实现了字典学习（dictionary learning），从全球最顶尖的模型之一中提取了数百万个特征。这是该技术首次获得成功...</li><li><a href="http://suno.com/blog/fundraising-announcement-may-2024">Suno 已融资 1.25 亿美元，旨在构建一个人人都能创作音乐的未来</a>：我们的音乐家社区值得拥有最好的工具，而构建最好的工具需要最顶尖的人才。我们将利用这笔资金加速产品开发并扩大我们的世界级...</li><li><a href="https://braindump.me/blog-posts/building-an-ai-game-studio">构建 AI 游戏工作室：我们目前的经验 - Braindump Incorporated</a>：利用 AI 创造世界和游戏</li><li><a href="https://x.com/alexandr_wang/status/1792905417065914858?s=46&t=90xQ8sGy63D2OtiaoGJuww">来自 Alexandr Wang (@alexandr_wang) 的推文</a>：1/ 今天，@Scale_AI 宣布以 138 亿美元的估值获得 10 亿美元融资。本轮融资由 @Accel 领投，现有投资者参投。@Scale_AI 在加速...方面从未处于如此有利的位置。</li><li><a href="https://fortune.com/2024/05/21/scale-ai-funding-valuation-ceo-alexandr-wang-profitability/">独家：Scale AI 以 140 亿美元估值获得 10 亿美元融资，其 CEO 预测年底将实现大幅营收增长和盈利</a>：Scale AI 帮助公司为 AI 模型训练标注和测试数据，该公司已完成一轮 10 亿美元的新融资，估值达 140 亿美元。</li><li><a href="https://www.theverge.com/2024/5/21/24162185/humane-seeking-acquisition-rumor-ai-pin">在 AI Pin 表现平平后，Humane 正在寻求买家</a>：显然 Humane 认为其价值超过 10 亿美元。</li><li><a href="https://x.com/laurentsifre/status/1793045814756921651?s=46&t=90xQ8sGy">来自 Laurent Sifre (@laurentsifre) 的推文</a>：H</li><li><a href="https://www.anthropic.com/news/mapping-mind-language-model">映射大语言模型的思想</a>：我们已经确定了数百万个概念在 Claude Sonnet（我们部署的大语言模型之一）内部是如何表示的。这是有史以来第一次对现代生产级大模型内部进行的详细观察...</li><li><a href="https://x.com/dsiroker/status/1792956339515273537">来自 Dan Siroker (@dsiroker) 的推文</a>：很多人问我关于 Microsoft Recall 的看法，这就是我的观点！</li><li><a href="https://news.ycombinator.com/item?id=40429326">未找到标题</a>：未找到描述</li><li><a href="https://x.com/thesephist/status/1793031719244734923">来自 Linus (@thesephist) 的推文</a>：到 2024 年底，在几个大型生产部署中，在潜空间/激活空间（latent/activation space）引导基础模型的效果将超过在 Token 空间（“Prompt Eng”）的引导。我曾对此表示怀疑...</li><li><a href="https://x.com/mlpowered/status/1792948212728524917?s=46&t=90xQ8sGy63D2OtiaoGJuww">来自 Emmanuel Ameisen (@mlpowered) 的推文</a>：今天，我们宣布已在 Sonnet 上成功实现了字典学习，从全球最顶尖的模型之一中提取了数百万个特征。这是该技术首次获得成功...</li><li><a href="https://x.com/laurentsifre/status/1793045814756921651?s=46&t=90xQ8sGy63D2OtiaoGJuww">来自 Laurent Sifre (@laurentsifre) 的推文</a>：H</li><li><a href="https://x.com/alexalbert__/status/1792936647665107108?s=46&t=90xQ8sGy63D2OtiaoGJuww">来自 Alex Albert (@alexalbert__) 的推文</a>：我们新的可解释性论文首次详细展示了前沿 LLM 的内部情况，并包含了一些精彩的故事。我想分享其中两个自我读过以来一直令我难忘的故事。背景介绍...</li><li><a href="https://x.com/stephenlcasper/status/1793014675237638341?s=46&t=90xQ8sGy63D2OtiaoGJuww">来自 Cas (Stephen Casper) (@StephenLCasper) 的推文</a>：🧵 5 月 5 日，我针对 Anthropic 的下一篇 SAE 论文会做和不会做的事情做了 10 个预测。我 10 投 10 中... https://x.com/StephenLCasper/status/1787270794017702045 引用 Cas (Stephen...</li><li><a href="https://x.com/reach_vb/status/1792949163249791383?s=46&t=90xQ8s">来自 Vaibhav (VB) Srivastav (@reach_vb) 的推文</a>：冲啊！Phi 3 - Small, Medium 和 Vision 发布了！🔥  &gt; Medium 版本可与 Mixtral 8x22B、Llama 3 70B 竞争，并击败了 Command R+ 104B 和 GPT 3.5 &gt; Small 版本击败了 Mistral 7B 和 Llama 3 8B &gt; 支持 4K 和 128K ...</li><li><a href="https://x.com/reach_vb/status/1792949163249791383?s=46&t=90xQ8sGy63D2OtiaoGJuww">来自 Vaibhav (VB) Srivastav (@reach_vb) 的推文</a>：冲啊！Phi 3 - Small, Medium 和 Vision 发布了！🔥  &gt; Medium 版本可与 Mixtral 8x22B、Llama 3 70B 竞争，并击败了 Command R+ 104B 和 GPT 3.5 &gt; Small 版本击败了 Mistral 7B 和 Llama 3 8B &gt; 支持 4K 和 128K ...</li><li><a href="https://youtu.be/uHEPBzYick0?si=ajbDL9agnubNAECO&t=203">微软 vs. 苹果：Satya Nadella 表示专注于 AI 的 Copilot+ PCs 击败了 Macs | WSJ</a>：微软搭载 Qualc... 的新型 Copilot+ PCs

omm 芯片和 AI Windows 功能旨在击败 Apple 的 MacBooks。WSJ 的 Joanna Stern 试用了这些新款笔记本电脑并坐下来...
</li>
</ul>

</div>
  

---


### **Latent Space ▷ #[ai-announcements](https://discord.com/channels/822583790773862470/1075282504648511499/1242620273086304356)** (1 messages): 

- **加入 Survey Paper Club 以快速获取论文见解**：*对于新加入的朋友，我们明天有一个 survey —— 这是在一小时内快速了解几篇论文的绝佳方式*。[在此注册以获取通知](https://lu.ma/e5nk2ebp)。

**提到的链接**：<a href="https://lu.ma/e5nk2ebp">LLM Paper Club (Survey Paper Club!) · Zoom · Luma</a>：今天是 survey 日！从这里挑选一篇论文并在 5 分钟内进行讲解：https://app.sli.do/event/bNV6mo3BFGhe8Bqzb1tonb/live/questions

  

---


### **Latent Space ▷ #[llm-paper-club-west](https://discord.com/channels/822583790773862470/1197350122112168006/1242915170003456151)** (4 messages): 

- **Zoom 链接已通过电子邮件发送**：成员们询问会议的 Zoom 链接在哪里提供。他们被引导至[此处](https://lu.ma/e5nk2ebp)注册，链接每周会发送到他们的电子邮箱。

**提到的链接**：<a href="https://lu.ma/e5nk2ebp">LLM Paper Club (Survey Paper Club!) · Zoom · Luma</a>：今天是 survey 日！从这里挑选一篇论文并在 5 分钟内进行讲解：https://app.sli.do/event/bNV6mo3BFGhe8Bqzb1tonb/live/questions

  

---



### **LangChain AI ▷ #[general](https://discord.com/channels/1038097195422978059/1038097196224086148/1242394632285847642)** (36 messages🔥): 

- **LangChain vs LangChain_Community**：成员们讨论了 **LangChain** 和 **LangChain Community** 之间的架构差异。参考 [LangChain 文档](https://python.langchain.com/v0.2/docs/concepts/#architecture)解释了关键部分和集成。

- **链接 LangChain 模型**：一位用户询问了关于链接 LangChain 模型的问题，描述了一个特定场景并分享了 [LangChain Cookbook 教程](https://youtu.be/2xxziIWmaSA?si=3wkNt_huJKu3xK3t&t=1694)。成员们建议了如何处理跨链的变量名一致性。

- **用于云端部署的 Pluto**：一位成员提交了一个 PR，将 **Pluto** 作为 **LangServe** 应用在云端的部署选项。他们还分享了一个 [QA 助手示例](https://xw3vdvjmyp7jig7tmrvrqbisiu0peosf.lambda-url.us-east-1.on.aws/)和一篇解释性[文章](https://pluto-lang.vercel.app/cookbook/rag-qa-bot-with-web)。

- **使用 Ray 进行分布式摄取**：有人提出了关于使用 **Ray** 和 **LangChain** 进行分布式数据摄取的问题，但指出 Ray 团队的资源已过时。社区尚未提供明确的解决方案。

- **Plan-and-Execute 示例问题**：一位用户报告了 **langgraphjs** 中 **plan-and-execute** 示例的问题，并提到了使其正常运行所需的特定软件包版本。该示例与 Node 的兼容性受到质疑，但特定的版本调整帮助解决了错误。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://discordapp.com/channels/1038097195422978059/1242839942921584760">Discord - 与好友和社区聊天的新方式</a>：Discord 是通过语音、视频和文字进行交流的最简单方式。聊天、聚会，并与你的好友和社区保持紧密联系。</li><li><a href="https://python.langchain.com/v0.2/docs/concepts/#architecture">概念指南 | 🦜️🔗 LangChain</a>：本节包含 LangChain 关键部分的介绍。</li><li><a href="https://youtu.be/2xxziIWmaSA?si=3wkNt_huJKu3xK3t&t=1694">LangChain Cookbook - 7 个核心概念初学者指南</a>：Twitter: https://twitter.com/GregKamradt Newsletter: https://mail.gregkamradt.com/signup Cookbook Part 2: https://youtu.be/vGP4pQdCocw Wild Belle - Keep You: ht...</li><li><a href="https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb?ref=blog.langchain.dev)">langgraphjs/examples/plan-and-execute/plan-and-execute.ipynb at main · langchain-ai/langgraphjs</a>：⚡ 以图的形式构建语言 Agent ⚡。通过在 GitHub 上创建账号为 langchain-ai/langgraphjs 的开发做出贡献。</li><li><a href="https://github.com/langchain-ai/langchain/discussions/22006#discussioncomment-9515272">KeyError: "Input to ChatPromptTemplate is missing variables {'agent_scratchpad'}. 以及 TypeError: string indices must be integers -> format_to_openai_function_messages( x["intermediate_steps"] ), · langchain-ai/langchain · Discussion #22006</a>：检查了其他资源。我为此问题添加了一个非常详细的标题。我使用集成搜索查询了 LangChain 文档。我使用 GitHub 搜索来查找类似问题并...
</li>
</ul>

</div>
  

---

### **LangChain AI ▷ #[langserve](https://discord.com/channels/1038097195422978059/1170024642245832774/1242905562526646343)** (1 messages): 

- **LangServe 的 'invoke' 端点 Bug 引发讨论**：用户报告了 LangServe 的 'invoke' 端点存在一个普遍问题，即无法返回检索链的所有输出。它只返回问答对，而不包含上下文和源文档，且没有检索到任何文档。[讨论链接](https://github.com/langchain-ai/langserve/discussions/461)。

- **'invoke' 路由的空输出问题**：另一位用户分享了一个相关问题，即 'invoke' 路由返回空输出，而流式传输（streaming）功能却能正常工作。这种差异给依赖 'invoke' 端点获取完整响应的应用带来了挑战。[问题链接](https://github.com/langchain-ai/langserve/issues/301)。

- **RemoteRunnable vs. RunnableWithMessageHistory**：一个被强调的问题是 RemoteRunnable 组件无法返回源文档，而与其对应的 RunnableWithMessageHistory 则表现正常。这种不一致性影响了托管脚本在问答链中返回预期来源的可靠性。[问题链接](https://github.com/langchain-ai/langserve/issues/618)。
<div class="linksMentioned">

<strong>提及的链接</strong>：

<ul>
<li>
<a href="https://github.com/langchain-ai/langserve/discussions/461">使用检索链时未检索到文档 · langchain-ai/langserve · Discussion #461</a>：你好，我是 LangChain 和 LangServe 的新手。我认为在返回元数据时存在问题。API 只返回了答案和问题，这里是我的 FastAPI 服务端代码...</li><li><a href="https://github.com/langchain-ai/langserve/issues/301">LangServe：'invoke' 路由返回空输出，而 Streaming 正常工作 · Issue #301 · langchain-ai/langserve</a>：我正在构建一个非常简单的 LangChain 应用，它接收客户反馈字符串并将其分类到以下 Pydantic 类中：class AnalysisAttributes(BaseModel): overal...</li><li><a href="https://github.com/langchain-ai/langserve/issues/618">RemoteRunnable 不返回来源，但 RunnableWithMessageHistory 可以 · Issue #618 · langchain-ai/langserve</a>：概述：我开发了一个用于问答的链，当作为独立的 Python 脚本运行时功能正常，能按预期返回来源。然而，当该脚本托管在...
</li>
</ul>

</div>
  

---


### **LangChain AI ▷ #[share-your-work](https://discord.com/channels/1038097195422978059/1038097372695236729/1242528634837794836)** (3 messages): 

- **使用 Upstage AI Solar 模型与你的 PDF 聊天**：查看这篇关于[创建 PDF 查询助手](https://medium.com/@sonam.gupta1105/creating-a-pdf-query-assistant-with-upstage-ai-solar-and-langchain-integration-6631280093b5)的博客文章。作者解释了他们如何利用即将推出的 **Upstage AI Solar LLM** 并将其与 **LangChain** 集成，以根据 PDF 回答问题。

- **使用 LangServe 简化 AWS 部署**：了解如何在*无需*登录 AWS 控制台或理解复杂的云技术（如 Terraform、Pulumi 或 AWS CDK）的情况下，在 AWS 上部署 LangServe 应用。阅读 [Medium](https://medium.com/aimonks/deploy-langserve-application-to-aws-2d34b6ee5c1a) 上的详细指南了解更多信息。

- **5 分钟内构建 Web 界面文档问答机器人**：直接从你的 GitHub 文档仓库，使用 LangChain、FastUI 和 Pluto **构建你自己的文档问答机器人**。在 [AWSTip 文章](https://awstip.com/craft-a-document-qa-assistant-for-your-project-in-just-5-minutes-cccf1002a0af)中查找分步流程。

**提及的链接**：<a href="https://medium.com/@sonam.gupta1105/creating-a-pdf-query-assistant-with-upstage-ai-solar-and-langchain-integration-6631280093b5">使用 Upstage AI Solar 和 LangChain 集成创建 PDF 查询助手</a>：你是否曾因需要阅读大量的研究论文而感到不知所措？作为一个刚完成博士学位的人，我知道这并不容易……

  

---

### **OpenInterpreter ▷ #[general](https://discord.com/channels/1146610656779440188/1147665339266650133/1242415938658238555)** (23 条消息🔥): 

- **讨论开发设置：** 成员们讨论了 Open Interpreter 如何访问和审查他们的文件系统，具体的设置涉及 Boox E Ink 平板（用于阅读和记笔记）、OneNote（用于键入笔记）以及 VSCode（用于开发）。一位成员表示：*"一个典型的用例是从一个源发送‘链接’来引用另一个源。"*
  
- **Open Interpreter 的日常使用与复杂问题：** 一位成员询问其他人每天如何使用 Open Interpreter，寻求成功案例，特别是在桥接不同设备方面。他们提到使用它直接针对代码或论文提问，而无需切换到浏览器。

- **GPT-4o 集成问题：** 成员们分享了在 Open Interpreter 中设置 GPT-4o 的经验和问题，包括与 API keys 相关的错误消息。一位成员指出 GPT-4o 的速度明显更快，*"至少快了 5 倍。"*

- **模型中的文本格式问题：** 一位成员报告了 Gemini 1.5 和 Gemini Flash 等模型在代码块中插入不必要的换行符的问题，这会影响代码执行。他们还询问缺失 "python" 声明是否也是问题的一部分。

- **对 AI 立法的担忧：** 链接指向了加利福尼亚州一项备受争议的 AI 法案，引发了成员们的担忧。该法案涉及 AI 前沿模型（frontier models）的负责任开发，一位成员强调了一位立法者发布的[公开信](https://x.com/Scott_Wiener/status/1792572175116816853)，旨在解决误解。
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://x.com/Scott_Wiener/status/1792572175116816853">来自参议员 Scott Wiener (@Scott_Wiener) 的推文</a>: 最近几周，网上关于 SB 1047（我关于负责任开发最大、最强大 AI 前沿模型的法案）有很多讨论。我们听到了一些非常深刻的思考...</li><li><a href="https://github.com/OpenInterpreter/01">GitHub - OpenInterpreter/01: 开源语言模型计算机</a>: 开源语言模型计算机。通过在 GitHub 上创建账户来为 OpenInterpreter/01 的开发做出贡献。
</li>
</ul>

</div>
  

---


### **OpenInterpreter ▷ #[ai-content](https://discord.com/channels/1146610656779440188/1149229778138824765/1242874145943846972)** (2 条消息): 

- **比尔·盖茨展望更智能的 AI 界面：** 在[比尔·盖茨的一篇文章](https://www.gatesnotes.com/AI-agents)中，他讨论了当前的软件虽然有所改进，但在跨不同应用集成任务方面仍然有限。盖茨预测未来设备将能够根据日常语言的单一指令理解并执行任务，类似于亲密朋友提供的协助。

- **绕过 macOS ChatGPT 应用等待名单：** [Twitter](https://x.com/testingcatalog/status/1793347117458636981) 上分享了一个跳过 ChatGPT macOS 应用等待名单的变通方法。步骤包括在登录过程中把握时机执行 CMD+Q 命令，以获得立即访问权限。
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://www.gatesnotes.com/AI-agents">AI 即将彻底改变你使用电脑的方式 | 比尔·盖茨</a>: 未找到描述</li><li><a href="https://x.com/testingcatalog/status/1793347117458636981">来自 TestingCatalog News 🗞 (@testingcatalog) 的推文</a>: 事实证明，你可以通过这种方式轻松绕过 macOS ChatGPT 应用的等待名单：1. 启动应用并登录 2. 在窗口改变大小但尚未出现登录警报之前按下 CMD+Q。3. 启动...
</li>
</ul>

</div>
  

---

### **tinygrad (George Hotz) ▷ #[general](https://discord.com/channels/1068976834382925865/1068976834928193609/1242947436905893970)** (7 条消息): 

- **无需在三角函数上重复造轮子**：一位参与者表达了对“试图重新发明已经存在的东西”的担忧，特别是关于 Taylor series 及其在特定点周围的局限性。

- **建议替代的区间约减方案**：另一点强调了将范围约减到 [0, pi/2] 的随意性，指出也可以是 [0, pi/4]，但强调这并不能解决以最小计算量实现完美精度的核心问题。

- **IBM 对区间划分的实用方法**：提到实际实现通常涉及划分区间（如 [0, pi/2]）以寻找完美的近似值，并强调这已经是一个解决过的问题。

- **分享 IBM 的正弦函数实现**：分享了一个 [IBM 的 sine 函数实现](https://sourceware.org/git/?p=glibc.git;a=blob_plain;f=sysdeps/ieee754/dbl-64/s_sin.c;hb=HEAD)，并指出实现完美精度所需的努力取决于所涉及的具体类型。

- **范围约减的复杂性及解决方案**：分享了[另一个处理范围约减问题的 IBM 实现](https://sourceware.org/git/?p=glibc.git;a=blob_plain;f=sysdeps/ieee754/dbl-64/branred.c;hb=HEAD)链接，指出虽然过程复杂，但仅对非常大的数字是必要的，通常不会降低速度。
  

---


### **tinygrad (George Hotz) ▷ #[learn-tinygrad](https://discord.com/channels/1068976834382925865/1070745817025106080/1242819347806818375)** (10 条消息🔥): 

- **像专家一样在 tinygrad 中追踪梯度**：在 tinygrad 中，你可以使用 `with Tensor.train():` 开始追踪梯度，或者设置 `Tensor.no_grad = True/False` 在代码运行中停止/开始梯度追踪。来自 [GitHub 仓库的一个有用示例](https://github.com/tinygrad/tinygrad/blob/d12d412e8b0c900681e9d6c39e46c6e1594c2dcc/examples/beautiful_cartpole.py#L58)展示了其用法。

- **在 tinygrad 中手动设置训练模式**：澄清了 `Tensor.train` 装饰器在底层只是设置了 `Tensor.training`。你可以根据需要手动设置 `Tensor.training`，如这段 [代码片段](https://github.com/tinygrad/tinygrad/blob/d12d412e8b0c900681e9d6c39e46c6e1594c2dcc/tinygrad/tensor.py#L83) 所示。

- **`no_grad` 的装饰器**：推理模式有一个装饰器版本 `Tensor.inference_mode()`，其作用类似于 `no_grad`。这为临时禁用梯度追踪提供了更简洁的语法。

- **理解 movement op 优化**：讨论了链式 movement ops 的行为，并指出多个 view 虽然罕见，但在特定组合下是可能的。例如，使用 `ShapeTracker.from_shape((3, 4)).permute((1, 0)).reshape((3, 4))` 可能会导致多个 view。
<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://github.com/tinygrad/tinygrad/blob/d12d412e8b0c900681e9d6c39e4">GitHub - tinygrad/tinygrad at d12d412e8b0c900681e9d6c39e46c6e1594c2dcc</a>: 你喜欢 pytorch？你喜欢 micrograd？你会爱上 tinygrad！❤️  - GitHub - tinygrad/tinygrad at d12d412e8b0c900681e9d6c39e46c6e1594c2dcc</li><li><a href="https://github.com/tinygrad/tinygrad/blob/d12d412e8b0c900681e9d6c39e46c6e1594c2dcc/examples/beautiful_cartpole.py#L58">tinygrad/examples/beautiful_cartpole.py at d12d412e8b0c900681e9d6c39e46c6e1594c2dcc · tinygrad/tinygrad</a>: 你喜欢 pytorch？你喜欢 micrograd？你会爱上 tinygrad！❤️  - tinygrad/tinygrad</li><li><a href="https://github.com/tinygrad/tinygrad/blob/d12d412e8b0c900681e9d6c39e46c6e1594c2dcc/examples/beautiful_cartpole.py#L82">tinygrad/examples/beautiful_cartpole.py at d12d412e8b0c900681e9d6c39e46c6e1594c2dcc · tinygrad/tinygrad</a>: 你喜欢 pytorch？你喜欢 micrograd？你会爱上 tinygrad！❤️  - tinygrad/tinygrad</li><li><a href="https://github.com/tinygrad/tinygrad/blob/d12d412e8b0c900681e9d6c39e46c6e1594c2dcc/tinygrad/tensor.py#L83">tinygrad/tinygrad/tensor.py at d12d412e8b0c900681e9d6c39e46c6e1594c2dcc · tinygrad/tinygrad</a>: 你喜欢 pytorch？你喜欢 micrograd？你会爱上 tinygrad！❤️  - tinygrad/tinygrad
</li>
</ul>

</div>

### **DiscoResearch ▷ #[general](https://discord.com/channels/1178995845727785010/1182877486854451271/1242451432444006400)** (12 messages🔥): 

- **Supervised Fine-Tuning vs Preference Optimization**：在讨论 **Supervised Fine-Tuning (SFT)** 与 **Preference Optimization** 的根本区别时，一位成员指出，“SFT 提升了模型中 SFT 数据集数据点的概率分布”，而偏好优化还会降低非理想输出的概率。他们质疑，既然偏好优化看起来更全面，为什么还要排他性地使用 SFT。

- **Phi3 Vision 凭借 4.2b 参数表现惊艳**：一位成员分享了对 **Phi3 Vision** 的兴奋之情，该模型仅有 42 亿参数，并将其描述为图像流低延迟/实时推理的突破。*“想象一下，更小或更专业的版本将在机器人领域实现什么，”* 他们补充道 ([链接](https://x.com/jphme/status/1792950682695479734))。

- **Moondream2 与 Phi3 Vision 的对比**：成员们对比了 **Moondream2** 和 **Phi3 Vision** 在图像任务上的表现。有人指出，“Vik 试图减少幻觉。某些数据集在这方面表现较差。” ([Moondream2](https://huggingface.co/spaces/vikhyatk/moondream2))。

- **微软发布新模型**：微软发布新的 **7b** 和 **14b** Instruct 模型的公告引发了复杂反应。一位成员指出 14b 指令版本的德语表现不佳，而另一位成员则强调了它在抽取式任务和复杂推理方面的潜力。

- **对 Meta 400b 模型传闻的担忧**：一位成员对 **Meta 可能不会开源 400b 模型** 的传闻表示关注。他们注意到大多数讨论都引用了一个名为 Jimmy 的不可靠来源。

<div class="linksMentioned">

<strong>提及的链接</strong>：

<ul>
<li>
<a href="https://huggingface.co/spaces/vikhyatk/moondream2">moondream2 - a Hugging Face Space by vikhyatk</a>：未找到描述</li><li><a href="https://x.com/jphme/status/1792950682695479734">来自 Jan P. Harries (@jphme) 的推文</a>：Phi3 vision 刚刚发布 - 仅有 4.2b 参数且非常令人印象深刻。🤩 我觉得这是图像流低延迟/实时推理的一个突破 - 想象一下更小的模型会...
</li>
</ul>

</div>
  

---



### **Cohere ▷ #[general](https://discord.com/channels/954421988141711382/954421988783444043/1242590720175378512)** (8 messages🔥): 

- **加入 Cohere 团队**：一位成员兴奋地分享了 [Cohere 招聘页面链接](https://cohere.com/careers)，鼓励他人申请。他们强调公司专注于利用前沿的 ML/AI 技术解决现实世界的问题。
- **链接访问困惑**：有人提到在尝试访问提供的 Cohere 招聘链接时找不到页面。
- **LLM 模型 VRAM 占用**：一位成员分享了 Hugging Face 上的 [LLM-Model-VRAM-Calculator](https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator) 链接，并询问为什么在相同上下文长度下，Phi 3 Mini 比 Phi 3 Medium 占用更多 VRAM。
- **BotPress 集成 Command-R**：一位用户寻求关于如何将 Command-R 整合到 BotPress 的教程，并分别用英语和西班牙语寻求帮助。

<div class="linksMentioned">

<strong>提及的链接</strong>：

<ul>
<li>
<a href="https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator">LLM Model VRAM Calculator - a Hugging Face Space by NyxKrage</a>：未找到描述</li><li><a href="https://cohere.com/careers">Careers</a>：我们的 ML/AI 专家团队热衷于帮助开发者解决现实世界的问题。在多伦多、伦敦和帕洛阿尔托的办公室，我们工作在机器学习的最前沿，以开启...
</li>
</ul>

</div>
  

---


### **Cohere ▷ #[project-sharing](https://discord.com/channels/954421988141711382/1218409701339828245/1242870724708929688)** (1 messages): 

```html
- **寻求 BotPress 的 Command-R 教程**：一位成员询问是否有关于如何将 **Command-R** 整合到 **BotPress** 的教程。他们用英语和西班牙语重复了这一请求："Does anyone have a tutorial on how to incorporate Command-R into BotPress? Alguien tiene un tutorial de como incorporar Command-R en BotPress?"
```
  

---


### **Cohere ▷ #[collab-opps](https://discord.com/channels/954421988141711382/1218409745380147320/1242870740345294998)** (1 messages): 

- **寻求 BotPress 的 Command-R 教程**：一位成员询问是否有人拥有将 **Command-R** 整合到 **BotPress** 的教程。他们用 **英语和西班牙语** 寻求资源或指导。

### **AI Stack Devs (Yoko Li) ▷ #[ai-companion](https://discord.com/channels/1122748573000409160/1122788693950857238/1242531297750941899)** (7 条消息): 

- **AI Waifus 拯救生命**：一位用户幽默地宣称 *"AI waifus save lives!"*，引发了成员间的简短调侃，另一位成员回复道 *"Just monika."*
- **VentureBeat 关于情感 AI 的文章**：一位成员分享了一篇 **VentureBeat 文章**，讨论了在商业机器人中嵌入情感 AI 的计划，并提出疑问：*"waifus 很快就能‘理解’并处理情感了吗？"* 点击[此处](https://venturebeat.com/ai/exclusive-inflection-ai-reveals-new-team-and-plan-to-embed-emotional-ai-in-business-bots)阅读文章。
- **4Wall AI 的 3D 角色聊天机器人**：另一位成员提到他们正在 **4Wall AI** 开发 **3D 角色聊天机器人**，并宣传了在另一个频道 <#1122748840819306598> 发布的预告片。
- **回复：Just Monika**：针对关于 "Just Monika" 梗的提问 *“Who dat?”*，一位用户提供了背景信息的 GIF 链接，详见[此处](https://tenor.com/view/ddlc-doki-doki-literature-club-just-monika-monika-gif-20717242)。

**提到的链接**：<a href="https://tenor.com/view/ddlc-doki-doki-literature-club-just-monika-monika-gif-20717242">Ddlc Doki Doki Literature Club GIF - Ddlc Doki Doki Literature Club Just Monika - Discover &amp; Share GIFs</a>：点击查看 GIF

  

---



### **Datasette - LLM (@SimonW) ▷ #[ai](https://discord.com/channels/823971286308356157/1097032579812687943/1242549498220122203)** (5 条消息): 

- **高通发布适用于 Windows 的 Snapdragon 开发套件**：高通发布了一款全新的开发套件，搭载了其最强大的 Snapdragon X Elite 芯片，售价为 899.99 美元。它被宣传为 Mac Mini 的竞争对手，配备 32GB LPDDR5x RAM、512GB NVMe 存储和多个端口，是长续航、高性能 Arm 芯片 Windows 笔记本电脑的理想选择 [更多详情见 The Verge](https://www.theverge.com/2024/5/21/24158603/qualcomm-windows-snapdragon-dev-kit-x-elite)。

- **对 Windows 开发套件定价的抱怨**：一位用户对新款 Snapdragon 开发套件表示感兴趣，但认为 900 美元的价格过高，尤其是与去年 600 美元的型号相比。他们指出其 32GB RAM 和 512GB 存储非常适合 Arm 开发以及各种开发人员的工作负载 [更多详情](https://www.microsoft.com/en-us/d/windows-dev-kit-2023/94k0p67w7581?activetab=pivot:overviewtab)。

- **使用 Mac Mini 作为 Llamafile 服务器**：一位用户分享了使用 Mac Mini 作为长期运行的 Llamafile 服务器的积极体验，可通过 Tailscale 访问。他们非常欣赏其零冷启动特性以及与 `llm` CLI 的兼容性。

- **期待更实惠、更美观的开发套件**：另一位用户希望未来能有更便宜的型号，并表达了对半透明外壳设计的向往。

- **与 Claude 的 Smalltalk 实验**：一位用户分享了一个概念验证示例，展示了 Claude 进行闲聊（Smalltalk）的能力，通过对“什么是青蛙？”这一问题给出关于两栖动物的基础解释。
<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://www.theverge.com/2024/5/21/24158603/qualcomm-windows-snapdragon-dev-kit-x-elite">这是用于 Windows on Arm 实验的八英寸 Snapdragon PC</a>：高通正在销售黑色版本。</li><li><a href="https://www.theverge.com/2024/5/21/24158603/qualcomm-windows-snapdragon-dev-kit-x-e">这是用于 Windows on Arm 实验的八英寸 Snapdragon PC</a>：高通正在销售黑色版本。</li><li><a href="https://www.microsoft.com/en-us/d/windows-dev-kit-2023/94k0p67w7581?activetab=pivot:overviewtab">在 Microsoft Store 购买适用于 Arm 应用开发者的 Windows Dev Kit 2023 台式机</a>：使用 Windows Dev Kit 2023 构建、调试和测试适用于 Arm 的原生 Windows 应用，这是一款专为开发人员工作负载设计的紧凑型台式电脑。
</li>
</ul>

</div>
  

---



### **LLM Perf Enthusiasts AI ▷ #[general](https://discord.com/channels/1168579740391710851/1168579740391710855/1242577685906063431)** (2 条消息): 

- **Llama3/Phi3 截断响应**：一位成员寻求帮助，询问如何防止 **llama3/phi3** 出现 "*additional items omitted for brevity*"（为了简洁起见，省略了额外项）的情况。目前尚未有进一步的讨论或解决方案。

### **Mozilla AI ▷ #[announcements](https://discord.com/channels/1089876418936180786/1089876419926032396/1242640452038037535)** (1 条消息): 

- **成员组织的活动启动**：首批**成员组织的活动**包括演讲、AMA、演示和讨论。这些活动旨在促进思想交流并增强社区参与度。

- **LLM360 主持 AMA**：[LLM360](https://www.llm360.ai/) 以一场[重点介绍其在开源 LLM 领域工作的 AMA](https://discord.com/events/1089876418936180786/1240722407594004561) 开启了该系列活动。

- **Kate Silverstein 的演示和博客文章**：主任机器学习工程师 Kate Silverstein 将分享一个[使用 llamafile 进行 embeddings 的演示](https://discord.com/events/1089876418936180786/1242590711778381914)，并聊聊她[最近的博客文章](https://discord.com/channels/1089876418936180786/1242235316170129439)。

- **活动日历**：鼓励成员定期*深入查看*活动日历，以了解更多活动信息和参与社区活动的机会。
  

---


### **Mozilla AI ▷ #[llamafile](https://discord.com/channels/1089876418936180786/1182689832057716778/1242844126941155359)** (1 条消息): 

- **澄清 Python 示例中的模型用法**：一位成员询问在终端运行 tinyllama 模型时，是否需要在 `model="LLaMA_CPP"` 下指定模型。他们提供了一个代码片段，并提到代码可以运行，但不确定使用的是哪个模型。

**提到的链接**：<a href="http://<Your">未找到标题</a>：未找到描述

  

---



---



---




{% else %}

> 完整的频道细分内容已在邮件中截断。
> 
> 如果您想查看完整细分，请访问此邮件的网页版：[{{ email.subject }}]({{ email_url }})！
>
> 如果您喜欢 AInews，请[分享给朋友](https://buttondown.email/ainews)！预先感谢！

{% endif %}