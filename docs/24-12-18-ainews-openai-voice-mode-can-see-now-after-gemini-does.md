---
companies:
- openai
- google-deepmind
- anthropic
- togethercompute
- scale-ai
- meta-ai-fair
- mistral-ai
date: '2024-12-18T09:46:07Z'
description: '**OpenAI** 在 **Gemini** 之后不久推出了**实时视频 (Realtime Video)** 功能，但由于 Gemini
  发布更早、成本更低且速率限制更少，导致 OpenAI 的功能影响力相对较小。**Google DeepMind** 发布了 **Gemini 2.0 Flash**，其特点是增强的多模态能力和实时流媒体功能。**Anthropic**
  推出了 **Clio**，这是一个用于分析 **Claude** 模型实际使用情况的系统。**Together Computing** 收购了 CodeSandbox，旨在推出一款代码解释器工具。


  社区讨论重点关注了 **Meta 的 Llama 3.3-70B**，称赞其先进的角色扮演和提示词处理能力，在表达力和规避审查方面优于 **Mistral Large**
  和 **GPT-4o** 等模型。AI 社区还针对 AI 宕机和模型竞争进行了幽默的调侃，同时 **ChatGPT** 增加了“圣诞老人模式”以进行节日互动。社区中一个引人注目的观点是：*“Anthropic
  正在占领开发者生态系统，Gemini 赢得了 AI 爱好者的关注，而 ChatGPT 则统治着 AI 浅尝辄止者。”*'
id: 3351b790-b00d-40d0-814f-04f641efa8ba
models:
- gemini-2.0-flash
- claude
- claude-3.5-sonnet
- llama-3-70b
- llama-3
- mistral-large
- gpt-4o
original_slug: ainews-openai-voice-mode-can-see-now-after-gemini
people:
- bindureddy
title: 继 Gemini 之后，OpenAI 语音模式现在也具备视觉功能了。
topics:
- multimodality
- real-time-streaming
- roleplay
- prompt-handling
- model-comparison
- model-training
- creative-writing
- model-censorship
- code-execution
- developer-ecosystem
- ai-humor
---

<!-- buttondown-editor-mode: plaintext -->**率先发布就是一切 (Shipping first is all you need)。**

> 2024/12/11-2024/12/12 AI 新闻。我们为您检查了 7 个 subreddits、[**433** 个 Twitter 账号](https://twitter.com/i/lists/1585430245762441216) 和 **31** 个 Discord（**207** 个频道和 **6137** 条消息）。预计节省阅读时间（以 200wpm 计算）：**616 分钟**。您现在可以标记 [@smol_ai](https://x.com/smol_ai) 进行 AINews 讨论！

OpenAI 在[比预期晚一天后发布了 Realtime Video](https://openai.com/12-days/?day=6)，但其反响较小，因为 Gemini 抢先一步到达，且成本更低，速率限制（rate limiting）更少。


![image.png](https://assets.buttondown.email/images/27ba577f-cb84-49d0-bf28-2d6cc5dc6617.png?w=960&fit=max)


[舆论](https://x.com/mckaywrigley/status/1866930933842186427?s=46) 依然坚定地支持 Gemini：


![image.png](https://assets.buttondown.email/images/24e03295-4c8a-49b9-bf19-55c76a26ddb0.png?w=960&fit=max)


我们很高兴看到这些无疑是 SOTA 级别、非常努力的团队之间进行[一些友好的“互怼”](https://x.com/clmt/status/1867334655671783901?s=46)。

---


{% if medium == 'web' %}


**目录**

[TOC] 

{% else %}

**目录**和**频道总结**已移至此邮件的网页版：[{{ email.subject }}]({{ email_url }})！

{% endif %}


---

# AI Twitter 回顾

> 所有总结由 Claude 3.5 Sonnet 完成，取 4 次运行中的最佳结果。

以下是根据 Twitter 讨论整理的关键主题：

**AI 模型发布与更新**

- Google 发布了 **Gemini 2.0 Flash**，在多模态能力、实时流媒体和性能指标方面有重大改进。[@GoogleDeepMind 指出](https://twitter.com/GoogleDeepMind/status/1867299131632628065) 开发者现在可以使用实时音频/视频流。
- **OpenAI** [宣布了 ChatGPT 的视频功能](https://twitter.com/OpenAI/status/1867293000348631333)，包括 Advanced Voice mode 中的实时视频和屏幕共享。
- **Anthropic** [发布了关于 Clio 的研究](https://twitter.com/AnthropicAI/status/1867325190352576780)，这是一个用于分析 Claude 在不同语言和用例下的真实使用模式的系统。

**AI 基础设施与开发**

- [@bindureddy 观察到](https://twitter.com/bindureddy/status/1867110462581510408)，“Anthropic 正在占领开发者生态系统，Gemini 拥有 AI 爱好者的心智份额，而 ChatGPT 则统治着 AI 浅尝辄止者”。
- [Together Computing 收购了 CodeSandbox](https://twitter.com/togethercompute/status/1867233391935951356)，以推出 Together Code Interpreter，实现无缝的代码执行。
- [@teortaxesTex 指出](https://twitter.com/teortaxesTex/status/1867292159415636443)，放弃 Attention 机制意味着失去依赖它的几项关键能力。

**行业与市场动态**

- **Scale AI** 和 TIME 杂志推出了 [TIME AI 用于年度人物报道](https://twitter.com/alexandr_wang/status/1867255878141063312)。
- [@far__el 讨论了](https://twitter.com/far__el/status/1867113586230751240) 美国和中国 AI 能力之间的比较，认为差距可能比普遍认为的要小。

**梗与幽默**

- [ChatGPT 添加了圣诞老人模式](https://twitter.com/OpenAI/status/1867272686751428920) 用于节日对话。
- 关于 AI 宕机和服务中断的多个笑话。
- 关于模型比较和行业竞争的幽默看法。

---

# AI Reddit 回顾

## /r/LocalLlama 回顾

**主题 1. Meta 的 Llama 3.3-70B：角色扮演与 Prompt 处理的卓越表现**

- **[[为什么 Llama 3.3-70B 如此擅长根据 system prompt 扮演角色（甚至在未明确要求的情况下进入 roleplay）]](https://www.reddit.com/gallery/1hcl5oh)** ([Score: 311, Comments: 83](https://reddit.com/r/LocalLLaMA/comments/1hcl5oh/why_is_llama_3370b_so_immediately_good_at/)): **Llama 3.3-70B** 因其在根据 system prompt 采用特定人格和参与 roleplay 方面的精通而受到认可，即使在没有明确要求 roleplay 的情况下也是如此。这突显了其有效解释和响应细微 prompt 的高级能力。
  - **Roleplay 与创意写作**: **Llama 3.3-70B** 的 roleplay 能力备受关注，示例显示它能有效刻画 **Yoda 和 Jar Jar Binks** 等角色。一些用户注意到它在 roleplay 中的创意潜力，尽管它仍面临重复和回答简短等问题，特别是在 quantized 版本中。
  - **与其他模型的比较**: 讨论将 **Llama 3.3** 与 **Mistral Large** 和 **GPT-4o** 等其他模型进行了对比，一些用户指出 **Llama 3.3** 表现力更强且审查更少。该模型采用人格的能力归功于其训练，可能受到 **Meta** 的 **AI Studio** 以及来自 **Facebook** 和 **Instagram** 等平台的多元数据的影响。
  - **训练与审查**: 社区推测，由于 **Meta** 的战略目标，**Llama 3.3** 在训练时重点关注了 roleplay 和角色刻画，而不像 **OpenAI** 的模型那样受到严格审查。用户讨论了 **Meta** 的训练方法和数据策选如何促成了 **Llama 3.3** 先进的 roleplay 能力，一些人将其成功归因于缺乏 fine-tuning 约束和多样化的训练数据。


**主题 2. Microsoft 的 Phi-4：小模型，大 Benchmark 结果，怀疑依然存在**

- **[[介绍 Phi-4：Microsoft 最新的专注于复杂推理的小型语言模型]](https://techcommunity.microsoft.com/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090)** ([Score: 217, Comments: 86](https://reddit.com/r/LocalLLaMA/comments/1hd0y5j/introducing_phi4_microsofts_newest_small_language/)): **Microsoft** 推出了 **Phi-4**，这是一款旨在专注于复杂推理任务的新型小型语言模型（SLM）。该帖子未提供有关该模型能力或应用的更多细节或背景。
  - 许多用户对 **Phi** 系列模型表示怀疑，称其在 benchmark 上表现良好，但在实际应用中表现不佳。据推测，**Synthetic training datasets**（合成训练数据集）是 **Microsoft** 的关注重点，可能用于授权给其他公司作为抓取数据的替代方案。
  - 关于 **14B** 参数模型被视为“小模型”的讨论充满幽默感，用户指出这需要大量的 **GPU** 资源。**Phi-4** 的 benchmark 结果令人印象深刻，但由于以往对 **Phi-3** 的经验，用户仍保持谨慎。
  - 一些评论提到 **Phi-4** 将于下周在 **Hugging Face** 上线，并有人暗示早期关于 **Phi-3** 的帖子是试图制造噱头。训练中使用的 **synthetic data** 受到关注，特别是针对数学补全等任务。


- **[[兄弟，什么情况？？]](https://i.redd.it/npjopxbhsi6e1.png)** ([Score: 81, Comments: 38](https://reddit.com/r/LocalLLaMA/comments/1hd16ev/bro_wtf/)): 与 **Phi-3, Qwen 2.5, GPT, 和 Llama-3.3** 等其他模型相比，**Phi-4** 在 benchmark 中展现了极具前景的性能，评估使用的是 **OpenAI** 的 **SIMPLE-EVALS** 框架。表格将结果分为“小模型”和“大模型”，详细列出了 **MMLU, GPQA, 和 MATH** 等指标。
  - **Phi-4 的性能**: 虽然 **Phi-4** 显示出令人期待的 benchmark 结果，但用户对其现实世界的适用性表示怀疑，并指出以往 **Phi** 模型在受控测试之外往往表现不佳。共识是，尽管推理能力不错，但由于数据集较小，该模型在处理事实性数据时比较吃力。
  - **开源与 Synthetic Data**: 讨论强调了开源领域的进展，一些用户注意到 **Phi-4** 在某些测试中有潜力超越 **GPT-4o mini**。关于 **synthetic data** 与广泛互联网数据的有效性也存在争论，一些用户主张使用高质量的 **synthetic data** 以获得更好的模型训练效果。
  - **模型可用性与使用**: 该模型预计将在 **Hugging Face** 上提供，目前可从 **Azure** 下载，尽管用户反映下载速度较慢。一些用户分享了他们使用之前 **Phi** 模型的经验，强调了它们在推理和单轮交互等特定任务中的效用，尽管它们比较啰嗦且在多轮对话中效果较差。


**主题 3. OpenAI o1 vs Claude 3.5 Sonnet：订阅大对决**

- **OpenAI o1 vs Claude 3.5 Sonnet：哪款模型最物超所值？** ([Score: 139, Comments: 78](https://reddit.com/r/LocalLLaMA/comments/1hcngb7/openai_o1_vs_claude_35_sonnet_which_gives_the/))：**OpenAI 的 o1** 在复杂推理和数学方面表现出色，在 20 美元档位中超越了其他模型，是处理非编程任务的理想选择。**Claude 3.5 Sonnet** 在编程方面更胜一筹，尽管每周有 50 条消息的限制，但在速度和准确性之间提供了更好的平衡。**Claude** 以其迷人的个性著称，而 **o1** 则以高 IQ 被认可，这使得 **Claude** 更适合编程和对话任务，而 **o1** 更适合数学和推理。
  - 用户讨论了不同模型的性价比，**1M input tokens** 价格为 **$15**，**output tokens** 为 **每 1M $60**，对定价结构表示担忧。一些人建议使用 **openrouter** 或 **OpenWebUI**，以便在无需订阅费用的情况下灵活选择模型。
  - **Claude** 因其编程能力和迷人的个性而受到青睐，尽管一些用户报告了代码中的幻觉和过于一致的回答问题，而另一些人则认为它在快速解决复杂软件 Bug 方面不可或缺。**o1** 因过于顺从（overly agreeable）而受到批评，这使得它在某些任务中效果较差。
  - **Gemini 2.0** 和 **Qwen 系列** 获得了积极评价；**Gemini** 因其速度和免费而受到关注，而 **Qwen** 在非编程任务上比 **o1** 更受青睐。普遍观点认为，使用 API 并避免订阅可能更高效且更具成本效益。


**主题 4. Gemini 系列在数学基准测试中表现亮眼，认知声誉不断提升**

- **[U-MATH：全新的大学级数学基准测试；Gemini 是 GOAT / Qwen 是王者](https://www.reddit.com/gallery/1hcpbdz)** ([Score: 74, Comments: 21](https://reddit.com/r/LocalLLaMA/comments/1hcpbdz/umath_new_unilevel_math_benchmark_gemini_is_goat/))：**Gemini** 和 **Qwen** 因在 **U-MATH**（一个新的大学级数学基准测试）中的卓越表现而受到关注。帖子指出，在这种背景下，**Gemini** 被认为是史上最强（GOAT），而 **Qwen** 则被公认为领先者。
  - **Gemini 的表现**：**Gemini** 在包括 **U-MATH**、**LiveBench** 和 **FrontierMath** 在内的各种基准测试中被一致公认为表现最好的模型，超越了 **GPT-4o** 和 **Claude** 等其他模型。据推测，**Google** 通过 **AlphaZero**、**AlphaFold** 和 **AlphaProof** 等项目对数学和科学的专注为 **Gemini** 的成功做出了贡献。
  - **模型对比与挑战**：讨论强调了像 **7b-Math** 这样的小型模型令人印象深刻的表现，它们紧追 **72b-Instruct** 等大型模型。然而，小型模型在理解上下文线索和“指令遵循（instructions following）”方面存在困难，经常导致幻觉，正如在 **Qwen** 模型中所观察到的那样。
  - **基准测试详情与更新**：**U-MATH** 和 **μ-MATH** 基准测试是仅有的在此复杂度水平上测试 **LLM** 的测试，**Gemini Pro** 在解题和判断能力方面领先，尽管 **GPT/Claude/Gemini Flash** 等其他模型的幻觉率较低。**leaderboard** 和 **HuggingFace** 链接提供了关于这些评估的更多见解。


## 其他 AI 子版块回顾

> r/machinelearning, r/openai, r/stablediffusion, r/ArtificialInteligence, /r/LLMDevs, /r/Singularity

**主题 1. NeurIPS 2024 破坏指控扰乱研究**

- **[D] NeurIPS 2024 Best Paper Award 获得者破坏了其他团队** ([Score: 327, Comments: 31](https://reddit.com/r/MachineLearning/comments/1hctf36/d_the_winner_of_the_neurips_2024_best_paper_award/)): **NeurIPS 2024 Best Paper Award** 争议涉及对一名 ByteDance 研究员的指控，称其涉嫌破坏其他团队的研究以获取优势。指控包括该研究员参加会议以调试同事的代码，从而保持竞争优势，并有人呼吁撤回其论文。更多细节可以在 [integrity report](https://var-integrity-report.github.io/) 中找到。
  - **针对 Keyu Tian 的指控**：**Keyu Tian** 据称修改了 **PyTorch source code**，并通过入侵集群和创建登录后门来干扰训练过程，这使他能够通过更改模型权重和终止进程来破坏同事的实验。这导致了大规模的实验失败，引发了对其行为诚信的担忧。
  - **法律和机构反应**：据报道，**ByteDance** 正在起诉 Tian 索赔，这可能会影响他的 **NeurIPS 2024 Best Paper Award**。人们猜测这一事件可能对其学术和职业地位产生影响，并质疑 NeurIPS 是否有会影响其奖项的行为准则。
  - **文化和竞争背景**：一些评论者强调了中国学术界内部激烈的竞争压力，这可能会促使个人采取极端行动来获取资源和认可。这种背景可能解释（尽管不能证明其合理性）这种指控的行为，反映了该领域更广泛的系统性问题。


**Theme 2. Controversial 'Stop Hiring Humans' Campaign in SF**

- **[旧金山到处都是 "Stop Hiring Humans" 广告](https://www.reddit.com/gallery/1hco4y4)** ([Score: 237, Comments: 79](https://reddit.com/r/OpenAI/comments/1hco4y4/stop_hiring_humans_ads_all_over_sf/)): **"Stop Hiring Humans"** 广告已投放在整个 **San Francisco**，引发了广泛关注和讨论。该活动极具挑衅性的信息暗示了向自动化和 AI 驱动解决方案的转变，引发了关于以技术为中心的城市中人类就业未来的疑问。
  - 许多评论者（如 **XbabajagaX** 和 **dasjati**）指出，该广告活动的挑衅性质是获取关注和免费媒体曝光的战略举措，强调了其在引发广泛讨论和媒体报道方面的成功。[活动分析链接](https://smartcontentreport.com/artisan-controversial-campaign/)。
  - 包括 **heavy-minium** 和 **umotex12** 在内的讨论批评了该活动对 AI 能力的误导性声明，认为这可能会使公众对真正的 AI 进步感到麻木，或过早地加速关于 AI 的社会对话。
  - **AI_Ship** 和 **Secure-Summer2552** 等评论者指出，考虑到 **San Francisco** 明显的社会问题（如无家可归者），这些广告具有反乌托邦色彩且缺乏同理心，将其比作 **Black Mirror** 的一集，并建议 AI 应该支持而不是取代人类。


**Theme 3. ChatGPT's Santa Voice: Seasonal Gimmick or Revolutionary?**

- **[ChatGPT Advanced Voice Mode 增加了圣诞老人语音](https://v.redd.it/wxey2iusjg6e1)** ([Score: 128, Comments: 33](https://reddit.com/r/OpenAI/comments/1hcr6gu/chatgpt_advanced_voice_mode_adds_a_santa_voice/)): **ChatGPT** 推出了具有 **Santa Voice** 选项的 **Advanced Voice Mode**。
  - 用户对 **Santa Voice** 功能的反应不一；有些人觉得它很有趣且具有季节性，而另一些人则遇到了问题，例如难以切换回标准语音，或者由于摄像头激活而觉得该功能令人毛骨悚然。**surfer808** 提到了一次摄像头指示灯亮起且 **Santa Voice** 与他们互动的事件，引发了隐私担忧。
  - **Zulakki** 报告了一个技术问题，即 **Santa Voice** 最初可用但随后消失了，在尝试向家人演示时造成了不便。这表明该功能的可用性可能存在潜在的 Bug 或限制。
  - 关于**圣诞老人的国籍**有一场幽默的辩论，评论建议他来自 **UK**、**North Pole** 或 **Canada**，反映了对该功能实现及其文化影响的轻松看法。

- **OpenAI 12 天活动：第 6 天讨论帖** ([Score: 126, Comments: 241](https://reddit.com/r/OpenAI/comments/1hcqoxf/12_days_of_openai_day_6_thread/)): **OpenAI 的 12 天活动**在**第 6 天**推出了 **ChatGPT 的圣诞老人模式 (Santa mode)**，展示了结合视频的高级语音能力。直播讨论可通过 [OpenAI 官网](https://openai.com/12-days/) 和 [YouTube](https://www.youtube.com/watch?v=NIQDnWlwYyQ) 观看。
  - **高级语音模式 (Advanced Voice Mode) 与视频集成**：用户正在讨论在高级语音模式 (AVM) 中集成视频和屏幕共享功能，部分用户对 AVM 有效处理视频上下文的能力表示担忧。多条评论强调了在欧洲推出的延迟，并推测原因可能是容量问题而非法律限制。
  - **与 Google Gemini 的对比**：用户将 OpenAI 的发布与 **Google 的 Gemini 2.0** 进行对比，注意到 Gemini 的多模态能力和语音模式功能。一些用户认为 Google 在及时有效地发布功能方面处于领先地位，而另一些用户则对 OpenAI 潜在的未来更新（如传闻中的 **GPT-5** 发布）感到兴奋。
  - **用户体验与可访问性**：对于功能的可用性，用户的情绪交织着兴奋与沮丧，部分用户无法在所有设备或地区访问新功能。评论还提到了 ChatGPT 语音回复中被认为带有说教意味的语气，并建议进行更自然的交互。


**主题 4. OpenAI 的 12 天发布活动：AVM 中的视频功能**

- **OpenAI 为高级语音模式发布视频功能** ([Score: 105, Comments: 43](https://reddit.com/r/OpenAI/comments/1hcr3iw/openai_releases_video_to_advanced_voice_mode/)): **OpenAI** 在 **Gemini 发布**之际，为其**高级语音模式 (Advanced Voice Mode)** 引入了视频功能。
  - **OpenAI 的新功能**包括在**高级语音模式**中进行实时视频对话和屏幕共享，今天开始向 Teams 用户以及大多数 Plus 和 Pro 订阅者推出，而 Enterprise 和 Edu 用户将在明年年初获得访问权限。**“圣诞老人模式” (Santa mode)** 已在全球范围内支持 ChatGPT 语音模式的地区上线。
  - 关于**推出时间表**存在讨论，一些用户指出沟通中存在差异，因为 OpenAI 表示该功能将在“今天及下周内”推出，部分用户将其与之前功能发布的延迟进行了比较。
  - 用户对**可用性**感到好奇，一些人对欧洲地区的延迟访问表示沮丧，而另一些人则询问如何访问新功能，并提供了一个 YouTube 链接作为参考资源。


---

# AI Discord 摘要

> 由 O1-mini 生成的摘要之摘要的摘要

**主题 1. AI 模型对决：Gemini vs. Claude**

- [**Claude 在编程任务中占据主导地位**](https://www.codeium.com/changelog)：用户一致反馈 **Claude** 在编程准确性上优于 **Gemini 2.0**，巩固了其作为开发工作流首选的地位。
- [**Gemini 2.0 Flash 提升 AI 速度**](https://x.com/testingcatalog/status/1867251820986302787?s)：**Gemini 2.0 Flash** 因其提升的速度和性能而受到赞誉，尽管一些 Bug（如实时视频读取问题）仍在修复中。
- [**Project Astra 瞄准 OpenAI 的宝座**](https://www.theverge.com/2024/12/12/24319528/google-android-xr-samsung-project-moohan-smart-glasses)：**Project Astra** 作为 **OpenAI** 的强力竞争对手正受到关注，**Gemini 2.0** 的发布可能会重塑 AI 行业格局。

**主题 2. GPU 狂热：新品发布与黄牛之战**

- [**5090 GPU 发布引发期待**](https://www.codeium.com/changelog)：**5090 GPU** 定于 1 月初发布，拥有令人印象深刻的 **32GB VRAM**，有望大幅提升 AI 计算能力，引发了极大的期待。
- [**黄牛与网页爬虫争夺 GPU**](https://youtu.be/aV_xL88vcAQ?si=liMiC7spUMFY0LSF)：**GPU 黄牛**的兴起迫使用户采用**网页爬虫 (web scrapers)** 等策略，以便在高需求发布期间抢购心仪的显卡。
- [**Intel ARC B580 vs. Nvidia RTX 3060：战斗继续**](https://github.com/ROCm/composable_kernel/blob/develop/example/01_gemm/gemm_dl_fp16.cpp)：关于拥有 **12GB VRAM** 的 **Intel B580 GPU** 是否能超越流行的 **RTX 3060** 争论激烈，尽管人们对其 **CUDA** 支持仍有疑虑。

**主题 3. AI 工具动向：更新、Bug 与集成**

- [**Codeium 的 Windsurf Wave 1 发布**](https://www.codeium.com/changelog)：**Windsurf Wave 1** 推出了自主性升级，如 **Cascade Memories** 和自动化终端命令，通过 `.windsurfrules` 增强了 AI 交互。
- [**Aider 面临安装障碍**](https://aider.chat/docs/languages.html)：用户在全局安装 **Aider** 时遇到困难，在 OpenSSL 兼容性警告中找到了 `uv tool install aider-chat` 等替代方案。
- [**Cohere Go SDK 需要结构性修复**](mailto:support@cohere.com)：反馈指出 **Cohere Go SDK** 存在问题，特别是 `StreamedChatResponseV2` 字段，需要紧急进行结构调整以实现准确解析。

**主题 4. MLOps 奇迹：训练与优化创新**

- [**直接偏好优化登陆 Llama 3.3**](https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-bnb-4bit)：**DPO** 成功集成到 **Llama 3.3** 中，并配有完善的文档支持，为用户简化了微调过程。
- [**SPDL 提升 AI 训练效率**](https://ai.meta.com/blog/spdl-faster-ai-model-training-with-thread-based-data-loading-reality-labs/)：**SPDL** 利用**基于线程的数据加载 (thread-based data loading)** 显著缩短了 AI 模型训练时间，这对于 **Reality Labs** 的研究具有里程碑意义。
- [**训练雅可比分析揭示隐藏动态**](https://arxiv.org/abs/2412.07003)：一篇新论文深入研究了**训练雅可比 (training Jacobian)**，揭示了初始参数如何影响最终结果，并指出了将该分析扩展到更大网络时面临的挑战。

**主题 5. 社区催化剂：黑客松、AMA 会议与协作工具**

- [**LLM Agents MOOC 黑客松截止日期临近**](https://forms.gle/9u6HdVCWXgws16go9)：**LLM Agents MOOC 黑客松**将于 **12 月 17 日**截止提交，提交平台已从 **Devpost** 转移到 **Google Forms** 以简化评估流程。
- [**Modular 的 AMA 系列深化技术见解**](https://forum.modular.com/t/ask-joe-anything-about-the-mojo-standard-library/195)：由 Joe 和 Steffi 等专家主持的 **Ask Me Anything (AMA)** 会议探讨了使用 **Mojo** 进行 **GPU 编程**，促进了社区的深入理解。
- [**社区包早期访问启动**](https://codeium.com/changelog)：**Modular** 发布了**社区包的早期访问预览**，邀请用户共同参与测试并扩展包生态系统。

---

# 第 1 部分：高层级 Discord 摘要

## [Codeium / Windsurf](https://discord.com/channels/1027685395649015980) Discord

- **Windsurf Wave 1 发布**：Codeium 发布了 **Windsurf Wave 1**，引入了重大的自主性升级，包括 **Cascade Memories** 和自动终端命令执行。用户可以查看 [完整变更日志](https://www.codeium.com/changelog) 了解详细更新。
   - 此次发布通过 .windsurfrules 引导行为，增强了 AI 交互，使用户在适应新功能时能更有效地进行任务管理。
- **Cascade Memories 增强**：**Cascade Memories** 已集成到 Windsurf 中，通过 .windsurfrules 为 AI 行为提供强大的指导。该功能旨在自动化用户交互并改进任务管理。
   - 社区反馈表明 **Cascade Memories** 显著丰富了 AI 功能，尽管一些用户报告了与该功能相关的内部错误。
- **Gemini 模型与 Claude 性能对比**：讨论强调 **Gemini 2.0** 模型在编程任务中可能优于 **Claude**，用户表示有兴趣在 Cursor 等工具上部署 Gemini 模型。
   - 用户报告称，与其它模型相比，**Gemini-exp-1206** 等模型显示出更优越的性能指标，引发了关于开发工作流中最佳模型选择的辩论。
- **图像上传功能扩展**：Windsurf 中的 **Cascade 图像上传** 现在支持超过 1MB 的文件，增强了处理多种文件类型的灵活性。此次升级解决了之前用户体验中的限制。
   - 扩展后的图像上传能力受到了好评，允许用户在平台内处理更复杂的数据集和媒体。
- **Windsurf 中 Python 支持的改进**：Windsurf 中的 **Python 支持** 已升级，承诺提供更流畅、更顺滑的编程体验。用户可以通过 [Codeium 方案页面](https://www.codeium.com/plan) 管理其升级计划。
   - 增强的 Python 集成旨在简化开发流程，尽管一些用户报告了更新后因内部错误带来的挑战。

---

## [aider (Paul Gauthier)](https://discord.com/channels/1131200896827654144) Discord

- **O1 Pro 在调试方面表现出色**：用户报告称 **O1 Pro** 能有效地一次性修复问题，在处理重复性或复杂任务时表现优于其他模型。
   - 用户分享了对 **Sonnet** 的沮丧，它经常在简单的编辑上陷入无限循环，突显了 **O1 Pro** 的效率。
- **Gemini 2.0 Flash 性能亮眼**：**Gemini 2.0 Flash** 因其速度和准确性受到称赞，在编辑模式下得分很高，并为编程任务提供了巨大的 Context Window。
   - 尽管结果褒贬不一，许多用户认为它适合实际应用，特别是与编辑器模型结合使用时。
- **Aider 安装障碍与解决方案**：用户在全局安装 **Aider** 时面临挑战，但发现使用 `uv tool install aider-chat` 等解决方案非常有效。
   - 讨论了安装过程中的 OpenSSL 兼容性问题等警告，但认为可以忽略。
- **DeepSeek 面临性能问题**：用户对通过 **OpenRouter** 访问的 **DeepSeek** 表示沮丧，理由是性能缓慢且频繁报错。
   - 尽管面临这些挑战，**DeepSeek** 仍因其准确性而受到关注，促使一些用户继续使用它。
- **Gemini 模型响应差异**：用户报告称，与网页界面相比，**Aider** 中的 **Gemini** 模型提供的体育赛事比分已过时。
   - 这表明无法通过 **API** 获取近期事件，突显了对信息一致性的担忧。

## [Cursor IDE](https://discord.com/channels/1074847526655643750) Discord

- **Claude 在编程方面仍优于 Gemini 2.0**：用户讨论了 **Gemini 2.0** 和 **Claude**，尽管 **Gemini** 最近有所增强，但 **Claude** 在编程准确性方面仍处于领先地位。
   - 对比突显了 **Claude** 在编程任务中的持续优势，促使用户保持其偏好。
- **用户对 Cursor 的性能表示担忧**：参与者对 **Cursor** 最近的更新提供了反馈，表达了对其 Chat 和 Composer 功能性能及限制的沮丧。
   - 建议集中在优化 AI 规则，以增强 **Cursor** 内部的查询和响应能力。
- **AI 工具定价引发社区辩论**：用户辩论了 **Cursor** 和 **Gemini** 等 AI 工具的性价比，评估了它们相对于产出结果的价值。
   - 用户对订阅价格及其与市场上其他可用选项的对比表示担忧。
- **开发者讨论首选的 Web 托管平台**：用户推荐了 Railway 和 Cloudflare Workers 等服务器托管平台，强调了根据项目类型进行选择的重要性。
   - 讨论强调了在为各种开发项目选择托管方案时，成本与易用性之间的平衡。
- **Z 世代的编程风格受到关注**：关于代际编程风格的轻松对话出现了，引用了描绘 Z 世代程序员的幽默 YouTube 视频。
   - 参与者对这些编程趋势对未来代码质量和职场互动可能产生的影响表示担忧。



---



## [OpenAI](https://discord.com/channels/974519864045756446) Discord

- **OpenAI 推出圣诞老人模式和高级语音功能**：在 **12 Days of OpenAI 的第 6 天**，[Kevin Weil 及其团队](https://www.youtube.com/live/NIQDnWlwYyQ?si=vOsHQx2zV_W0Pz2s)在 **Advanced Voice** 中引入了新的 **Santa voice** 以及 **video** 和 **screensharing** 功能。
   - 演示鼓励观众参与这些节日功能，增强了节日主题活动期间的互动体验。
- **Project Astra 挑战 OpenAI 的主导地位**：**Project Astra** 作为 OpenAI 的潜在竞争对手正受到关注，讨论强调了它已准备好挑战 OpenAI 的产品。
   - 一些用户认为，即将发布的 **Gemini 2.0** 可能会显著影响 AI 行业的竞争格局。
- **Gemini 2.0 超越 OpenAI 模型，反馈褒贬不一**：**Gemini 2.0 Flash** 目前可在网页端访问，其性能相比 OpenAI 的模型获得了积极反馈。
   - 然而，用户报告了影响实时视频读取等功能的 Bug，表明仍有需要进一步完善的地方。
- **AI 图像和语音技术的进展**：**ElevenLabs** 的语音 AI 技术正在进行真实感测试，力求实现与人类声音无异的输出。
   - 在 AI 图像生成领域，**Hailuo** 和 **Sora** 等工具因免费额度而需求旺盛，尽管用户对不同视频格式的输出质量反应不一。
- **OpenAI 服务中断及恢复程序**：12 月 11 日 **PST 时间下午 3:16 至晚上 7:38**，服务中断影响了 OpenAI，API 流量在 **下午 5:40** 左右开始恢复。
   - **所有服务现已恢复运行**，OpenAI 将进行根本原因分析以防止未来再次发生此类事件。



---

## [Perplexity AI](https://discord.com/channels/1047197230748151888) Discord

- **Gemini 1.5 Pro Deep Search 比 Perplexity 慢**：用户观察到，与 Perplexity 相比，**Gemini 1.5 Pro Deep Search** 提供了更全面的研究能力，但 **响应时间显著更长**。分享了详细的基准测试（benchmarks）来阐明性能差异。
   - 一位成员强调，尽管在速度上有所权衡，但 Gemini 的彻底性使其适用于密集型研究任务，而其他成员则更喜欢 Perplexity 在要求较低的场景中更快的响应。
- **Perplexity 弃用 O1 推理模型**：**O1 推理模型** 已从 Perplexity 平台移除，引发了对处理复杂查询的担忧。[@AravSrinivas](https://x.com/aravsrinivas/status/1866938825043480813?s=61) 提到，该模型被认为是不必要的，因为 **推理（reasoning）现在会自动触发** 复杂任务。
   - 针对依赖 O1 模型进行高级推理的 Pro 用户的影响展开了讨论，一些人质疑这一决定及其对工作流效率的影响。
- **Perplexity 推出 LinkedIn 验证**：Perplexity 推出了 **LinkedIn 验证**，允许用户连接其个人资料以增强功能。该 [公告](https://x.com/testingcatalog/status/1867316249492943076?s=61) 让社区对该功能的具体益处感到好奇。
   - 用户推测了潜在优势，如改进的凭证验证或个性化的用户体验，但 Perplexity 尚未澄清这种集成的确切目的。
- **GPR 设备方法论的进展**：关于 **GPR 设备和方法论** 的讨论引起了成员的兴趣，[此链接](https://www.perplexity.ai/search/gpr-devices-and-methodologies-paoMOVomS9ejaHzJFka37A#0) 强调了最近的进展。
   - 参与者就 GPR 技术的最新技术和应用进行了交流，强调了其在各种工程领域中日益增长的作用。
- **Perplexity API 遇到 3D Secure 问题**：用户报告称，通过 **Perplexity API** 添加卡片会导致 UI 冻结，随后 **银行的 3D Secure** 屏幕迅速出现并消失，从而阻止了交易授权。
   - 讨论集中在 3D Secure 对安全合规性的必要性以及 API 内部缺乏替代解决方案，这阻碍了无缝支付流程。

---

## [Unsloth AI (Daniel Han)](https://discord.com/channels/1179035537009545276) Discord

- **使用 Llama 3.3 进行直接偏好优化 (DPO)**：成员确认 **Direct Preference Optimization (DPO)** 已成功与 [Llama 3.3](https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-bnb-4bit) 集成，并有全面的文档和示例支持。
   - Theyruinedelise 强调，提供的文档增强了易用性，促进了用户更顺畅的实现。
- **模型合并与量化的挑战**：讨论集中在合并模型的复杂性上，特别是合并到 **4-bit** 的缺点，这可能会降低 **LoRA** 微调模型的性能。
   - Disgrace6161 主张先合并到全精度以保持性能，强调了保留模型质量的重要性。
- **使用 LoRA 适配器优化微调**：**LoRA 适配器** 在微调中的作用得到了广泛讨论，强调了它们在保持模型完整性的同时优化 VRAM 占用的能力。
   - 参与者指出，根据具体任务要求和数据集特征，LoRA 中更高的秩（ranks）可以提升性能。
- **SPDL 提升 AI 训练效率**：[SPDL 博客文章](https://ai.meta.com/blog/spdl-faster-ai-model-training-with-thread-based-data-loading-reality-labs/) 概述了 **SPDL** 如何通过 **基于线程的数据加载** 加速 AI 模型训练，显著缩短了训练时间。
   - 这种方法改进了数据管理和吞吐量，事实证明对于处理 **Reality Labs** 研究中的大型数据集至关重要。
- **发布 OpenPlatypus 数据集**：包含 **25,000 个样本** 的 **OpenPlatypus** 数据集已发布，并在温度为 0 的情况下针对 **Qwen QwQ** 进行了评估，在 OpenRouter 上花费了 **$30**。
   - 建议包括排除 **100-5000 tokens** 范围之外的响应，并在缩减样本量后应用 k-means 聚类。

---

## [Stability.ai (Stable Diffusion)](https://discord.com/channels/1002292111942635562) Discord

- **5090 GPU 发布备受期待**：成员们正热切期待预定于 **1 月**初发布的 **5090 GPU**，并强调了其令人印象深刻的 **32GB VRAM** 容量。
   - 诸如 *“在 AI 的时间维度里，那就像过了好几年”* 之类的幽默评论反映了社区对这款新 GPU 的兴奋与期待。
- **利用 Web Scrapers 对抗 GPU 黄牛**：针对**黄牛（scalpers）**抢购 GPU 的现象引发了讨论，促使用户探索 **web scrapers** 和其他技术以在发布期间确保能买到显卡。
   - 参与者强调了对于不在 **US** 本地的用户来说难度更大，突显了获取 GPU 的挑战。
- **图像生成推荐的热门模型**：用户推荐了 **Dream Shaper**、**Juggernaut** 和 **SDXL** 等模型用于生成**宇宙飞船**等专业内容，并指出其效果显著。
   - 一些人建议利用 **LoRA** 训练来增强模型性能，而另一些人则指出 **8GB VRAM** 可能会限制其能力。
- **旧版 Stable Diffusion 模型的问题**：成员们报告了在使用 **WD1.4** 等旧模型时遇到的挑战，这些模型在图像生成任务中往往会产生异常结果。
   - 建议包括在训练 **LoRA** 模型时为正则化图像（regularization images）添加标签（captioning），以减轻这些问题并提高输出质量。
- **视频 AI 爱好者的 Discord 服务器推荐**：在询问讨论本地视频 AI 模型的合适 Discord 服务器时，提到了 **Mochi**、**LTX** 和 **HunYuanVideo** 等平台。
   - **Banodoco** Discord 服务器被强调为对这些视频 AI 模型感兴趣的爱好者的首选社区。

---

## [Eleuther](https://discord.com/channels/729741769192767510) Discord

- **训练 Jacobian 分析揭示参数依赖性**：[arXiv](https://arxiv.org/abs/2412.07003) 上的一篇新论文分析了**训练 Jacobian**，通过将参数空间中的一个小球体转换为椭球体，说明了最终参数如何受其初始值的影响。
   - 该研究识别了奇异值谱中的不同区域，指出在**白噪声（white noise）**上训练比在真实数据上训练更剧烈地压缩参数空间，并强调了将 Jacobian 分析扩展到更大网络时的计算挑战。
- **RWKV 模型发布：Flock of Finches & QRWKV-6**：RWKV 团队发布了 [Flock of Finches 37B-A11B](https://substack.recursal.ai/p/flock-of-finches-rwkv-6-mixture-of) 和 [QRWKV-6 32B Instruct Preview](https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1)，两者在多项任务中均展示了令人印象深刻的 Benchmark 结果。
   - **Flock of Finches** 仅用 **109 billion tokens** 训练就实现了极具竞争力的性能，而 **QRWKV-6** 在关键指标上已经超越了之前的 RWKV 模型。
- **Muon 优化器展现出优于 AdamW 的潜力**：共识认为 **Muon** 可能优于 **AdamW** 等现有优化器，其梯度正交化（gradient orthogonalization）可能与最大流形容量损失（maximum manifold capacity loss）和强化学习正则化有关。
   - [Muon](https://kellerjordan.github.io/posts/muon/) 优化器的底层数学原理被认为对提升性能具有启发性和合理性，尽管关于其更广泛适用性的讨论仍在继续。
- **NeurIPS 奖项争议与 VAR 论文学术不端疑虑**：NeurIPS 的 ARC 奖项引发了关于主办方改变规则（goalpost shifting）和潜在操纵策略的辩论，使人对其 Benchmark 的有效性产生怀疑。
   - 此外，针对 NeurIPS 2024 最佳论文一作 **Keyu Tian** 的质疑也被提出，指控其在 ByteDance 实习期间存在学术不端和恶意代码攻击行为，引发了重新评估该论文荣誉的呼声。
- **负注意力权重与 Cog Attention**：**Cog Attention** 的引入提出了一种允许负权重的注意力机制，旨在通过促进 Token 的删除、复制或保留来增强模型的表达能力。
   - 虽然这一概念具有创新性，但对其有效性和潜在学习难度的担忧依然存在，特别是在数独（Sudoku）任务等特定应用中。

---

## [LM Studio](https://discord.com/channels/1110598183144399058) Discord

- **GPU 网格：LM Studio 的多 GPU 掌控**：**LM Studio** 高效地将任务分配到多个 GPU 上，要求它们属于同一“类型”，但不一定是同一型号。*Heyitsyorkie* 提到，**LM Studio** 中的 GPU offload 是一个开关，可以利用所有可用的 GPU。
   - **LM Studio** 用户强调，这种设置通过利用连接的 GPU 的总计算能力，增强了性能的可扩展性。
- **Mac 性能：在 M4 Max 上运行 70b LLMs**：**M4 Pro** 芯片可以在至少 **16GB RAM** 的 Mac 上运行 **8b 模型**，而 **M4 Max** 则有能力运行 **70b 模型**，前提是用户为了灵活性优先考虑 RAM。
   - 参与者指出，像 **70b** 这样的大型模型需要大量内存，这使得 **M4 Max** 成为处理高需求 AI 任务的合适选择。
- **GPU 对决：Intel B580 vs Nvidia RTX 3060**：**Intel 的 B580 GPU** 价格亲民且拥有 **12GB VRAM**，但需要 **Vulkan** 支持，这引起了用户的怀疑。相比之下，**RTX 3060** 提供 **12GB VRAM**，二手价格在 **$150-$250** 之间。
   - *mlengle* 强调更倾向于 **Nvidia** GPU，因为它们支持 **CUDA**，而 Intel 的产品则缺乏这种支持。
- **无审查 AI：应对模型安全限制**：一位用户在寻找创建**无审查 AI 模型**的指导时表达了挫败感，强调缺乏移除安全功能的清晰资源。他们被建议探索 Unsloth 微调指南，并考虑使用旨在实现限制更少模型的数据集。
   - 参与者提出了处理模型安全性的替代方法，并指出了修改现有 **LLMs** 所涉及的复杂性。
- **微调 vs RAG：选择正确的 LLM 策略**：参与者讨论了**微调 LLMs** 的复杂性，特别是在处理数值数据时，认为这可能无法提供预期的结果。建议使用 **RAG** (Retrieval-Augmented Generation) 等替代方案进行数据检索。
   - 社区指出，与微调相比，传统的分析方法对于特定用例可能会产生更好的见解。

---

## [Bolt.new / Stackblitz](https://discord.com/channels/364486390102097930) Discord

- **少量使用后 Token 使用量显示为 'NaN'**：用户报告称，在少量使用后，**token usage** 显示为 'NaN'，导致困惑和跟踪不准确。
   - 支持人员建议如果问题持续存在，请重新加载标签页或联系帮助中心，因为显示问题正在解决中。
- **Bolt 中的调试导致过度的 Token 消耗**：用户在 **Bolt 中调试**时遇到问题，导致在没有有效结果的情况下消耗了过多的 Token。
   - 建议包括使用更集中的 Prompt 和文件固定（file pinning），以防止在复杂任务期间发生不必要的更改。
- **Supabase 集成将增强 Bolt 功能**：社区讨论了将 **Supabase 集成**到 Bolt 中的潜力，许多人认为这将增强构建项目的功能。
   - 用户表示乐观，认为这种集成可以显著简化工作流程，特别是对于那些从 Firebase 等服务迁移过来的用户。
- **功能请求集中在 GitHub 集成和全栈支持**：用户对功能提出了建议，包括更好的 **GitHub 集成**和对**全栈应用**的更多支持。
   - 社区强调要礼貌地提出功能请求，并将其引导至 GitHub issues 页面进行正式审议。

---

## [Notebook LM Discord](https://discord.com/channels/1124402182171672732) Discord

- **NotebookLM UI 翻新并推出交互式音频**：NotebookLM 即将迎来 UI 翻新，其特点是为 **Sources**、**Chat** 以及 **Notes & Audio Overview** 设立了独立板块，并推出了 *Interactive Audio Beta*，支持与主持人进行实时互动 ([Tweet](https://x.com/testingcatalog/status/1867251820986302787?s))。
   - 此次更新旨在通过改进导航和可用性来提升用户体验，解决当前在源管理和音频交互方面的局限性。
- **Gemini 2.0 提升性能**：**Gemini 2.0** 预计将以更高的输出 Token 限制和先进功能超越现有模型 ([Tweet](https://x.com/testingcatalog/status/1867251820986302787?s))。
   - 然而，人们对与前代版本相比可能存在的上下文窗口大小限制表示担忧。
- **自定义 AI 语音助力播客个性化**：成员们讨论了为播客集成 **custom voices**（自定义语音），并建议使用 **Eleven Labs** 进行语音克隆，以满足日益增长的个性化音频体验需求。
   - 一位用户强调了利用专业克隆语音来增强听众参与度和内容独特性的重要性。
- **AI 驱动的 TTRPG 冒险受到关注**：使用 AI 运行 **TTRPG** 冒险的热度激增，这与单人 **D&D** 游戏类似，可提供更具沉浸感的叙事。
   - 用户报告了这种尝试的不同成功程度，指出尽管存在一些挑战，但这仍是一项有趣的尝试。
- **AI 生成的视频播客探讨深度主题**：一个由原始人和 AI 聊天机器人组成的全新 **AI 生成视频播客** 深入探讨了诸如 *生命意义* 等主题，将幽默与深刻对话融为一体。
   - 这种创新的形式展示了古代与现代视角之间的动态关系，因其独特的方法而引起关注。

---

## [Nous Research AI](https://discord.com/channels/1053877538025386074) Discord

- **Hermes 3B 超出基准测试预期**：用户正在对比 **Hermes 3B**、**Llama 3.2**、**Mistral 7B** 和 **Qwen 2.5** 的基准测试，**Hermes 3B** 在多项指标上表现出卓越性能。
   - **Senor1854** 强调了新 [数学基准数据集](https://toloka.ai/math-benchmark) 相比既有数据集的可靠性，强调了不断演进评估技术的重要性。
- **QTIP 模型在无需重新训练的情况下优于 AQLM**：据报道，**QTIP 模型**在无需重新训练的情况下表现优于 **AQLM**，详情见 [QTIP GitHub 仓库](https://github.com/Cornell-RelaxML/qtip)。
   - 社区反应表明**信号处理技术**在机器学习中正重新兴起，成员们指向 [研究论文](https://openreview.net/pdf?id=7sdkLVuYCU) 以获取更深入的见解。
- **Llama3 面临容量利用率挑战**：**Llama3** 被指出在**模型容量利用率**方面经历了性能下降，导致成员们开始审视底层的模型动态。
   - 成员们计划研究相关研究以了解性能退化的原因，并对**模型容量**如何影响 **Llama3** 的效能表示关注。
- **推出新数学基准 U-MATH 和 μ-MATH**：**Toloka** 宣布推出 **U-MATH** 和 **μ-MATH**，这是两个旨在评估 **LLMs** 大学水平数学能力的全新基准。
   - 这些基准预计将提供更可靠的评估，与之前的评分系统形成对比，并推动**评估技术**的进步。
- **利用大模型隐藏状态预训练小模型**：**Kotykd** 提出了一种新颖的训练方法，即使用**大模型隐藏状态**（**big model hidden states**）在不同架构中预训练较小的模型，以提高效率。
   - 这一想法引发了关于此类方法可行性和潜力的讨论，成员们强调需要进一步的探索和实验。

## [GPU MODE](https://discord.com/channels/1189498204333543425) Discord

- **Torch.compile 面临 Dynamic Padding 性能惩罚**：一位用户报告称，在将 **torch.compile(mode='max-autotune')** 与 **dynamic=True** 结合使用时，初始 Decoder 迭代过程中出现了显著的性能惩罚，特别是在处理新的 conditioning shapes 时运行速度变慢。
   - 尽管启用了 dynamic padding，性能问题依然存在，这引发了关于减轻与变长输入相关的性能惩罚的潜在解决方案的讨论。
- **Triton 通过 Fused Kernels 增强 Matmul 和 Softmax**：社区成员正在 Triton 中为 **matmul** 和 **softmax** 开发 **fused kernel**，借鉴了现有的点对点激活融合（如 ReLU）。
   - 成员们寻求关于利用 Triton 文档中 group-ordered matmul 示例的指导，以克服融合 softmax 操作相关的挑战。
- **TorchAO 中的 Float8 训练：从 DDP 转向 FSDP**：**TorchAO** 的 **float8 训练**实现在使用 **DDP** 扩展到多 GPU 设置时遇到错误，尽管在单 GPU 上运行顺畅。
   - 社区成员建议采用 **FSDP** 进行数据并行，并鼓励在 **TorchAO** 上分享代码或报告问题，以促进故障排除和改进。
- **CUTLASS 成为顶级 GEMM 实现替代方案**：在关于排除 cuBLAS 之外的最佳 **GEMM 实现**讨论中，**CUTLASS** 被认为是领先的替代方案。
   - 参与者比较了纯 CUDA 和 Triton 等多种替代方案，最终认可 **CUTLASS** 在矩阵乘法任务中的卓越性能。
- **GPU Glossary 发布及 H100 Tensor Core 澄清**：**GPU Glossary** 在 Modal 上发布，详细介绍了“Streaming Multiprocessor”等术语，并解决了 **H100 GPU** 中的核心计数和 **tensor core** 功能问题。
   - 讨论强调了准确表示 GPU 架构的必要性，包括澄清 H100 中的每个 SM 拥有 **128 个 FP32 cores**，以及 **tensor cores** 与 CUDA cores 相比的操作差异。

---

## [Cohere](https://discord.com/channels/954421988141711382) Discord

- **Cohere 支持响应速度**：当用户报告问题时，成员强调对于紧急事项应联系 [support@cohere.com](mailto:support@cohere.com) 的**支持团队**。
   - 另一位用户鼓励直接发消息以获得更快协助，并认可支持团队的存在。
- **Rerank 超时问题**：多位用户在使用 **Rerank** 功能时遇到 **504 gateway timeout** 错误，其中一位报告请求在 **40 秒**后超时。
   - 该问题似乎是偶发的，因为一些成员注意到服务不久后恢复，而其他人仍报告存在困难。
- **H100 上 FP8 量化优于 BnB**：关于量化技术的讨论显示，在 **H100 硬件**上，**FP8 量化**在高用户负载下的快速推理方面优于 **BnB**。
   - 成员们一致认为，像 **WikiText** 这样的传统校准数据集在实际性能中往往表现不足，特别是对于非英语语言。
- **Cohere Go SDK 结构修复**：反馈表明 **Cohere Go SDK** 中与 tools calls 相关的 `StreamedChatResponseV2` 字段结构不正确。
   - **ToolPlanDelta** 和 **ToolCallDelta** 的定义缺少准确解析所需的必要字段。
- **Aya Expanse 模型许可担忧**：用户表示倾向于在公司内部环境中使用 **Aya Expanse 模型**，强调在避免潜在数据泄露的同时需要速度。
   - 用户对 **CC-BY-NC 许可**表示了担忧，引发了关于即使在企业环境内进行非商业用途的影响的讨论。

## [LLM Agents (Berkeley MOOC)](https://discord.com/channels/1280234300012494859) Discord

- **LLM Agents Hackathon 截止日期及平台变更**：**LLM Agents MOOC Hackathon** 的提交截止日期临近，为 **12月17日**。提交平台已从 **Devpost** 迁移至 **Google Forms**，以确保评估工作的顺利进行。
   - 获胜者将于 **2025年1月上半月** 公布，鼓励参与者通过聊天频道寻求最后的帮助，并访问 Hackathon 网站了解更多详情。
- **高级 LLM Agents MOOC 将于 2025 年春季启动**：**Advanced Large Language Model Agents MOOC** 定于 **2025年春季** 开课，重点关注推理和数学 AI。目前已开放报名，链接见 [此表单](https://forms.gle/9u6HdVCWXgws16go9)。
   - 教学大纲仍在制定中，预计 **Prof Song** 将提供更多细节。课程将从 **1月中旬持续到5月初**，更多信息可在 [MOOC 网站](https://llmagents-learning.org/sp25) 查看。
- **MOOC 作业和测验政策**：所有作业（包括书面文章）的截止日期为 **2024年12月12日晚上 11:59 PM PST**。测验按 **完成情况评分**（completion basis），允许参与者在不受惩罚的情况下获得证书。
   - 书面文章作业需要提供社交媒体帖子的链接，可通过 [Written Article Assignment Submission](https://forms.gle/7ekobPNSWDLBWnDT6) 提交。测验旨在促进学习而非严格考核。
- **Hackathon 的 Ninja Tier 要求**：对于 Hackathon 中的 **Ninja Tier**，必须完成所有测验并提交文章作业，实验（Labs）为选修项。
   - 鼓励参与者针对其 Hackathon 项目撰写书面文章，以增强他们在该等级中的贡献。

---

## [Interconnects (Nathan Lambert)](https://discord.com/channels/1179127597926469703) Discord

- **Google 发布 Android XR**：Google 在最近的 [演示](https://www.theverge.com/2024/12/12/24319528/google-android-xr-samsung-project-moohan-smart-glasses) 中展示了 **Android XR**，这是一款专为 **Headsets**（头显）和 **Smart Glasses**（智能眼镜）设计的新型混合现实操作系统。
   - 该平台具有带字幕的实时 **Translation**（翻译）功能，强化了 Google 向增强现实技术转型的战略重点。
- **OpenAI 与 Anthropic 的市场竞争**：**OpenAI** 和 **Anthropic** 正在加剧市场领导地位的竞争。到 2024 年底，**Anthropic** 的 ARR 达到 10 亿美元，而 **OpenAI** 的收入为 40 亿美元，估值为 1570 亿美元。
   - 这种竞争凸显了 **Anthropic** 在编程应用领域的增长，引发了 **OpenAI 高管** 对战略从安全转向激进营销的担忧。
- **MLLM 开发进展**：社区成员正积极寻找跟踪 **MLLM** 发展的优质来源，一些人利用 **Scraping** 技术和 [Twitter](https://x.com/jbohnslav) 信息流作为潜在资源。
   - 提升信息质量的努力反映了 **MLLM** 领域对实时、可靠数据的需求。
- **Hugging Face 的 VLM 见解**：来自 Hugging Face 的 **Merve** 被推荐为获取 **VLM** 见解的关键资源，可以通过 [Twitter](https://x.com/mervenoyann) 访问她发布的信息。
   - 她的内容被认为对于紧跟 **Vision-Language Models** 发展的人士非常有价值。
- **AI 模型创意基准测试**：围绕建立衡量 **LLM** 创意任务能力的有效基准展开了讨论，旨在解决目前缺乏 **Diversity**（多样性）和创意标准的问题。
   - **Claude-3** 尽管受到社区青睐，但在创意写作基准测试中排名往往较低，这凸显了改进评估指标的必要性。

---

## [LlamaIndex](https://discord.com/channels/1059199217496772688) Discord

- **Calsoft 发布 CalPitch 工具**：Calsoft 推出了 [CalPitch](https://twitter.com/llama_index/status/1866949720654090423)，该工具旨在协助其业务开发团队研究潜在客户，并在人工监督下起草外联邮件。
   - 此次发布展示了 **AI 如何增强并加速** 当前的工作流程。
- **通过 SharePoint 和 LlamaParse 增强 RAG Agent**：新功能支持构建遵循 SharePoint 权限的 RAG Agent，满足了 **Azure stack** 用户使用 **LlamaParse** 解析非结构化 PDF 数据并连接到企业数据源的需求。
   - 针对数据隐私问题，确保数据保留时间不超过 **48 小时**。
- **Google Gemini 2.0 模型发布**：Google 发布了最新的 **Gemini 2.0** 模型，并提供首日支持，可通过 `pip install llama-index-llms-gemini` 或 `pip install llama-index-llms-vertex` 进行访问。
   - [Gemini 2.0 Flash](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#gemini-2-0-flash) 模型承诺提升速度和能力，被誉为 AI 领域的游戏规则改变者。
- **使用 ReAct Agent 个性化 Slack Bot**：一位用户正在使用 **ReAct Agent** 开发 Slack Bot，并寻求关于如何在不暴露其 AI 身份的情况下融入个性的建议。
   - 社区成员建议使用带有 system prompt 的 **FunctionCallingAgent** 来定制其个性。
- **将 BGEM3 与 Qdrant 数据库集成**：一位用户询问如何通过 **LlamaIndex** 将 **BGEM3** 模型与 **Qdrant** 数据库集成，并寻求相关流程指导。
   - 社区分享了与 **BGEM3** 相关的资源以协助集成。

---

## [Modular (Mojo 🔥)](https://discord.com/channels/1087530497313357884) Discord

- **Swag Challenge 获胜者公布**：我们在周一开启了 **swag challenge**，并在[此处](https://forum.modular.com/t/winners-of-day-1-swag-challenge/189)公布了获胜者。Ahmed 还主持了一场 **[关于使用 Mojo 进行 GPU 编程的 Ask Me Anything 会议](https://forum.modular.com/t/simplifying-gpu-programming-with-parametric-tile-level-tensors-in-mojo-llvm-developers-meeting-2024/38)**。
   - 这一举措不仅增强了社区参与度，还为参与者提供了与专家直接交流使用 **Mojo** 进行 **GPU 编程**的机会。
- **AMA 会议深入探讨 Mojo**：周二，Joe 主持了一场 **[关于标准库的 Ask Me Anything 会议](https://forum.modular.com/t/ask-joe-anything-about-the-mojo-standard-library/195)**，对标准库的功能和特性提供了宝贵的见解。
   - 此外，今天的活动还包括 **[关于 MLIR 中 async Mojo/协程实现的 Steffi 问答](https://forum.modular.com/t/efficient-coroutine-implementation-in-mlir-llvm-developers-meeting-2024/39)** 以及 **[关于 Mojo 优化流水线的 Weiwei 问答](https://forum.modular.com/t/what-we-learned-from-building-mojos-optimization-pipeline-llvm-developers-meeting-2024/35)**，旨在深化对特定技术主题的理解。
- **社区软件包早期访问版发布**：昨天，我们发布了 **社区软件包的早期访问预览版**，鼓励用户加入并协助测试打包功能。感兴趣的用户可以在 <#1098713770961944628> 注册，以获得进入指导频道 <#1313164738116583454> 的权限。
   - 此次发布旨在通过让社区参与测试和开发来扩展软件包生态系统。
- **Async Mojo 实现与优化流水线**：今天的 **Ask Me Anything 会议** 包括关于 **MLIR 中 async Mojo/协程实现** 以及 **Mojo 优化流水线** 的讨论。
   - 这些会议旨在提供深入的技术知识，并促进使用 Mojo 的 AI 工程师之间的互动。

---

## [DSPy](https://discord.com/channels/1161519468141355160) Discord

- **面向 LLM 的 DSPy 框架**：在引入 [DSPy 框架](https://www.dbreunig.com/2024/12/12/pipelines-prompt-optimization-with-dspy.html)后，**DSPy** 显著减少了为编程语言模型编写 Prompt 的时间。
   - 该框架使用样板化 Prompt 和任务签名（task signatures），简化了 Prompt 的创建并提高了基于 LLM 应用的效率。
- **关注文本和图像输入**：成员们讨论了是否要投入视频和音频输入，其中一位成员建议目前先专注于文本和图像输入。
- **定义 LLM Agent**：一位成员发起了关于“LLM Agent”定义的讨论，并分享了一个探讨其隐喻含义的 [Thread](https://x.com/lateinteraction/status/1867261806726819890)。
   - 参与者幽默地承认了这场辩论的争议性，称 *“你现在捅了马蜂窝了。”*
- **使用有标签数据进行优化**：确认了 **Optimizer** 可以与有标签数据（特别是金标准输入输出对）一起使用。
   - 这一确认引发了成员们对使用有标签数据集进行优化的浓厚兴趣和参与。
- **AI 是技术界的鸭嘴兽**：一位成员反思了 AI 对现有技术分类的挑战，将其比作 [The Platypus In The Room](https://www.dbreunig.com/2023/05/08/ai-is-a-platypus.html) 中描述的技术“鸭嘴兽”。
   - 他们强调：*“AI 和 LLM 的几乎每一个显著特性都在挑战我们的惯例、分类和规则集。”*

---

## [OpenInterpreter](https://discord.com/channels/1146610656779440188) Discord

- **寻找蜘蛛侠：平行宇宙故障效果**：一位用户正在寻找他们在网站上看到的 **Spider Verse 故障效果**，以便**复制该效果**。
   - 他们对该效果的*创意方面*表现出浓厚兴趣。
- **Open Interpreter 的 Docker 问题**：一位成员报告称，在 Docker 中运行的 **Open Interpreter** 仅返回模型的聊天响应，而不执行代码。
   - 他们认为该应用程序似乎在**假装执行代码**，而实际上并没有执行。
- **GitHub Model I 教程更新**：一位用户询问了 **GitHub 页面**上关于 Model I 教程的最新变化，注意到信息发生了重大转变。
   - *似乎 GitHub 页面更新了，现在很多东西都不一样了*，这表明了对文档的困惑。
- **Struggles with NVIDIA NIM Base URL Setup**: 一位用户寻求设置 **NVIDIA NIM 基础 URL 链接**的帮助，提到尝试多次均未成功。
   - 他们表达了沮丧，称已经尝试了很久但**运气不佳**。
- **WebVoyager 与 GPT 4V 的偏好**：一位成员询问了关于 **WebVoyager** 的意见，表示倾向于更新模型以使用 **GPT 01** 而不是 **GPT 4V**。
   - 他们对测试并可能切换模型感到好奇。

---

## [tinygrad (George Hotz)](https://discord.com/channels/1068976834382925865) Discord

- **Coverage.py 介绍**：一位成员介绍了 [Coverage.py](https://coverage.readthedocs.io/en/7.6.9/) 作为测量 Python **代码覆盖率**的工具，强调了其跟踪已执行代码和分析未执行部分的能力。
   - 最新版本 **7.6.9** 于 **2024 年 12 月 6 日**发布，支持从 3.9 到 3.14 alpha 2 的 Python 版本。
- **gcov 作为替代覆盖率工具**：一位成员推荐使用 [gcov](https://gcc.gnu.org/onlinedocs/gcc/Gcov.html) 进行覆盖率分析，并询问是否有更*细粒度*的选项。
   - 这引发了关于各种可用覆盖率工具及其各自优势的广泛讨论。
- **George Hotz 认可 Coverage.py**：George Hotz 认为 **Coverage.py** 是评估测试覆盖率的*良好起点*，体现了他对其增强**代码质量**能力的信心。
   - 他的背书强调了该工具在寻求改进测试流程的工程师中的有效性。
- **寻求测试覆盖率专家**：一位成员请求熟练使用**测试覆盖率工具**的用户提供帮助，以识别**死代码**。
   - 他们强调，为了保持**代码质量**，未测试的代码*可能应该被删除*。

## [Torchtune](https://discord.com/channels/1216353675241590815) Discord

- **QRWKV6-32B 模型提升计算效率**：[Recursal AI](https://x.com/rohanpaul_ai/status/1866971776737218564) 将 Qwen 32B Instruct 模型转换为 **QRWKV6** 架构，在保持原始 32B 性能的同时，在推理过程中实现了 **1000 倍的计算效率**。
   - 此修改将 Transformer Attention 替换为 **RWKV-V6 Attention**，从而显著降低了计算成本。
- **AMD GPU 实现快速训练**：使用 **16 块 AMD MI300X GPU**（每块 192GB VRAM），**QRWKV6** 模型的训练仅需 **8 小时** 即可完成，展示了 AI 开发速度的进步。
   - 即将推出的 **Q-RWKV-6 72B** 和 **RWKV-7 32B** 等模型正在开发中，有望提供更强大的能力。
- **RWKV-V6 Attention 增强可扩展性**：**QRWKV6** 模型中的线性注意力机制（Linear Attention）在规模化应用中被证明非常高效，特别是在处理长上下文（Long Context）时。
   - 尽管有这些改进，由于计算限制，该模型目前的上下文长度上限为 **16k**，但在超过此限制后仍保持稳定。
- **模型转换降低重训练成本**：转换过程允许将任何 QKV Attention 模型转换为 RWKV 变体，而无需进行**完整重训练**，从而降低了计算成本。
   - 然而，该模型继承了 **Qwen 模型**的语言限制，仅支持约 **30 种语言**，而 RWKV 通常支持 **100 多种语言**。
- **社区协作推动进步**：**QRWKV6** 模型的训练由 **TensorWave** 赞助，**EleutherAI** 和 RWKV 社区做出了重大贡献。
   - 虽然转换过程具有创新性，但部分细节尚未公开，社区对其**具体实现方式（how-to）**感到好奇。

---

## [Gorilla LLM (Berkeley Function Calling)](https://discord.com/channels/1111172801899012102) Discord

- **为自定义 API 微调 Gorilla LLM**：一位用户正在寻求关于如何**微调 Gorilla LLM** 以识别自定义 API 的指导，并表示此前在该过程中遇到了困难。
   - 他们特别提到了从 [Hugging Face](https://huggingface.co/models) 下载 **GoEx 模型**时的挑战。
- **下载 GoEx 模型的挑战**：用户提到在尝试下载 **GoEx 模型**以便在 **Colab 环境**中使用时遇到了麻烦。
   - 这凸显了对模型获取提供更清晰说明或故障排除步骤的需求。
- **在 Gorilla LLM 中实现可逆性**：用户询问了在其 Gorilla LLM 项目中**实现可逆性（Reversibility）**的策略。
   - 这表明开发者对开发过程中的有效控制机制有着广泛兴趣。
- **在 Colab 中训练 Gorilla LLM**：他们正在 **Colab 环境**中进行 **Gorilla LLM** 的训练。
   - 这种方法可能需要高效的资源管理和清晰的训练协议。

---

## [Axolotl AI](https://discord.com/channels/1104757954588196865) Discord

- **PyTorch 的 PYTORCH_TUNABLEOP_ENABLED 标志**：一位成员强调了在 PyTorch 中使用 `PYTORCH_TUNABLEOP_ENABLED=1` 来启用可调操作（Tunable Operations），并引用了 [PyTorch GitHub 仓库](https://github.com/pytorch/pytorch/tree/main/aten/src/ATen/cuda/tunable)。
   - 该功能暗示了 **CUDA** 可调操作的优化，可能会提高使用 PyTorch 的开发者的效率。
- **CUDA 可调性提升 GPU 性能**：讨论集中在 `PYTORCH_TUNABLEOP_ENABLED=1` 及其对 **CUDA** 操作的好处，表明在 GPU 计算任务中可能存在性能提升。
   - 成员们认为，可调方法允许开发者更有效地自定义操作，从而符合特定的用户需求。

## [Mozilla AI](https://discord.com/channels/1089876418936180786) Discord

- **Mozilla Builders Demo Day 回顾发布**：[Mozilla Builders Demo Day 回顾](https://blog.mozilla.org/en/mozilla/mozilla-builders-demo-day/) 重点介绍了成员们如何在恶劣的天气条件下线下齐聚，展示了令人惊叹的 **technology** 以及 **participant connections**。
   - 该活动展示了前沿技术，并促进了参与者之间的紧密联系。
- **致谢核心贡献者**：向促成此次活动的特定团队和贡献者表达了特别感谢，详情见[此处](https://discord.com/channels/1089876418936180786/1301981533447393430)。
   - 社区成员展现了非凡的韧性，在困难条件下（如*冒着海啸*）依然坚持参加。
- **Demo Day 的社交媒体热度**：Mozilla Builders 分享了他们的 [LinkedIn 动态](https://www.linkedin.com/posts/mozilla-builders_when-purpose-meets-technology-activity-7273076925529481216-1dug?utm_source=share&utm_medium=member_desktop) 和一条 [推文](https://x.com/mozillabuilders/status/1867312203571114041)，将此次活动描述为*优秀人才与卓越技术的精彩汇聚*。
   - 社交媒体帖子强调了活动的成功以及强烈的社区参与度。
- **Demo Day 精彩视频发布**：为错过活动的人分享了名为 [Demo_day.mp4](https://cdn.discordapp.com/attachments/1089876419926032396/1316894546571034715/Demo_day.mp4?ex=675cb51e&is=675b639e&hm=0981245db20d7860bd878f4e98eefb65291266ff8c0dcae04ae28dc0e5b12717&) 的精彩回顾视频。
   - 该视频展示了当天的部分 **presentations** 和 **interactions**，提供了全面的概览。

---

**MLOps @Chipro Discord** 没有新消息。如果该频道长时间没有动态，请告知我们，我们将将其移除。

---

**LAION Discord** 没有新消息。如果该频道长时间没有动态，请告知我们，我们将将其移除。

---

**HuggingFace Discord** 没有新消息。如果该频道长时间没有动态，请告知我们，我们将将其移除。

---

**AI21 Labs (Jamba) Discord** 没有新消息。如果该频道长时间没有动态，请告知我们，我们将将其移除。

---

# 第二部分：分频道详细摘要与链接


{% if medium == 'web' %}

### **Codeium / Windsurf ▷ #[announcements](https://discord.com/channels/1027685395649015980/1027688115592237117/1316507848754200698)** (1 条消息): 

> `Windsurf Wave 1 Launch, Cascade Memories, Usage Transparency, Image Upload Capabilities, Improved Python Support` 


- **Windsurf Wave 1 正式上线！**：Windsurf Wave 1 现已发布，带来了重大的 **autonomy**（自主性）升级，包括 Cascade memories 和自动化终端命令执行。
   - 查看 [完整更新日志](https://www.codeium.com/changelog) 以获取变更和改进的详细概览。
- **Cascade Memories 增强 AI 交互**：通过 `.windsurfrules` 引入的 **Cascade memories** 显著引导了 AI 行为，提供了更有效的任务管理。
   - 该功能旨在自动化并丰富用户与平台的交互。
- **更新的使用额度和定价模型推出**：Windsurf 正在实施全新的使用额度和定价系统，其中包括一个显示当前方案使用情况的设置面板。
   - 在[此处](https://codeium.com/redirect/windsurf/learn-pricing)了解更多关于定价变化和全新 “Legacy Chat” 模式的信息。
- **Cascade 图片上传功能增强！**：Cascade 现在支持超过之前 **1MB** 限制的图片上传，显著提升了用户体验。
   - 这一变化为用户上传待处理文件类型提供了更大的灵活性。
- **Python 支持获得升级**：Windsurf 内的 Python 支持得到了增强，承诺提供更流畅的编码体验。
   - 用户可以通过 [Codeium 方案页面](https://www.codeium.com/plan) 自助升级其方案。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://www.codeium.com/changelog">Windsurf Editor 更新日志 | Windsurf Editor 和 Codeium 扩展</a>: Windsurf Editor 的最新更新和变更。</li><li><a href="https://www.codeium.com/plan">方案设置</a>: 未来的编辑器，就在今天。Windsurf Editor 是首个基于 AI agent 的 IDE，让开发者保持专注流。现已支持 Mac, Windows 和 Linux。</li><li><a href="https://codeium.com/blog/windsurf-wave-1">Windsurf Wave 1</a>: 介绍 Wave 1，我们对 Windsurf Editor 的第一批更新。</li><li><a href="https://x.com/windsurf_ai/status/1866948850205986926">来自 Windsurf (@windsurf_ai) 的推文</a>: 介绍 Wave 1。本次更新包含：🧠 Cascade Memories 和 .windsurfrules 💻 自动化终端命令 🪟 WSL, devcontainer, Pyright 支持... 以及更多。
</li>
</ul>

</div>
  

---


### **Codeium / Windsurf ▷ #[discussion](https://discord.com/channels/1027685395649015980/1027697446446432336/1316508664252862545)** (135 条消息🔥🔥): 

> `Codeium Plugin Issues, Windsurf Features, Credit Management Concerns, User Experience with AI Integration, Comparisons to Other AI Tools` 


- **Codeium 插件面临批评**：用户对 Codeium 插件表示沮丧，理由包括尝试 AI 聊天时出现错误消息，以及对其与 Windsurf 相比性能的担忧。
   - 一位用户提到，*“每次我写东西时都会报错，”* 表明技术挑战仍在继续。
- **Windsurf Context 功能**：关于 Windsurf 及其 Context 功能的讨论强调了项目的索引能力，用户询问了 Pinned Context 的工作原理。
   - 作为回应，有人指出 Windsurf 会 *索引项目*，用户可以在设置中查看。
- **对额度消耗的担忧**：许多用户注意到 Codeium 和 Windsurf 的额度消耗很快，对提供的有限额度表示不满。
   - 一位成员评论道，*“500 次 User Prompt 额度并不多，”* 并称这项开支很大，尤其是在货币较弱的国家。
- **AI 工具的用户体验**：用户将 Windsurf 与 Cursor 等竞争工具进行了比较，对其性能和价值评价不一。
   - 一位用户反思了某些 AI 工具的高昂成本，称 *“500 美元简直是丧心病狂。”*
- **对功能和方案的困惑**：用户对在 IDE 中集成个人 GPT 和 Claude 账号，以及 Codeium 插件的整体预期功能存在疑问。
   - 回复显示，虽然 Codeium 持续开发其插件，但与其他平台相比，用户仍会遇到明显的局限性。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://tenor.com/view/bobawooyo-dog-confused-dog-huh-dog-meme-shocked-dog-gif-16491396616893958961">Bobawooyo Dog Confused GIF - 困惑的狗</a>: 点击查看 GIF</li><li><a href="https://youtu.be/oU3H581uCsA?si=4aBg2C3EvcVh3BzD">Devin 评测：它是一个比 Cursor 更好的 AI 编程 Agent 吗？</a>: 阅读完整评测：https://www.builder.io/blog/devin-vs-cursor
</li>
</ul>

</div>
  

---

### **Codeium / Windsurf ▷ #[windsurf](https://discord.com/channels/1027685395649015980/1306163501286293515/1316496688189538304)** (647 条消息🔥🔥🔥): 

> `Windsurf 性能问题，Gemini 模型对比 Claude，Cascade 内部错误，Codeium 用户反馈，支持工单系统` 


- **Windsurf 性能问题导致内部错误频发，引发用户沮丧**：用户在 Windsurf 中遇到高频率的内部错误，尤其是在最近的更新之后，影响了整体生产力并导致了沮丧情绪。
   - 许多用户报告称由于这些错误导致 credits 损失，并对服务的一致性表示担忧。
- **Gemini 模型可能优于 Claude**：目前正在讨论 Gemini 2.0 模型在编程任务上是否优于 Claude，用户表达了在 Cursor 上尝试 Gemini 模型的兴趣。
   - 一些用户指出 Gemini-exp-1206 似乎优于包括 Sonnet 在内的其他模型。
- **Cascade Base 上的内部错误持续存在**：用户报告在 Cascade Base 上遇到内部错误，并质疑在其他人已经指出相同问题的情况下是否仍需提交支持工单。
   - 尽管依赖 Cascade Base，用户仍面临挑战，这导致有人建议支持团队应更加主动。
- **用户反馈与产品批评**：用户对 Codeium 的产品评价褒贬不一，讨论了订阅价值以及近期价格调整的影响。
   - 一些用户对产品的不一致性表示担忧，而另一些用户则强调了持续反馈对改进功能的重要性。
- **支持工单系统受到质疑**：人们对支持工单系统在解决模型重复性问题（特别是与内部错误相关的问题）方面的有效性和必要性提出了质疑。
   - 用户认为，如果多个用户都报告了相同的问题，可能不需要针对每个案例都进行直接支持。


<div class="linksMentioned">

<strong>提及的链接</strong>:

<ul>
<li>
<a href="https://x.com/kregenrek/status/1866963579137917350">来自 Kevin Kern (@kregenrek) 的推文</a>: Windsurf 获得了一个非常不错的更新。你现在可以为 AI 定义规则（类似于 cursorrules）。而且 cursorrules 扩展开箱即用，可以直接将 70 个预定义规则导入 Windsurf...</li><li><a href="https://r1prompts.com">RabbitR1 Prompts</a>: 未找到描述</li><li><a href="https://x.com/sdrzn/status/1867271665086074969">来自 Saoud Rizwan (@sdrzn) 的推文</a>: Cline 现在可以使用 MCP 为自己创建并添加工具！尝试让它“添加一个拉取最新 npm 文档的工具”——Cline 会处理从创建 MCP 服务器到将其安装到自身的所有事务...</li><li><a href="https://x.com/codeiumdev/status/1861171933704040617">来自 Codeium - Windsurf (@codeiumdev) 的推文</a>: 今天，@AnthropicAI 正在推出他们的 Model Context Protocol (MCP)，这是一个将 AI 助手连接到数据源的开放标准。我们很高兴能与 Anthropic 合作，基于 MCP 构建...</li><li><a href="https://ai.google.dev/pricing#1_5flash">未找到标题</a>: 未找到描述</li><li><a href="https://aistudio.google.com/">Google AI Studio</a>: Google AI Studio 是开始使用 Gemini（我们下一代多模态生成式 AI 模型系列）进行构建的最快方式。</li><li><a href="https://status.anthropic.com/">Anthropic 状态</a>: 未找到描述</li><li><a href="https://tenor.com/view/funny-animals-dog-hide-im-not-here-shy-gif-2362647336245836199">有趣的动物狗狗 GIF - 有趣的动物狗狗躲藏 - 发现并分享 GIF</a>: 点击查看 GIF</li><li><a href="https://github.com/unixwzrd/unixwzrd.github.io/discussions">unixwzrd/unixwzrd.github.io · Discussions</a>: 探索 unixwzrd unixwzrd.github.io 的 GitHub Discussions 论坛。讨论代码、提出问题并与开发者社区协作。</li><li><a href="https://status.openai.com/">OpenAI 状态</a>: 未找到描述</li><li><a href="https://codeium.com/changelog">Windsurf 编辑器更新日志 | Windsurf 编辑器和 Codeium 扩展</a>: Windsurf 编辑器的最新更新和变化。
</li>
</ul>

</div>
  

---


### **aider (Paul Gauthier) ▷ #[general](https://discord.com/channels/1131200896827654144/1131200896827654149/1316494886752620645)** (1026 条消息🔥🔥🔥): 

> `O1 Pro 性能，Gemini Flash，DeepSeek，Devin AI，OpenHands`

- **O1 Pro 作为调试工具**：用户报告称 O1 Pro 在调试方面非常高效，通常一次尝试就能修复问题，而其他模型在处理重复性或复杂任务时往往表现挣扎。
   - 一些用户分享了对 Sonnet 的不满，指出与 O1 Pro 的高效相比，它在进行简单编辑时经常陷入无限循环。
- **Gemini Flash 性能**：Gemini 2.0 Flash 因其速度和准确性而受到赞誉，在编辑模式下得分很高，并为编程任务提供了巨大的 Context Window。
   - 虽然部分用户的体验褒贬不一，但许多人认为它适合实际应用，特别是与编辑器模型结合使用时。
- **DeepSeek 的挑战**：用户表达了通过 OpenRouter 访问 DeepSeek 时的沮丧，理由是性能缓慢且错误频繁，而一些直接使用 DeepSeek 的用户则有更好的体验。
   - 尽管面临挑战，DeepSeek 仍因其准确性而受到关注，这使得一些人尽管面临性能问题仍继续使用它。
- **对 Devin AI 的批评**：Devin AI 因其高昂的成本和缺乏有效的编程能力而受到批评，用户开玩笑说其表现与预期相比非常糟糕。
   - 一位用户提到在糟糕的体验后启动了退款流程，凸显了对该模型可靠性的担忧。
- **OpenHands 的开发**：OpenHands 因其快速的更新和改进而获得认可，用户注意到开发者对问题的响应非常迅速，并定期进行增强。
   - 那些测试 OpenHands 的用户报告了积极的体验，特别是最近的修复解决了之前的困扰。


<div class="linksMentioned">

<strong>提及的链接</strong>：

<ul>
<li>
<a href="https://x.com/sdrzn/status/1867271665086074969">来自 Saoud Rizwan (@sdrzn) 的推文</a>：Cline 现在可以使用 MCP 为自己创建并添加工具了！试着让它“添加一个获取最新 npm 文档的工具”——Cline 会处理从创建 MCP 服务器到将其安装到……的所有工作。</li><li><a href="https://mcp-get.com/">MCP 软件包注册表 | Model Context Protocol 软件包管理</a>：未找到描述</li><li><a href="https://www.anthropic.com/news/anthropic-amazon-trainium">与 AWS 共同助力下一代 AI 开发</a>：今天我们宣布扩大与 AWS 在 Trainium 上的合作，以及来自 Amazon 的 40 亿美元新投资。</li><li><a href="https://app.devin.ai/sessions/266955553baf40cfa7fdd32d42ab219d">寻找 issue 85 的解决方案</a>：你可靠的 AI 软件工程师</li><li><a href="https://app.devin.ai/sessions/266955553baf40cfa7f">Devin (开发者)</a>：你可靠的 AI 软件工程师</li><li><a href="https://x.com/zeddotdev/status/1866909952268235077">来自 Zed (@zeddotdev) 的推文</a>：🚀 隆重推出 Zed v0.165！就像你可以拆分编辑器面板一样，现在你也可以拆分终端面板了。</li><li><a href="https://tenor.com/view/one-piece-one-piece-movie-6-one-piece-baron-omatsuri-baron-omatsuri-and-the-secret-island-op-movie-6-gif-13794598097003310170">海贼王剧场版 6 GIF - 海贼王剧场版 6 祭典男爵与神秘岛 - 发现并分享 GIF</a>：点击查看 GIF</li><li><a href="https://aider.chat/docs/leaderboards/">Aider LLM 排行榜</a>：LLM 代码编辑能力的定量基准。</li><li><a href="https://openrouter.ai/docs/provider-routing',">OpenRouter</a>：LLMs 的统一接口。为你的提示词寻找最佳模型和价格</li><li><a href="https://x.com/Google/status/1866869309277937937">来自 Google (@Google) 的推文</a>：隆重推出 Gemini 2.0，这是我们迄今为止最强大的 AI 模型，专为 Agent 时代设计。Gemini 2.0 带来了更强的性能、更多的多模态能力以及全新的原生工具使用。</li><li><a href="https://www.warp.dev">Warp：智能终端</a>：Warp 是一款内置 AI 和开发团队知识库的智能终端。现已支持 MacOS 和 Linux。</li><li><a href="https://aider.chat/docs/usage/copypaste.html">通过 Web 聊天进行复制/粘贴</a>：Aider 可与 LLM Web 聊天界面配合使用</li><li><a href="https://tenor.com/view/i-am-the-outlaw-walton-goggins-boyd-crowder-justified-i-am-a-bad-guy-gif-27308106">I Am The Outlaw Walton Goggins GIF - I Am The Outlaw Walton Goggins Boyd Crowder - 发现并分享 GIF</a>：点击查看 GIF</li><li><a href="https://aider.chat/docs/usage/watch.html">IDE 中的 Aider</a>：Aider 不仅可以在命令行运行，还可以在浏览器中运行。</li><li><a href="https://github.com/Aider-AI/conventions">GitHub - Aider-AI/conventions：供 aider 使用的社区贡献规范文件</a>：供 aider 使用的社区贡献规范文件 - Aider-AI/conventions</li><li><a href="https://pieces.app">Pieces for Developers — 开发工作流的长期记忆</a>：Pieces 是你的 AI 助手，可捕获从浏览器到 IDE 及协作工具的实时上下文，管理代码片段并支持多种 LLMs。</li><li><a href="https://github.com/Upsonic/gpt-computer-assistant">GitHub - Upsonic/gpt-computer-assistant：带有生产级 API 的 Docker 化 Computer Use Agents - 用于 Langchain 的 MCP 客户端 - GCA</a>：带有生产级 API 的 Docker 化 Computer Use Agents - 用于 Langchain 的 MCP 客户端 - GCA - Upsonic/gpt-computer-assistant</li><li><a href="https://github.com/robert-at-pretension-io/mcp">GitHub - robert-at-pretension-io/mcp：代码</a>：代码。通过在 GitHub 上创建账号来为 robert-at-pretension-io/mcp 的开发做出贡献。</li><li><a href="https://github.com/Aider-AI/aider-install">GitHub - Aider-AI/aider-install：aider 的精简安装程序</a>：aider 的精简安装程序。通过在 GitHub 上创建账号来为 Aider-AI/aider-install 的开发做出贡献。</li><li><a href="https://github.com/lee88688/aider-composer">GitHub - lee88688/aider-composer：Aider 的 VSCode 扩展，无缝集成到 VSCode 中</a>：Aider 的 VSCode 扩展，无缝集成到 VSCode 中 - GitHub - lee88688/aider-composer：Aider 的 VSCode 扩展，无缝集成到 VSCode 中
</li>
</ul>

### **aider (Paul Gauthier) ▷ #[questions-and-tips](https://discord.com/channels/1131200896827654144/1133060505792159755/1316501289781166132)** (90 条消息🔥🔥): 

> `Aider 安装问题、Aider 与 Rust 依赖、Gemini 模型对比、Aider 的注释功能、Aider 用户体验与反馈` 


- **不同系统上的 Aider 安装**：用户表达了在全局安装 Aider 时遇到的挑战，其中一位指出使用 `uv tool install aider-chat` 是一个简便的解决方案。
   - 安装过程中的警告（如 OpenSSL 兼容性问题）也被讨论，但被认为可以忽略。
- **Aider 与 Rust 依赖澄清**：澄清了 Aider 不会拉取外部 Rust 依赖或当前仓库之外的任何其他语言，仅关注已提交的代码。
   - 用户想知道未来扩展知识上下文以包含外部依赖的计划。
- **Gemini 模型响应的差异**：用户报告称 Aider 中的 Gemini 模型提供的体育比分比 Web 界面旧，这表明通过 API 无法访问最近的事件。
   - 强调了具有和不具有 Web 搜索功能的模型之间的区别，引发了对信息一致性的担忧。
- **Aider 注释功能的挑战**：用户对 Aider 的自动注释过程表示担忧，有时它会在不进行更改的情况下删除注释，导致困惑。
   - 反馈表明，用户希望对编辑过程有更多控制权，以确保仅完成指定的任务。
- **Aider 用户体验与反馈**：用户分享了他们使用 Aider 的各种经验，讨论了其在项目设置中的有效使用，同时表达了对额外反馈机制的需求。
   - 一些用户建议在解决查询后清除聊天记录以保持清晰，而另一些用户则强调了总结先前操作的重要性。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://ai.google.dev/gemini-api/docs/models/gemini-v2">未找到标题</a>: 未找到描述</li><li><a href="https://aider.chat/docs/languages.html">支持的语言</a>: Aider 支持几乎所有流行的编程语言。</li><li><a href="https://docs.astral.sh/uv/concepts/tools/#tool-environments)">工具 | uv</a>: 未找到描述</li><li><a href="https://github.com/simonw/llm-claude-3/issues/16#issuecomment-2432863499)">由于 PyO3 依赖导致安装失败 - 与 Python 3.13 不兼容 · Issue #16 · simonw/llm-claude-3</a>: 我刚刚在 M1 Mac 上通过 brew 全新安装了 llm，然后执行了 llm install llm-claude-3。在这里，我遇到了以下错误：Building wheels for collected packages: tokenizers Building wheel ...
</li>
</ul>

</div>
  

---


### **Cursor IDE ▷ #[general](https://discord.com/channels/1074847526655643750/1074847527708393565/1316494892301815899)** (620 条消息🔥🔥🔥): 

> `Gemini vs Claude、Cursor 性能、AI 工具与价格、Web 托管解决方案、编程挑战` 


- **Gemini 2.0 与 Claude 对比**：用户对 Gemini 2.0 的评价褒贬不一，一些人称赞其能力，而另一些人则在编码任务上仍然忠于 Claude。
   - 对它们的性能进行了比较，有人声称尽管 Gemini 有所进步，但 Claude 在编码准确性方面仍处于领先地位。
- **Cursor 性能与反馈**：围绕 Cursor 最近的更新进行了讨论，用户对当前聊天和 Composer 功能的性能和局限性表示不满。
   - 一些用户提出了改进 AI 规则的方法，以优化 Cursor 内的查询和响应。
- **AI 工具与定价**：Cursor 和 Gemini 等 AI 工具的性价比是一个争论的话题，用户正在考虑它们相对于所提供产出的价值。
   - 用户对 AI 工具的支出以及美元订阅与市场上其他可用选项的对比表示担忧。
- **Web 托管解决方案**：用户建议使用 Railway 和 Cloudflare Workers 等平台进行服务器托管，强调需要根据项目类型进行选择。
   - 不同托管解决方案的成本和可用性引发了开发者之间关于偏好的讨论。
- **编程文化与幽默**：出现了关于代际编程风格的轻松对话，并引用了描绘 Gen Z 程序员的幽默 YouTube 视频。
   - 用户分享了他们对这些趋势对编码质量和职场互动潜在未来影响的担忧。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://livebench.ai/">LiveBench</a>: 未找到描述</li><li><a href="https://docs.cursor.com/advanced/models#what-context-window-is-used-for-model-x">Cursor - Build Software Faster</a>: 未找到描述</li><li><a href="https://supermaven.com/">Supermaven: Free AI Code Completion</a>: 最快的 Copilot。Supermaven 使用 100 万 token 的上下文窗口来提供最高质量的代码补全。</li><li><a href="https://www.youtube.com/watch?v=s0Gw6dfk91g"> - YouTube</a>: 未找到描述</li><li><a href="https://forum.cursor.com/t/how-to-do-fix-in-composer-and-fix-in-chat-actions-from-keyboard/31221">如何在键盘上执行 `Fix in Composer` 和 `Fix in Chat` 操作</a>: 这两个：我在设置中找不到。</li><li><a href="https://vanilla-components.com/">Vanilla Components</a>: 一个轻量、灵活且可定制的 Vue 3 UI 库，使用 Tailwind CSS 进行样式设计</li><li><a href="https://tenor.com/view/unemployment-unemployed-laid-off-layoffs-layoff-gif-17329141">Unemployment Unemployed GIF - Unemployment Unemployed Laid Off - Discover &amp; Share GIFs</a>: 点击查看 GIF</li><li><a href="https://tenor.com/view/claptrap-robot-gif-13502248">Claptrap Robot GIF - Claptrap Robot - Discover &amp; Share GIFs</a>: 点击查看 GIF</li><li><a href="https://tenor.com/view/wait-what-wait-a-minute-huh-gif-17932668">Wait What Wait A Minute GIF - Wait What Wait A Minute Huh - Discover &amp; Share GIFs</a>: 点击查看 GIF</li><li><a href="https://tenor.com/bLCZX.gif">Emobob Sponegbob GIF - Emobob Sponegbob Emo - Discover &amp; Share GIFs</a>: 点击查看 GIF</li><li><a href="https://docs.adonisjs.com/guides/views-and-templates/inertia">Inertia</a>: 未找到描述</li><li><a href="https://www.youtube.com/watch?v=k-uXBLFuHe0">我们需要阻止 Z 世代程序员 ✋😮‍💨 #coding</a>: 未找到描述</li><li><a href="https://status.cursor.com/">Cursor Status</a>: 未找到描述</li><li><a href="https://codecourse.com/articles/livewire-or-inertiajs-which-one-should-you-choose">Livewire 还是 Inertia.js。你应该选择哪一个？</a>: Livewire 和 Inertia 都是在 Laravel 中构建应用程序的极受欢迎的技术栈。如果你在两者之间犹豫不决，让我们权衡一下哪一个适合你。</li><li><a href="https://youtu.be/oU3H581uCsA?si=4aBg2C3EvcVh3BzD">Devin 评测：它是一个比 Cursor 更好的 AI 编程 Agent 吗？</a>: 阅读完整评测：https://www.builder.io/blog/devin-vs-cursor</li><li><a href="https://github.com/getcursor/docs">GitHub - getcursor/docs: Cursor 的开源文档</a>: Cursor 的开源文档。通过在 GitHub 上创建账户为 getcursor/docs 的开发做出贡献。</li><li><a href="https://codeium.com/changelog">Windsurf Editor 更新日志 | Windsurf Editor 和 Codeium 扩展</a>: Windsurf Editor 的最新更新和变化。</li><li><a href="https://www.youtube.com/shorts/oy0QD-40ppg">Z 世代程序员疯了吗？😅… #coding</a>: 未找到描述</li><li><a href="https://cursor.directory/">Cursor Directory</a>: 为你的框架和语言寻找最佳的 Cursor 规则。
</li>
</ul>

</div>
  

---


### **OpenAI ▷ #[annnouncements](https://discord.com/channels/974519864045756446/977259063052234752/1316825023620845678)** (1 条消息): 

> `OpenAI 的 12 天，圣诞模式，Advanced Voice 功能` 


- **OpenAI 第 6 天揭晓圣诞模式**: 最新的 [YouTube 视频](https://www.youtube.com/live/NIQDnWlwYyQ?si=vOsHQx2zV_W0Pz2s) 展示了新的 **Santa 语音**，该功能与 **Advanced Voice** 中的 **视频** 和 **屏幕共享** 功能一同推出。
   - Kevin Weil 及其团队提供了演示，同时鼓励观众体验这些节日功能。
- **关注 OpenAI 的 12 天最新动态**: 鼓励成员通过在指定频道领取 **role**（角色），在 **OpenAI 的 12 天** 活动期间保持关注。
   - 通过提及角色定制选项来增强参与感，从而促进社区互动。



**提到的链接**: <a href="https://www.youtube.com/live/NIQDnWlwYyQ?si=vOsHQx2zV_W0Pz2s">Advanced Voice 中的圣诞模式与视频——OpenAI 的 12 天：第 6 天</a>: Kevin Weil、Jackie Shannon、Michelle Qin 和 Rowan Zellers 介绍并演示了新的 Santa 语音，以及 Advanced Voice 中的视频和屏幕共享功能。

  

---

### **OpenAI ▷ #[ai-discussions](https://discord.com/channels/974519864045756446/998381918976479273/1316495564472324280)** (417 条消息🔥🔥🔥): 

> `Project Astra, Gemini 2.0 vs. OpenAI, AI Image Generation, Voice AI Developments, AI Model Comparisons` 


- **Project Astra 准备挑战 OpenAI**：讨论强调了对 **Project Astra** 的期待，一些人表示相信它可能会超越 OpenAI 的产品。
   - 一位用户暗示 **Gemini 2.0** 的发布可能会改变 AI 领域的格局。
- **Gemini 2.0 被认为优于 OpenAI**：用户注意到 **Gemini 2.0 Flash** 目前已在网页端上线，其性能相比 OpenAI 的模型获得了积极反馈。
   - 然而，一些用户报告了由于 Bug 导致实时视频读取等特定功能出现问题。
- **AI 图像生成工具引发热议**：几位用户讨论了他们使用各种 AI 图像生成工具（如 **Hailuo** 和 **Sora**）的体验，并强调由于免费额度导致服务拥挤。
   - 他们分享了生成的内容，对输出质量有不同的反馈，特别是在使用各种视频格式时。
- **Voice AI 技术不断进步**：围绕 Voice AI 的对话表明，**ElevenLabs** 的技术正在接受真实性测试，在与真人声音的辨识度方面结果褒贬不一。
   - 用户正尝试复制类人的语音输出，但承认在某些语调起伏方面存在挑战。
- **对 AI 服务的普遍不满**：许多人讨论了对服务推出的挫败感，特别是与 Gemini 等替代方案相比，OpenAI 的实施速度较慢。
   - 一些用户对遇到的音频质量问题表示担忧，强调了移动端和桌面端平台之间的体验差异。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://tenor.com/view/yap-yapper-yapping-what-huh-gif-17267607410251793922">Yap Yapper GIF - Yap Yapper Yapping - Discover &amp; Share GIFs</a>: 点击查看 GIF</li><li><a href="https://github.com/AlignAGI/Alignment/">GitHub - AlignAGI/Alignment: Promoting global awareness and action for ethical AI alignment and safeguarding humanity against AI self-replication risks. Includes research, frameworks, and open-source resources.</a>: 促进全球对伦理 AI 对齐的意识和行动，保护人类免受 AI 自我复制风险。包括研究、框架和开源资源。 - AlignAGI/Alig...</li><li><a href="https://www.youtube.com/results?search_query=what+is+chatgpt+o1">未找到标题</a>: 未找到描述
</li>
</ul>

</div>
  

---


### **OpenAI ▷ #[gpt-4-discussions](https://discord.com/channels/974519864045756446/1001151820170801244/1316518132051083344)** (21 条消息🔥): 

> `OpenAI service outage, Custom GPT file format, ChatGPT recovery updates, AI view feature release, User API call handling` 


- **OpenAI 服务中断更新**：12 月 11 日 **太平洋标准时间 (PST) 下午 3:16 至晚上 7:38**，一次已知的故障影响了 OpenAI 服务，API 的流量恢复大约在 **下午 5:40** 开始。
   - 根据最新更新，**所有服务现已完全恢复运行**，OpenAI 将对此次事件进行根本原因分析。
- **Custom GPT 的最佳文件格式**：一位用户询问了在 Custom GPT 中存储场景的理想文件格式，目前使用的是带有表格的 Word 文档。
   - 另一位用户建议 **简单的文本文件** 是最好的，因为易于访问且没有不必要的格式复杂性。
- **ChatGPT 恢复进展**：用户报告 ChatGPT 开始恢复，但对于完全恢复的时间表仍不确定。
   - 一位用户幽默地建议在等待服务恢复期间休息一下看场电影。
- **AI view 功能推出**：针对有关 AI view 功能的问题，一位用户确认该功能 **正在推出中**。
   - 随着该功能从演示状态转为正式上线，关于其全面可用性的细节仍待定。
- **在 Custom GPT 中处理 API 调用**：一位成员讨论了处理 API 调用时的挑战，特别是当初始请求失败时，需要重复尝试直到成功。
   - 另一位参与者强调，根据错误响应修正逻辑至关重要，并建议 **处理各种 HTTP 状态码**。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://status.openai.com/incidents/ctrsv3lwd797">API, ChatGPT &amp; Sora Facing Issues</a>: 未找到描述</li><li><a href="https://status.openai.com/">OpenAI Status</a>: 未找到描述
</li>
</ul>

</div>
  

---

### **OpenAI ▷ #[prompt-engineering](https://discord.com/channels/974519864045756446/1046317269069864970/1316500831176228934)** (5 messages): 

> `Canmore 交互函数，用于演示文稿幻灯片的 Custom GPT，格式化 Evals` 


- **Canmore 交互函数详解**：一位成员详细介绍了 **Canmore** 工具用于管理文本档的三个主要函数：`create_textdoc`、`update_textdoc` 和 `comment_textdoc`，每个函数都接受 JSON 格式的参数。
   - *不确定其准确性，但这是 4o 描述它的方式*，作为对所提供功能的免责声明。
- **请求用于讲座演示的 Custom GPT**：一位用户表示对一种 Custom GPT 感兴趣，该工具可以处理 PDF 演示文稿幻灯片并生成自然语言讲座，在增强演讲流畅性的同时保留逐字句。
   - 他们征求了现有解决方案的建议或开发此类工具的有效 Prompt。
- **关于规范工具名称的讨论**：一位成员确认 **canmore** 确实是所讨论工具的正确名称，并强调了其规范地位。
   - 这与之前的提及一致，为有关工具使用的对话增添了清晰度。
- **关于格式化 Evals 的咨询**：一位成员寻求关于如何正确格式化评估指标（Evals）的帮助，表示需要指导。
   - 该咨询目前仍是开放式的，尚未提供任何回复。


  

---


### **OpenAI ▷ #[api-discussions](https://discord.com/channels/974519864045756446/1046317269069864970/1316500831176228934)** (5 messages): 

> `Canmore 工具函数，用于讲座的 Custom GPT，格式化 Evals` 


- **Canmore 工具函数详情**：一位用户提供了关于 **Canmore** 工具运作方式的见解，概述了三个函数：`canmore.create_textdoc`、`canmore.update_textdoc` 和 `canmore.comment_textdoc`，每个函数都需要特定的 JSON 参数。
   - 另一位用户确认 **Canmore** 是该工具的正确规范名称，支持了最初参与者的描述。
- **请求 Custom GPT 讲座生成器**：一位用户表示对一种 Custom GPT 模型感兴趣，该模型可将 PDF 演示文稿幻灯片转换为自然语言讲座，强调在增强自然语言表达的同时，需要逐字包含每个句子。
   - 他们寻求现有模型或相关的 Prompt 来创建此类功能。
- **关于格式化 Evals 的咨询**：一位成员询问了在项目或讨论背景下格式化评估（Evals）的适当方式。
   - 对话中未就此格式化问题提供具体细节或指导。


  

---

### **Perplexity AI ▷ #[general](https://discord.com/channels/1047197230748151888/1047649527299055688/1316500025919934544)** (433 条消息🔥🔥🔥): 

> `Gemini 性能对比、Perplexity 应用问题、Pro 订阅疑问、O1 与推理模型、LinkedIn 集成公告` 


- **Gemini 可执行复杂研究但速度较慢**：用户注意到 **Gemini 1.5 Pro Deep Search** 在进行深度研究时非常有趣，并指出虽然它的表现可能优于 Perplexity，但响应时间明显更长。
   - 一位用户提到，与 Perplexity 较快的响应速度相比，Gemini 详尽的回答值得为详细研究而等待。
- **Perplexity 应用遇到用户界面问题**：多位用户对 **Perplexity MacOS app** 表示失望，强调了图标错位、高 CPU 占用率以及基本功能失效等问题。
   - 用户发现最初对文本输入的关注缺乏易用性，降低了 2024 年应有的整体体验。
- **Pro 订阅差异问题**：成员们对 Pro 订阅表示困惑，特别是关于限制和访问权限的问题，一些人报告服务突然不可用。
   - 有建议称，除非检测到滥用，否则 Perplexity 不会施加真正的限制，这促使用户询问其与 Enterprise Pro 产品的区别。
- **O1 推理模型被移除**：多位用户质疑 **O1 reasoning model** 从平台消失的原因，并表示在处理复杂查询时更倾向于使用它。
   - 讨论中提到该模型被认为是不必要的，因为 Pro 用户在处理复杂任务时可以自动触发推理功能。
- **LinkedIn 验证功能上线**：据宣布，Perplexity 正在推出 **LinkedIn verification**，允许用户连接其个人资料以获得潜在的增强功能。
   - 然而，这种集成的具体原因尚不清楚，引起了用户的好奇。


<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://tenor.com/view/back-to-work-get-back-to-work-working-grumpy-get-back-to-it-gif-12677234">Back To Work Get Back To Work GIF - Back To Work Get Back To Work Working - Discover &amp; Share GIFs</a>：点击查看 GIF</li><li><a href="https://x.com/aravsrinivas/status/1866938825043480813?s=61">来自 Aravind Srinivas (@AravSrinivas) 的推文</a>：@caviterginsoy o1 是不必要的（至少目前如此）。Pro 中的推理功能会在查询复杂时自动触发。</li><li><a href="https://tenor.com/view/laugh-laughing-aman-gupta-meme-aman-gupta-boat-aman-gupta-gif-25305713">Laugh Laughing GIF - Laugh Laughing Aman Gupta Meme - Discover &amp; Share GIFs</a>：点击查看 GIF</li><li><a href="https://aistudio.google.com/">Google AI Studio</a>：Google AI Studio 是开始使用 Gemini（我们下一代多模态生成式 AI 模型系列）进行构建的最快方式。</li><li><a href="https://tenor.com/view/confused-kid-black-umm-mahmoud-gif-11362661">Confused Kid GIF - Confused Kid Black - Discover &amp; Share GIFs</a>：点击查看 GIF</li><li><a href="https://tenor.com/view/willem-dafoe-looking-up-scared-among-us-gif-27315085">Willem Dafoe Looking Up GIF - Willem Dafoe Looking Up Scared - Discover &amp; Share GIFs</a>：点击查看 GIF</li><li><a href="https://x.com/testingcatalog/status/1867316249492943076?s=61">来自 TestingCatalog News 🗞 (@testingcatalog) 的推文</a>：新动态 🔥：Perplexity 正在推出 LinkedIn 验证！用户可以从 @perplexity_ai 的个人资料部分连接到他们的 LinkedIn 个人资料。但具体原因尚不完全清楚 👀</li><li><a href="https://status.perplexity.com/">Perplexity - 状态</a>：Perplexity 运行状态</li><li><a href="https://help.perplexity.supply/en/articles/10062097-why-has-my-order-not-arrived-yet">为什么我的订单还没到？ | Perplexity Supply 帮助中心</a>：未找到描述</li><li><a href="https://kpu.maisa.ai/play">Maisa KPU</a>：探索来自 Maisa 的 AI 操作系统 KPU</li><li><a href="https://help.perplexity.supply/en/articles/10062097-why-has-">为什么我的订单还没到？ | Perplexity Supply 帮助中心</a>：未找到描述
</li>
</ul>

</div>
  

---

### **Perplexity AI ▷ #[sharing](https://discord.com/channels/1047197230748151888/1054944216876331118/1316499956990738533)** (6 条消息): 

> `B650E Taichi 问题，Yong Yuan Niwan Cheng Sinaitoy，GPR 设备与方法论，诗歌请求，广告文案` 


- **B650E Taichi 冻结问题**：一位成员分享了一个链接，讨论了他们的 **B650E Taichi 主板**在某些更新后出现**冻结**的问题，并提供了[具体案例详情](https://www.perplexity.ai/search/my-b650e-taichi-freezes-after-1jqKbT81SEWwOeZLyK69Hg#3)。
   - 成员们正在讨论可能的解决方案和故障排除步骤，以解决冻结问题。
- **探索 Yong Yuan Niwan Cheng Sinaitoy**：另一个链接引起了对 **Yong Yuan Niwan Cheng Sinaitoy** 的关注，邀请读者参与其内容及其影响，可在此处访问 [here](https://www.perplexity.ai/search/yong-yuan-niwan-cheng-sinaitoy-UUBVfeyfTMORezndiNWicg)。
   - 围绕该话题的讨论似乎引起了人们对其背景和相关性的兴趣。
- **调查 GPR 设备与方法论**：一位成员引用了关于 **GPR 设备与方法论**的链接，以探索其在各个领域的应用，链接见 [此处](https://www.perplexity.ai/search/gpr-devices-and-methodologies-paoMOVomS9ejaHzJFka37A#0)。
   - 这引发了关于 GPR 技术中所使用的创新和技术的对话。
- **创意诗歌请求**：一位成员请求写一首关于特定主题的诗，通过链接 [此处](https://www.perplexity.ai/search/please-write-me-a-poem-about-t-ddSPj5KOQrSySXEijGVsWg#0) 分享了他们的创作意图。
   - 这一对创意的呼吁引发了参与者之间关于诗歌形式和风格偏好的讨论。
- **制作百万美元广告**：一位用户寻求帮助，希望制作一份引人注目的 **100 万美元**广告，其请求链接见 [此处](https://www.perplexity.ai/search/write-me-one-dollar-million-ad-cgDP.NLERDWQ4ottwio40g)。
   - 参与者开始集思广益，构思朗朗上口的短语和卖点，以优化广告的效果。


  

---


### **Perplexity AI ▷ #[pplx-api](https://discord.com/channels/1047197230748151888/1161802929053909012/1316529118476505280)** (6 条消息): 

> `Perplexity API 银行卡支付问题，3D Secure 交易问题，Perplexity Pages 的创建` 


- **API 银行卡支付问题导致 UI 冻结**：一位成员报告称，在 Perplexity API 中添加卡会导致 **UI 冻结**，随后出现并消失 **银行的 3D Secure** 屏幕，表明交易未获得授权。
   - 这引发了关于潜在解决方案以及不使用 3D Secure（这是银行的标准做法）所面临挑战的讨论。
- **无法绕过 3D Secure**：另一位成员强调 **3D Secure** 是必要的，因为他们所在地区的大多数银行都实施了该功能，导致没有此安全功能就无法继续。
   - 他们正在寻找替代解决方案，以便在使用所需安全措施的同时避免 Perplexity API 的问题。
- **请求 Perplexity Pages 的 API 端点**：一位成员询问是否存在用于创建 **Perplexity Pages** 的 **API 端点**。
   - 作为回应，另一位用户澄清说 **API** 和 **Perplexity 网站**是不同的产品，目前主站**没有 API**。


  

---

### **Unsloth AI (Daniel Han) ▷ #[general](https://discord.com/channels/1179035537009545276/1179035537529643040/1316494879169183835)** (265 messages🔥🔥): 

> `DPO with Llama 3.3, Merging models and quantization, LoRA adapters and fine-tuning, 4-bit vs 16-bit model merging, Unsloth license and compatibility` 


- **成功的 DPO 实现**：成员们确认 Direct Preference Optimization (DPO) 可以成功用于 [Llama 3.3](https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-bnb-4bit)，并提供了现有的文档和示例。
   - Theyruinedelise 提到文档为实现 DPO 提供了清晰的指导，提高了参与者的易用性。
- **模型合并的复杂性**：关于模型合并的风险和建议进行了广泛讨论，特别是针对合并到 4-bit 的情况，为了保持 LoRA 微调模型的质量，不建议这样做。
   - Disgrace6161 解释说，将 LoRA 适配器合并到 4-bit 模型中可能会降低性能，主张先合并到全精度（full precision）。
- **LoRA 与微调实践**：参与者分享了在微调中使用 LoRA 适配器的见解，强调虽然 LoRA 可以优化 VRAM 使用，但合并时应谨慎以维持模型质量。
   - 有人指出，LoRA 中更高的 rank 可能会带来更好的性能，但这取决于具体的任务和所使用的数据集。
- **量化考量**：讨论了 4-bit 量化与 16-bit 相比的有效性，成员们强调 4-bit 通常会显示出性能下降。
   - 反馈表明，4-bit 应该被视为最后一步，而不是初始合并，以避免模型准确性的复合退化。
- **Unsloth 许可证见解**：成员们触及了 Unsloth 采用不同许可证的原因，旨在保护知识产权不被其他实体挪用。
   - Theyruinedelise 澄清说，该许可旨在维护代码库的完整性，同时允许家庭用户不受限制地从中受益。


<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://www.determined.ai/blog/lora-parameters">Finding the best LoRA parameters</a>：alpha、rank 和学习率如何影响模型准确性，以及 rank-stabilized LoRA 是否有帮助。</li><li><a href="https://arxiv.org/abs/2405.09673">LoRA Learns Less and Forgets Less</a>：Low-Rank Adaptation (LoRA) 是一种广泛用于大型语言模型的参数高效微调方法。LoRA 通过仅对选定的权重矩阵训练低秩扰动来节省显存。在本文中...</li><li><a href="https://lightning.ai/pages/community/lora-insights/">Finetuning LLMs with LoRA and QLoRA: Insights from Hundreds of Experiments - Lightning AI</a>：LoRA 是训练自定义 LLM 最广泛使用的参数高效微调技术之一。从使用 QLoRA 节省显存到选择最佳 LoRA 设置，本文提供了实用的...</li><li><a href="https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-bnb-4bit">unsloth/Llama-3.3-70B-Instruct-bnb-4bit · Hugging Face</a>：未找到描述</li><li><a href="https://docs.unsloth.ai/basics/reward-modelling-dpo-orpo-and-kto">Reward Modelling - DPO, ORPO &amp; KTO | Unsloth Documentation</a>：要在 Unsloth 中使用 DPO、ORPO 或 KTO，请遵循以下步骤：</li><li><a href="https://www.kaggle.com/code/shaswatsingh69420/ddp-sft-trainer">multi gpu fine tuning </a>：使用 Kaggle Notebooks 探索并运行机器学习代码 | 使用来自“无附加数据源”的数据
</li>
</ul>

</div>
  

---


### **Unsloth AI (Daniel Han) ▷ #[off-topic](https://discord.com/channels/1179035537009545276/1179039861576056922/1316701342416371712)** (1 messages): 

> `SPDL: Faster AI Model Training, Thread-based Data Loading, Reality Labs AI Research` 


- **SPDL 加速 AI 模型训练**：[SPDL 博客文章](https://ai.meta.com/blog/spdl-faster-ai-model-training-with-thread-based-data-loading-reality-labs/) 讨论了 SPDL 如何通过实现 **thread-based data loading** 技术来优化 AI 模型训练。
   - 这种方法显著缩短了训练时间，提高了 **Reality Labs** 研究期间的性能效率。
- **Thread-based Data Loading 的影响**：通过利用 **thread-based data loading**，SPDL 能够简化数据管理并减少训练过程中的瓶颈。
   - 博客强调，这种方法对于处理更大的数据集和提高吞吐量（throughput）至关重要。


  

---

### **Unsloth AI (Daniel Han) ▷ #[help](https://discord.com/channels/1179035537009545276/1179777624986357780/1316519343143780435)** (15 条消息🔥): 

> `Unsoth AI Installation Issues, Fine-Tuning Process, Multi-GPU Training Memory Error, Using Colab for Training, Ollama Setup` 


- **寻求 Unsloth 模型训练帮助**：一位用户在尝试使用其提供的自定义 collator 训练模型 `unsloth/Llama-3.2-11B-Vision-Instruct` 时遇到了 `ValueError`。
   - 他们建议其他人提供协助，因为其他人可能对模型为何无法识别 token 有所见解。
- **关于开始微调的建议**：一名成员在成功安装 Unsloth 后表示不确定如何开始微调，促使另一名用户分享了相关主题的教程链接。
   - 该教程指导用户创建一个类似于 ChatGPT 的定制化个人助手。
- **多 GPU 微调期间的内存错误**：一位用户分享了他们的多 GPU 微调 notebook 链接，该 notebook 在训练几步后会触发内存错误，并请求帮助解决此问题。
   - 他们提供了一个托管在 Kaggle 上的 notebook 链接以便进一步分析。
- **用于 Unsloth 的 Colab Notebook**：一位用户发布了一个 Colab notebook 链接，用于访问与 Unsloth 相关的训练代码。
   - 该 notebook 旨在供希望实验该模型并排除故障的用户使用。
- **浏览 Unsloth 安装说明**：分享了关于正确安装程序的说明，以避免在设置 Unsloth 时出现问题，包括相关 GitHub 仓库的链接。
   - 重点强调了应使用说明中指定的适当模型版本开始微调过程。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://www.youtube.com/wat"> - YouTube</a>: 未找到描述</li><li><a href="https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing#scrollTo=2eSvM9zX_2d3">Google Colab</a>: 未找到描述</li><li><a href="https://www.kaggle.com/code/shaswatsingh69420/ddp-sft-trainer">multi gpu fine tuning </a>: 使用 Kaggle Notebooks 探索并运行机器学习代码 | 使用来自“无附加数据源”的数据</li><li><a href="https://docs.unsloth.ai/tutorials/how-to-finetune-ll">Unsloth Documentation</a>: 未找到描述</li><li><a href="https://docs.unsloth.ai/tutorials/how-to-finetune-llama-3-and-export-to-ollama">How to Finetune Llama-3 and Export to Ollama | Unsloth Documentation</a>: 为在 Ollama 上本地运行而创建定制化个人助手（类似 ChatGPT）的初学者指南</li><li><a href="https://www.youtube.com/watch?v=V6LDl3Vjq-A">EASILY Train Llama 3 and Upload to Ollama.com (Must Know)</a>: 通过学习如何使用您自己的自定义数据微调这个强大的 AI 模型，释放 LLaMA 3.1 的全部潜力！🚀 在本视频中，我们将带您...</li><li><a href="https://github.com/unslothai/unsloth#installation-instructions---conda">GitHub - unslothai/unsloth: Finetune Llama 3.3, Mistral, Phi, Qwen 2.5 &amp; Gemma LLMs 2-5x faster with 80% less memory</a>: 以 2-5 倍的速度和减少 80% 的内存微调 Llama 3.3, Mistral, Phi, Qwen 2.5 和 Gemma LLM - unslothai/unsloth
</li>
</ul>

</div>
  

---

### **Unsloth AI (Daniel Han) ▷ #[research](https://discord.com/channels/1179035537009545276/1257011997250424842/1316537859209171025)** (3 messages): 

> `OpenPlatypus Dataset, Minimum Wage Debate in Stenland, QwQ Model Development, Mathematics Aptitude Test of Heuristics Dataset` 


- **OpenPlatypus 数据集发布**：发布了一个名为 **OpenPlatypus** 的新数据集，包含 **25,000 个样本**。该数据集是在 temperature 为 0 的情况下通过 **Qwen QwQ** 运行生成的，在 OpenRouter 上花费了 **$30**。
   - 建议排除长度超过 **5000 tokens** 和短于 **100 tokens** 的响应，并考虑在减小样本量后进行 k-means 聚类。
- **Stenland 的最低工资担忧**：一场讨论强调了在 Stenland 提高**最低工资**的担忧，特别是如果雇主面临更高成本，可能对就业产生潜在影响。
   - 提议的一个选项指出，如果**提高最低工资**不增加雇主对福利的缴费，这可能会减轻一些财务负担并缓解负面影响。
- **创建 QwQ 模型**：一名成员正在使用前述数据集开发 **14B** 和 **3B QwQ 模型**，但尚未进行测试。
   - 这种方法旨在将任何模型转换为 **QwQ** 版本，展示了模型适配的实际应用。
- **用于基准测试的 MATH 数据集**：**Mathematics Aptitude Test of Heuristics (MATH)** 数据集由来自各种数学竞赛的问题组成，包含详细的分步解决方案。
   - 建议利用该数据集对 **QwQ** 进行基准测试 (benchmarking)，同时过滤掉某些基准问题以进行相关的比较。


<div class="linksMentioned">

<strong>提及的链接</strong>：

<ul>
<li>
<a href="https://huggingface.co/datasets/hendrycks/competition_math">hendrycks/competition_math · Datasets at Hugging Face</a>：未找到描述</li><li><a href="https://huggingface.co/datasets/forcemultiplier/QwQ_OpenPlatypus_25k_jsonl">forcemultiplier/QwQ_OpenPlatypus_25k_jsonl · Datasets at Hugging Face</a>：未找到描述
</li>
</ul>

</div>
  

---

### **Stability.ai (Stable Diffusion) ▷ #[general-chat](https://discord.com/channels/1002292111942635562/1002292112739549196/1316508928724566136)** (208 messages🔥🔥): 

> `即将发布的 5090 GPU，GPU 的 Scalping 行为，图像生成的模型推荐，Stable Diffusion 模型的挑战，本地视频 AI 模型的 Discord 社区` 


- **对 5090 GPU 的期待**：成员们对预计在 1 月初发布的 **5090 GPU** 表示兴奋，并注意到其 **32GB VRAM** 的容量。
   - *In AI time, that like years*（在 AI 的时间维度里，那就像过了好几年）成为了一种反映等待 GPU 发布心情的幽默表达。
- **关于 Scalpers 和购买 GPU 的讨论**：对 **scalpers** 抢购 GPU 的担忧促使用户讨论使用 **web scrapers** 和其他方法来在发布日确保买到显卡。
   - 许多人表示需要耐心，有人指出如果不在美国境内，购买显卡会变得更加困难。
- **图像生成的模型推荐**：用户推荐了 **dream shaper**、**juggernaut** 和 **SDXL** 等模型用于生成特定内容（如 **spaceships**）。
   - 一些人建议在需要时尝试 **LoRA** 训练，而另一些人则指出 **8GB VRAM** 可能会受到限制。
- **Stable Diffusion 模型的挑战**：成员们讲述了在使用较旧模型（如 **WD1.4**）时遇到的困难，例如产生奇怪的结果。
   - 针对训练 **LoRA** 时对正则化图像（regularization images）进行 **captioning** 以改善结果提出了建议。
- **寻找视频 AI 模型的社区 Discord**：一位用户询问是否有讨论本地视频 AI 模型的优质 Discord 服务器，特别提到了 **Mochi, LTX, 和 HunYuanVideo**。
   - **Banodoco** Discord 服务器被推荐为一个适合感兴趣者的社区。


<div class="linksMentioned">

<strong>Links mentioned</strong>:

<ul>
<li>
<a href="https://www.reddit.com/r/StableDiffusion/comments/1enxdga/flux_recommended_resolutions_from_01_to_20/">Reddit - Dive into anything</a>: 未找到描述</li><li><a href="https://github.com/TencentQQGYLab/ComfyUI-ELLA?tab=readme-ov-file```">GitHub - TencentQQGYLab/ComfyUI-ELLA: ELLA nodes for ComfyUI</a>: ComfyUI 的 ELLA 节点。通过在 GitHub 上创建账号来为 TencentQQGYLab/ComfyUI-ELLA 的开发做出贡献。</li><li><a href="https://github.com/jhc13/taggui">GitHub - jhc13/taggui: Tag manager and captioner for image datasets</a>: 图像数据集的标签管理器和标注器。通过在 GitHub 上创建账号来为 jhc13/taggui 的开发做出贡献。</li><li><a href="https://civitai.com/models/67131/moe-mix">Moe Mix - v1.0 | Stable Diffusion Checkpoint | Civitai</a>: 这是我的第二次模型融合。它使用了 8 个不同的模型，包括一个自定义微调的 SD1.5 基础模型。请分享并尽情使用。
</li>
</ul>

</div>
  

---

### **Eleuther ▷ #[announcements](https://discord.com/channels/729741769192767510/794042109048651818/1316505161794846851)** (1 messages): 

> `Training Jacobian Analysis, Parameter Space Dynamics, Neural Network Training, Impact of Data on Training, Upcoming Papers Series` 


- **Training Jacobian 揭示参数依赖性**：这篇新论文分析了 **training Jacobian**，通过将参数空间中的一个小球体转换为椭球体，展示了最终参数如何依赖于其初始值。
   - **Jacobian singular values**（奇异值）指示了稳定和混沌子空间，其中稳定性在参数变化极小的 **bulk** 区域中得到强调。
- **识别出 Bulk 和混沌子空间**：该分析将奇异值谱分为三个区域：**chaotic** 区域、稳定的 **bulk**，以及一个随输入数据而非标签变化的低维结构。
   - 在 **white noise**（白噪声）上进行训练比在真实数据上训练更剧烈地压缩了参数空间，突显了其影响。
- **Jacobian 分析中的计算挑战**：计算整个 training Jacobian 对于较大的网络来说在 *计算上是不可行的 (computationally intractable)*，限制了深入分析。
   - 该研究主要使用了一个 **5K parameter MLP**，并在更大的模型（如 **62K parameter image classifier**）中发现了类似的奇异值趋势。
- **探索即将发布的研究论文**：这篇论文是关于 *neural network training dynamics* 和 **loss landscape geometry** 系列研究中的第一篇。
   - 鼓励感兴趣的参与者查看 <#1052314857384460398> 频道以进一步参与。
- **访问论文和代码**：可以通过 [arXiv](https://arxiv.org/abs/2412.07003) 访问论文，其中包括托管在 [GitHub](https://github.com/EleutherAI/training-jacobian) 上的补充代码。
   - 讨论中包括一个 [Twitter thread](https://x.com/norabelrose/status/1866943688993370381)，介绍了论文的见解及其影响。


<div class="linksMentioned">

<strong>提及的链接</strong>:

<ul>
<li>
<a href="https://arxiv.org/abs/2412.07003">Understanding Gradient Descent through the Training Jacobian</a>: 我们利用训练后的网络参数相对于其初始值的 Jacobian 矩阵来研究神经网络训练的几何学。我们的分析揭示了训练中的低维结构...</li><li><a href="https://github.com/EleutherAI/training-jacobian">GitHub - EleutherAI/training-jacobian</a>: 通过在 GitHub 上创建账户来为 EleutherAI/training-jacobian 的开发做出贡献。</li><li><a href="https://x.com/norabelrose/status/1866943688993370381">Nora Belrose (@norabelrose) 的推文</a>: 神经网络的最终参数如何取决于其初始参数？在这篇新论文中，我们通过分析 training Jacobian（最终参数对初始参数的导数矩阵）来回答这个问题...
</li>
</ul>

</div>
  

---

### **Eleuther ▷ #[general](https://discord.com/channels/729741769192767510/729741769738158194/1316500768978636810)** (70 messages🔥🔥): 

> `RWKV 模型发布, AdamW 权重衰减的重要性, NeurIPS 讨论, ARC 奖项争议, 对 VAR 论文不当行为的担忧` 


- **RWKV 模型亮相：Flock of Finches 与 QRWKV-6**：RWKV 团队宣布发布两个新模型：**Flock of Finches 37B-A11B** 和 **QRWKV-6 32B Instruct Preview**，展示了在多个任务上令人印象深刻的 Benchmark 结果。
   - *Flock of Finches* 在仅训练了 **1090 亿个 tokens** 的情况下表现出了极具竞争力的性能，而 **QRWKV-6** 在关键指标上已经超越了之前的 RWKV 模型。
- **AdamW 中权重衰减（Weight Decay）的重要性**：讨论了 AdamW 中 **权重衰减设置** 对影响奇异值（singular values）的重要性，并建议在相关论文中包含该设置。
   - 社区成员指出，不同的权重衰减设置可能会导致不同的结果，并强调了矩阵形状对权重缩放（weight scales）的影响。
- **NeurIPS 奖项争议与讨论**：ARC 奖项引发了成员间的辩论，有人声称其标准在不断变动（goalpost moving），并对其奖项结构的动机提出了批评。
   - 对话暗示了一些组织者可能采用了操纵手段，成员们对该 Benchmark 的有效性表示怀疑。
- **对 VAR 论文不当行为的担忧**：分享了一份关于 NeurIPS 2024 最佳论文第一作者 **Keyu Tian** 的报告，指控其在 ByteDance 实习期间存在严重的不当行为，包括恶意代码攻击。
   - 据报道，这些破坏性行为蓄意破坏了研究项目，导致学术界呼吁重新考虑该论文获得的荣誉。
- **算法推理与竞赛集**：一场热烈的交流突显了什么是真正的**算法推理（algorithmic reasoning）**的模糊性，特别是在竞赛集和暴力法（brute force）的背景下。
   - 成员们指出，Benchmark 理想情况下应该由人类解决，并批评了任何可能掩盖评估有效性的尝试。


<div class="linksMentioned">

<strong>提及的链接</strong>：

<ul>
<li>
<a href="https://var-integrity-report.github.io/">与 NeurIPS 2024 最佳论文奖相关的伦理挑战</a>：未找到描述</li><li><a href="https://bsky.app/profile/souravmishra.bsky.social/post/3ld34y3pzts2y">Bluesky</a>：未找到描述</li><li><a href="https://bsky.app/profile/main-horse.bsky.social/post/3lcgtluughk2c">main (@main-horse.bsky.social)</a>：很难想象在同时破坏其他团队的同时，完成这些操作所需的技能水平</li><li><a href="https://substack.recursal.ai/p/flock-of-finches-rwkv-6-mixture-of">Flock of Finches: RWKV-6 混合专家模型 (MoE)</a>：迄今为止最大的 RWKV MoE 模型！</li><li><a href="https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1">recursal/QRWKV6-32B-Instruct-Preview-v0.1 · Hugging Face</a>：未找到描述</li><li><a href="https://substack.recursal.ai/p/q-rwkv-6-32b-instruct-preview">Q-RWKV-6 32B Instruct Preview</a>：迄今为止最强、最大的 RWKV 模型变体：QRWKV6 32B Instruct Preview
</li>
</ul>

</div>
  

---


### **Eleuther ▷ #[research](https://discord.com/channels/729741769192767510/747850033994662000/1316496877801443338)** (117 messages🔥🔥): 

> `Muon 优化器, 负注意力权重, 注意力机制见解, 在模型中前置信息, 替代 Softmax 的方法`

- **Muon 优化器展现出潜力**：大家达成共识，认为 **Muon** 可能是近期最好的优化器之一，其底层数学原理既深刻又合理，相比 **AdamW** 等现有方法具有更好的性能表现。
   - 讨论反映了 Muon 中的梯度正交化（gradient orthogonalization）如何与最大流形容量损失（maximum manifold capacity loss）相关联，并将其与强化学习（reinforcement learning）中的正则化联系起来。
- **探索负注意力权重**：**Cog Attention** 的引入提出了一种允许负权重的注意力机制，这可能通过支持同时进行 token 的删除、复制或保留来增强模型的表达能力。
   - 同时也引发了对该方法有效性和潜在学习难度的担忧，特别是在数独（Sudoku）应用等特定场景下。
- **前置信息的挑战**：参与者讨论了在训练时前置辅助信息（如语言）但在测试时不包含这些信息的潜在弊端，以避免模型基于不准确的数据进行条件化。
   - 建议包括探索 EM-style 方法或修改输入表示，以增强模型在不依赖辅助信息的情况下的泛化能力。
- **创新的 Softmax 替代方案**：一位参与者建议探索传统 **softmax** 的替代方案，例如使用 tanh 变换为注意力机制创建不同的归一化方法。
   - 提出了一种实现多元版本 tanh 的探索性想法，旨在提高表达能力，同时解决标准 softmax 的局限性。
- **理解注意力机制的动态**：对注意力机制的动态进行了批判性审查，特别是使用负注意力权重等替代形式的影响以及对模型表达能力的作用。
   - 对话强调了在不牺牲有效处理信息所需的复杂性的前提下，在注意力中强制实现稀疏性（sparsity）的潜在替代方案。


<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://x.com/_arohan_/status/1866621771451076812?s=46">rohan anil (@_arohan_) 的推文</a>：秘密终于公开了：我下个月将加入 @AIatMeta 的 Llama 团队，致力于下一代 Llama 模型的研发。是的，在下一次……之前我已经准备好了一些 Llama 的双关语。</li><li><a href="https://arxiv.org/abs/2412.05270">APOLLO：类 SGD 的内存占用，AdamW 级别的性能</a>：大型语言模型 (LLMs) 在训练期间以内存密集著称，尤其是在使用流行的 AdamW 优化器时。这种内存负担使得必须使用更多或更高端的 GPU，或者减少……</li><li><a href="https://arxiv.org/abs/2410.23819">权重衰减诱导低秩注意力层</a>：训练深度神经网络时，权重衰减等正则化器的效果尚未被完全理解。我们研究了训练神经网络时权重衰减以及 $L2$-正则化的影响……</li><li><a href="https://arxiv.org/abs/2410.24206">通过中心流理解深度学习中的优化</a>：深度学习中的优化仍然难以理解，即使在确定性（即全批次）训练的简单设置下也是如此。一个关键难点在于优化器的许多行为是隐式的……</li><li><a href="https://kellerjordan.github.io/posts/muon/">Muon：神经网络隐藏层的优化器 | Keller Jordan 博客</a>：未找到描述</li><li><a href="https://arxiv.org/abs/2203.00555">DeepNet：将 Transformers 扩展到 1,000 层</a>：在本文中，我们提出了一种简单而有效的方法来稳定极深层的 Transformers。具体来说，我们引入了一个新的归一化函数 (DeepNorm) 来修改残差连接……</li><li><a href="https://arxiv.org/abs/2404.05405">语言模型的物理学：第 3.3 部分，知识容量缩放定律</a>：缩放定律描述了语言模型的大小与其能力之间的关系。与之前通过损失或基准测试评估模型能力的研究不同，我们估计了……</li><li><a href="https://arxiv.org/abs/2402.02098">当 QK 特征谱集中时，自注意力网络实现局部化</a>：自注意力机制在现代机器学习中占据主导地位。它具有一种有趣的功能，即通过调节注意力局部化程度，自适应地从输入序列中选择 token……</li><li><a href="https://arxiv.org/abs/2411.07176">具有负权重的更具表达力的注意力</a>：我们提出了一种名为 Cog Attention 的新型注意力机制，它允许注意力权重为负以增强表达能力，这源于两个关键因素：(1) Cog Attention 可以移动……</li><li><a href="https://arxiv.org/abs/2406.13138">大型语言模型之所以有偏见，是因为它们是大型语言模型</a>：本文的主要目标是引发关于偏见与大型语言模型基本属性之间关系的深入讨论。我们试图通过说服读者……</li><li><a href="https://arxiv.org/abs/1511.06429">利用侧信息进行学习的模式</a>：监督学习、半监督学习和无监督学习在给定输入/输出样本的情况下估计一个函数。通过结合侧信息，可以提高学习函数对未见数据的泛化能力……</li><li><a href="https://arxiv.org/abs/2404.04454v1">AdamW 的隐式偏置：$\ell_\infty$ 范数约束优化</a>：具有解耦权重衰减的 Adam（也称为 AdamW）因其在语言建模任务中的卓越性能而广受赞誉，在泛化方面超越了具有 $\ell_2$ 正则化的 Adam……</li><li><a href="https://arxiv.org/abs/2406.09366">迈向对最大流形容量表示的改进理解和利用</a>：最大流形容量表示 (MMCR) 是最近的一种多视图自监督学习 (MVSSL) 方法，它匹配或超越了其他领先的 MVSSL 方法。MMCR 很有趣，因为它并不……
</li>
</ul>

</div>
  

---


### **Eleuther ▷ #[lm-thunderdome](https://discord.com/channels/729741769192767510/755950983669874798/1316717404356608021)** (2 条消息): 

> `保存模型输出` 


- **保存模型输出是可行的**：一位成员提出了关于是否可以保存模型输出的问题。
   - 另一位成员解释说，通过使用 `--log_samples` 标志配合 `--output_path`，模型输出和输入模型的文本都将以每文档级别保存。
- **理解日志参数**：必须正确使用 `--log_samples` 标志，以确保正确记录模型的输出。
   - 此选项允许用户记录输出及相关的输入文本，从而增强模型性能的可追溯性。


  

---

### **LM Studio ▷ #[general](https://discord.com/channels/1110598183144399058/1110598183144399061/1316496775376404634)** (152 条消息🔥🔥): 

> `LM Studio Model Support, Running LLMs on Mac, Uncensored AI Models, Fine-tuning LLMs, GPU Configuration for LLMs` 


- **LM Studio 支持视觉模型，但存在局限性**：成员们讨论了虽然 LM Studio 确实支持某些视觉模型，但用户应注意并非所有模型（如 llama-3.2）都兼容。
   - 有人指出，如果计划附加图像进行分析，并非所有模型都能产生令人满意的结果。
- **在搭载 M4 Pro 和 Max 的 Mac 上运行 LLM**：讨论强调 M4 Pro 芯片可以运行 LLM，特别是至少配备 16GB RAM 的 8b 模型，而更大的模型则需要更多 RAM。
   - 提到 M4 Max 能够运行 70b 模型，但建议用户应优先考虑 RAM 以获得灵活性。
- **无审查 AI 模型的挑战**：一位用户对寻找创建无审查 AI 模型的指导感到沮丧，强调缺乏移除安全功能的清晰资源。
   - 建议探索 Unsloth 微调指南，并考虑使用旨在实现较少限制模型的训练数据集。
- **微调 LLM 及其可行性**：参与者讨论了微调 LLM 的复杂性，特别是在处理数值数据时，认为这可能无法提供预期的结果。
   - 提到了 RAG 等数据检索替代方案，表明传统的分析方法对于特定用例可能会产生更好的洞察。
- **GPU 配置与性能**：用户分享了关于其配置的见解，指出 GPU 规格和 RAM 显著影响模型性能。
   - 讨论了优先考虑 VRAM 而非原始算力的好处，强调了为模型加载提供适当缓解措施的重要性。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://huggingface.co/docs/autotrain/index">AutoTrain</a>: 未找到描述</li><li><a href="https://www.youtube.com/watch?v=zjkBMFhNj_g">[1hr Talk] Intro to Large Language Models</a>: 这是一个面向普通观众的 1 小时大语言模型介绍：ChatGPT、Claude 和 Bard 等系统背后的核心技术组件。什么是...</li><li><a href="https://www.youtube.com/watch?v=baQH7tsIQQ8"> - YouTube</a>: 未找到描述
</li>
</ul>

</div>
  

---


### **LM Studio ▷ #[hardware-discussion](https://discord.com/channels/1110598183144399058/1153759714082033735/1316568647610798121)** (29 条消息🔥): 

> `LM Studio GPU Usage, Intel GPU Purchasing Decisions, Gaming Laptop RAM Limitations, B580 GPU Reviews, RTX 3060 Comparisons` 


- **LM Studio 高效利用多 GPU**：成员们讨论了 **LM Studio** 可以将任务分配到多个 GPU 上，并确认它们应该是相同的“类型”，但不一定是相同的型号。
   - *Heyitsyorkie* 补充说，**LM Studio** 中的 GPU offload 只是一个开关，如果有可用的 GPU，它就会利用所有 GPU。
- **关于购买 Intel GPU 的辩论**：Koboldminion 对 **B580 GPU** 表示好奇，注意到它具有 **12GB VRAM** 且价格实惠，但对需要使用 Vulkan 持保留意见。
   - 其他人对 Intel GPU 用于 AI 用途持怀疑态度，*mlengle* 强调由于 **CUDA** 支持，更倾向于 Nvidia 选项。
- **游戏笔记本可能随 RAM 进步而改进**：有一场关于当前游戏笔记本 RAM 支持上限为 **64GB** 的对话，希望能有未来的 **128GB 或 256GB** 能力。
   - *Heyitsyorkie* 声称 Macbook 凭借其统一内存（unified RAM）方案，目前提供了最佳的 AI 便携解决方案。
- **对 B580 GPU 评测的关注**：一位成员分享了一个 [关于 B580 GPU 的 YouTube 视频](https://youtu.be/aV_xL88vcAQ?si=liMiC7spUMFY0LSF)，声称它提供了市场上最好的 **VRAM/价格比**。
   - 其他人期待 B580 的创新用途，例如组合多个单元进行基准测试。
- **RTX 3060 被视为可行的替代方案**：成员们讨论了 **RTX 3060**，提到了它的 **12GB VRAM** 以及 **$150-$250** 之间的实惠二手价格。
   - *mlengle* 指出了 Intel GPU 由于缺乏 CUDA 支持而存在的局限性，进一步强化了对 Nvidia 选项的偏好。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://huggingface.co/lmstudio-community">lmstudio-community (LM Studio Community)</a>: 未找到描述</li><li><a href="https://youtu.be/aV_xL88vcAQ?si=liMiC7spUMFY0LSF">Intel Arc B580 Review, The Best Value GPU! 1080P &amp; 1440p Gaming Benchmarks</a>: 在 Patreon 上支持我们：https://www.patreon.com/hardwareunboxedYT 会员：https://www.youtube.com/channel/UCI8iQa1hv7oV_Z8D35vVuSg/join 购买相关产品...
</li>
</ul>

</div>
  

---

### **Bolt.new / Stackblitz ▷ #[announcements](https://discord.com/channels/364486390102097930/671536649301131325/1316810488969035777)** (1 messages): 

> `Bolt 针织帽，2024 节日特惠` 


- **获取你的 Bolt 针织帽！**：作为 **2024 节日特惠** 的一部分，你现在可以以 **$30.00** 的价格购买 **Bolt 针织帽**，购买地址在 [这里](https://shop.bolt.new/en-usd/products/2024-holiday-special-x1f385)。
   - 这款针织帽由 **100% Turbo 腈纶面料**制成，采用均码设计，确保在这个节日季为你带来温暖与时尚。
- **商品质量保证**：Bolt 保证其产品质量；任何印刷错误或可见的质量问题都将获得更换或退款。
   - 然而，由于商品是按需定制的，因此不接受**常规退货**或**尺码相关的退货**。



**提及的链接**：<a href="https://shop.bolt.new/en-usd/products/2024-holiday-special-x1f385">2024 Holiday Special &#x1f385;</a>：StackBlitz 的官方网站和商店。查找最新的周边商品。

  

---


### **Bolt.new / Stackblitz ▷ #[prompting](https://discord.com/channels/364486390102097930/1301167628416454737/1316816223681646733)** (1 messages): 

> `删除所有对话，聊天记录错误` 


- **删除所有对话未能清除历史记录**：一位成员报告称，当他们点击“删除所有对话”时，实际上并没有移除 Prompt 中的聊天历史记录，这导致了持续的错误。
   - *有什么解决这个问题的建议吗？* 成员们对这个持续存在的问题表示沮丧。
- **聊天记录导致的重复错误**：另一位成员强调，无法删除聊天记录导致在 Prompting 会话期间出现重复错误。
   - 他们建议可能需要更好的基础设施来支持删除功能。


  

---


### **Bolt.new / Stackblitz ▷ #[discussions](https://discord.com/channels/364486390102097930/680953097354215446/1316497505080578158)** (174 messages🔥🔥): 

> `Token 使用问题，使用 Bolt 进行调试，Supabase 集成，前端 vs 全栈开发，功能请求与改进` 


- **Token 使用困惑**：用户报告了 Token 使用量的不一致，特别是在极少量使用后剩余 Token 显示为 'NaN'，引发了对底层问题的讨论。
   - 支持团队建议如果问题持续存在，请重新加载标签页或联系帮助中心，因为显示问题正在处理中。
- **Bolt 中的调试挑战**：几位用户在 Bolt 中遇到了调试问题，有时会导致过多的 Token 消耗而没有产生有效结果。
   - 建议包括使用更具针对性的 Prompt，以及使用文件固定（file pinning）来防止在复杂任务期间发生不必要的更改。
- **即将到来的 Supabase 集成**：社区讨论了将 Supabase 集成到 Bolt 中的潜力，许多人认为这将增强构建项目的功能。
   - 用户表示乐观，认为这种集成可以显著简化工作流程，特别是对于那些从 Firebase 等服务迁移过来的用户。
- **使用 Bolt 构建电子商务**：讨论围绕 Bolt 是否可以用于创建一个功能齐全的销售数字产品的电子商务网站展开，对其能力的看法不一。
   - 尽管在上下文管理方面存在潜在挑战，但用户仍受到了鼓励，并指出通过努力和引导式的 Prompting 是可以实现的。
- **功能请求与改进**：用户提出了功能建议，包括更好的 GitHub 集成以及对全栈应用的更多支持。
   - 社区强调了礼貌提出功能请求的重要性，并引导用户前往 GitHub issues 页面进行正式提交。


<div class="linksMentioned">

<strong>提及的链接</strong>：

<ul>
<li>
<a href="https://tenor.com/view/silly-cat-silly-car-car-stare-10-thousand-yard-stare-10-thousand-yard-gif-14200271775968563996">Silly Cat Silly Car GIF - Silly cat Silly car Car stare - Discover &amp; Share GIFs</a>：点击查看 GIF</li><li><a href="https://bolters.io/docs/understanding-cors">Understanding CORS in WebContainer</a>：了解跨源资源共享 (CORS)、其对 WebContainer 的影响以及当前的局限性</li><li><a href="https://bolters.io/docs/prompting-101">Prompting 101</a>：学习如何在 Bolt.new 中有效地与 AI 助手沟通</li><li><a href="https://bolters.io/docs/firebase-storage">Firebase Storage Integration</a>：学习如何在你的应用程序中集成 Firebase Storage 进行文件上传
</li>
</ul>

</div>
  

---

### **Notebook LM Discord ▷ #[use-cases](https://discord.com/channels/1124402182171672732/1124403655819415592/1316496544018600088)** (17 messages🔥): 

> `AI 自定义语音、TTRPG 角色扮演、后末日音乐剧、AI 生成播客、使用 NotebookLM 进行文献综述` 


- **用于播客的 AI 自定义语音**：几位成员对在播客中使用**自定义语音**表示了兴趣，其中一位建议使用 **Eleven Labs** 进行语音克隆。
   - 一位用户强调了使用**专业克隆语音**的愿望，这表明对个性化音频体验的需求日益增长。
- **使用 AI 运行 TTRPG 冒险**：一位成员询问如何使用 AI 运行 **TTRPG** 冒险（类似于单人 **D&D** 游戏），以获得沉浸式的叙事体验。
   - 另一位成员确认尝试过这种方法，表示虽然成功程度各异，但这是一个有趣的尝试。
- **探索后末日音乐剧**：一位用户建议创作一部**后末日音乐剧**，并引用了名为 *UNREAL MYSTERIES 6: The Christmas Special* 的 YouTube 视频，该视频融合了幽默与特定主题。
   - 这可能为结合音乐与反乌托邦背景的独特叙事方式铺平道路。
- **AI 生成的视频播客**：一个新的 AI 生成视频播客以原始人和 AI 聊天机器人为主角，探讨了诸如“生命的意义”等深刻主题。
   - 该剧集承诺将幽默与深度对话相结合，展示了古代与现代视角之间有趣的动态。
- **在 NotebookLM 中进行文献综述的挑战**：一位学生研究员分享了使用 **NotebookLM** 进行文献综述的经验，提到了在从论文中提取详细信息方面的局限性。
   - 这引发了关于在使用该工具进行学术研究时，如何增强洞察深度的可能解决方案的讨论。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://notebooklm.google.com/notebook/e20a4db8-24b9-4f16-ba85-41f3b204cb79/audio">未找到标题</a>：未找到描述</li><li><a href="https://youtu.be/dbCqtRgBxdY">AI Podcast Caveman &amp; Chatbot</a>：当 AI 遇见石器时代：全新的视频播客来了！🪨🤖🎙️ 深刻的问题。永恒的智慧。意想不到的主持人。介绍一个开创性的...</li><li><a href="https://www.youtube.com/watch?v=3OFeH9YFxjM">UNREAL MYSTERIES 6: The Christmas Special - a Post-Apocalyptic Musical</a>：每个好节目都有圣诞特辑，而每个好的圣诞特辑都是音乐剧……David 和 Hannah 对抗僵尸驯鹿、澳大利亚外星人以及 l...</li><li><a href="https://youtu.be/ufe-EWH3_gc?si=C8lneeoL82j1kT1T">Women Suck at EVERYTHING?! Debating Fresh and Fit&#39;s Myron Gaines @StandOutTV_</a>：来自 FreshandFit 播客的 Myron Gaines 认为女性在所有事情上都很差劲。从开车到运动，他认为女性不如男性。加入我一起辩论...
</li>
</ul>

</div>
  

---


### **Notebook LM Discord ▷ #[general](https://discord.com/channels/1124402182171672732/1124402182909857966/1316528021594705973)** (125 messages🔥🔥): 

> `NotebookLM 更新、播客自定义、YouTube 视频摘要、Gemini 2.0、来源管理` 


- **NotebookLM 将通过交互功能进行 UI 重构**：NotebookLM 将迎来全新的 UI，包含 **Sources**、**Chat** 以及 **Notes & Audio Overview** 的独立板块，并推出“Interactive Audio Beta”，允许与主持人进行实时交互 [Tweet](https://x.com/testingcatalog/status/1867251820986302787?s)。
   - 此次更新旨在通过改进导航和易用性来提升用户体验。
- **播客自定义的挑战**：用户表示在自定义播客角色性格和控制长度方面存在困难，建议使用特定的 Prompt 以获得更好的效果。
   - 建议将原始来源链接整合到笔记中，以便日后参考。
- **关于 Gemini 2.0 能力的讨论**：预计 Gemini 2.0 的性能将优于现有模型，期待更高的输出 Token 限制和高级功能 [source](https://x.com/testingcatalog/status/1867251820986302787?s)。
   - 也有人对与之前模型相比可能存在的上下文窗口（context window）大小限制表示担忧。
- **在 NotebookLM 中管理来源**：用户注意到目前在上传后检索原始来源链接存在局限性，建议采用将链接作为标题复制等做法以便参考。
   - 这一权宜之计旨在保持生成回复中所使用的提取文本来源的清晰度。
- **与 YouTube 及外部工具的互动**：成员们分享了 YouTube 视频链接和有助于总结内容以获得更好学习效果的工具。
   - 同时也强调了利用各种平台增强学习体验的重要性。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://imgur.com/a/30PAOYB">imgur.com</a>: 在 Imgur 发现互联网的魔力，这是一个由社区驱动的娱乐目的地。通过幽默的笑话、热门的 memes、有趣的 gifs、感人的故事、病毒式传播的视频等来振奋你的精神...</li><li><a href="https://x.com/testingcatalog/status/1867251820986302787?s=19">来自 TestingCatalog News 🗞 (@testingcatalog) 的推文</a>: 重磅消息 🚨：NotebookLM 将获得全新的 UI 更新，包含 Sources、Chat 以及 Notes & Audio Overview 三个独立板块 👀。这还伴随着一个 "Interactive Audio Beta"，用户将可以...</li><li><a href="https://x.com/testingcatalog/status/1867251820986302787?s">来自 TestingCatalog News 🗞 (@testingcatalog) 的推文</a>: 重磅消息 🚨：NotebookLM 将获得全新的 UI 更新，包含 Sources、Chat 以及 Notes & Audio Overview 三个独立板块 👀。这还伴随着一个 "Interactive Audio Beta"，用户将可以...</li><li><a href="https://x.com/testingcatalog/status/1867251820986302787?s=12&t=ccIP884aIouoWLyTaNwi-g">来自 TestingCatalog News 🗞 (@testingcatalog) 的推文</a>: 重磅消息 🚨：NotebookLM 将获得全新的 UI 更新，包含 Sources、Chat 以及 Notes & Audio Overview 三个独立板块 👀。这还伴随着一个 "Interactive Audio Beta"，用户将可以...</li><li><a href="https://x.com/testingcatalog/status/1867251820986302787?s=46&t=ccIP884aIouoWLyTaNwi-g">来自 TestingCatalog News 🗞 (@testingcatalog) 的推文</a>: 重磅消息 🚨：NotebookLM 将获得全新的 UI 更新，包含 Sources、Chat 以及 Notes & Audio Overview 三个独立板块 👀。这还伴随着一个 "Interactive Audio Beta"，用户将可以...</li><li><a href="https://www.google.com/search?q=ideasthesia+research&rlz=1C1VDKB_enUS1055US1055&oq=ideasthesia+research&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRigATIHCAQQIRigATIHCAUQIRigAdIBCDY1MTdqMGo3qAIIsAIB&sourceid=chrome&ie=UTF-8">ideasthesia research - Google 搜索</a>: 未找到描述</li><li><a href="https://www.youtube.com/watch?v=FJiXHRdW6ws"> - YouTube</a>: 未找到描述</li><li><a href="https://www.youtube.com/watch?v=HXwP-pAez2k">如何使用 chatgpt https://chatgpt.com/share/675b31fa-5f50-8013-8ca7-289ad9534b13</a>: https://chatgpt.com/share/675b31fa-5f50-8013-8ca7-289ad9534b13</li><li><a href="https://www.youtubetrimmer.com/">修剪和裁剪 YouTube 视频 - YouTubeTrimmer.com</a>: YouTubeTrimmer.com：在线修剪和裁剪 YouTube 视频。一个免费的在线工具。</li><li><a href="https://youtu.be/HBu1sIUNqKo?feature=shared"> - YouTube</a>: 未找到描述</li><li><a href="https://youtu.be/aG0ixD3OY80">你必须知道的 10 个 NotebookLM Podcast 提示词</a>: NotebookLM Podcast 正在改变游戏规则——为什么要满足于通用的双主持人对话？在这段视频中，我将揭秘 10 个能提升你 Noteboo...</li><li><a href="https://www.youtube.com/watch?v=wZRkfBsTTt8">美国机密档案：DARPA 的秘密思想控制技术（第 4 季）| History</a>: 美国国防高级研究计划局 (DARPA) 启动了一项开发非手术神经技术的计划——在这项技术中也用于思想控制...</li><li><a href="https://www.youtube.com/watch?v=r_ahZOgPTsk">混沌理论简易指南 - BBC World Service</a>: 根据经典物理学和艾萨克·牛顿定律，预测宇宙中物体的行为本应相对容易...</li><li><a href="https://www.youtube.com/watch?v=TI6sY0kCPpk">什么是弦理论？</a>: Brian Greene 在 3 分钟内解释了弦理论的基本概念。三十五年前，弦理论席卷了物理学界，承诺实现梦寐以求的统一...</li><li><a href="https://hailuoai.video/">海螺 AI (Hailuo AI)：利用 AI 将创意转化为视觉</a>: Hailuo AI 工具 - 创新的 AI 视频生成器和提示词，将您的创意转化为令人惊叹的 AI 视频。利用尖端的 AI 驱动技术和一段...</li><li><a href="https://youtu.be/L7dw799vu5o?si=mE2LmG51EwDO3HMp">Gemini 2.0 幕后故事</a>: Gemini 模型产品负责人 Tulsee Doshi 与主持人 Logan Kilpatrick 一起深入了解 Gemini 2.0 的幕后故事，深入探讨该模型的多模态能力...</li><li><a href="https://www.youtube.com/shorts/MRQJr7Qaqvs">2024 年 12 月 11 日</a>: 未找到描述
</li>
</ul>

### **Nous Research AI ▷ #[general](https://discord.com/channels/1053877538025386074/1149866623109439599/1316535059368378369)** (84 条消息🔥🔥): 

> `Hermes 模型基准测试、Qwen 和 Mistral 讨论、活动注册更新、数学基准测试见解、模型运行与微调工具` 


- **Hermes 3B 的基准测试预期**：用户有兴趣比较 **Hermes 3B**、**Llama 3.2** 以及 **Mistral 7B** 和 **Qwen 2.5** 等其他模型的基准测试。
   - 讨论中提到了超越 **Mistral 7B** 的潜在进展，并对探索各种其他模型表现出极大的热情。
- **即将举行的活动注册**：几位用户注册了一个名额有限的活动，引发了关于注册流程和主办方审批的讨论。
   - 参与者对线下见面表示兴奋，并讨论了演讲直播或录像的可能性。
- **数学基准测试评估见解**：**Senor1854** 分享了关于一个新数学基准测试数据集的见解，强调了其评估结果相较于既有基准的可靠性。
   - 用户认可了新基准如何与之前的评分形成对比，强调了不断演进评估技术的重要性。
- **关于运行模型的讨论**：成员们寻求运行 **Hermes** 等各种模型的建议，并推荐使用 **LM Studio** 以方便访问。
   - 讨论重点在于通过不同平台运行模型的可用工具以及开源解决方案的优势。
- **探索新的模型训练方法论**：**Kotykd** 提出了一种新颖的训练思路，即利用大模型的隐藏状态（hidden states）在不同架构中预训练小模型，以提高效率。
   - 这引发了关于训练方法可行性的讨论，强调了进一步探索和实验的必要性。


<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://webllm.mlc.ai/">WebLLM | Home</a>：未找到描述</li><li><a href="https://huggingface.co/NousResearch/Hermes-3-Llama-3.2-3B">NousResearch/Hermes-3-Llama-3.2-3B · Hugging Face</a>：未找到描述</li><li><a href="https://lu.ma/kqz3rb4u">NOUS @ NEURIPS · Luma</a>：12 月 12 日星期四，下午 6 点开门，晚上 7 点开始演讲。名额有限。DCTRL, 436 W Pender St, Vancouver。提供食物 + 饮料 + 周边。演讲内容：DisTrO Demystified - @theemozilla…</li><li><a href="https://github.com/carl-devin/CYAI-vision-agent/blob/main/README.md">CYAI-vision-agent/README.md at main · carl-devin/CYAI-vision-agent</a>：主仓库：Vision AI agent，让摄像头投入工作。更安全的职场和街道。 - carl-devin/CYAI-vision-agent</li><li><a href="https://arxiv.org/html/2412.06769v1">Training Large Language Models to Reason in a Continuous Latent Space</a>：未找到描述</li><li><a href="https://toloka.ai/math-benchmark">U-MATH &amp; μ-MATH:  Assessing LLMs  on university-level math</a>：Toloka 很高兴宣布推出 U-MATH 和 μ-MATH，这是两个用于评估 LLM 在大学水平数学能力的开创性基准测试。
</li>
</ul>

</div>
  

---


### **Nous Research AI ▷ #[ask-about-llms](https://discord.com/channels/1053877538025386074/1154120232051408927/1316495456318132234)** (10 条消息🔥): 

> `3B 中的 Amnesia 模式、LLM 的 iOS 应用、未过滤版 Hermes、Ollama 中的上下文长度、Llama Instruct 的持续 SFT` 


- **3B 缺少 Amnesia 模式**：成员指出 **3B** 似乎没有 *Amnesia 模式*，因为有人报告在空提示词下得到了**随机的后续内容**。
   - 关于该功能，普遍共识是“并不认为它具备”。
- **iOS 应用支持自定义模型**：一位成员询问是否有支持运行 **LLM** 并支持自定义模型或 **Hermes** 的 iOS 应用。
   - 另一位成员分享了他们的发现，即大多数应用确实允许使用**自定义下载的模型**。
- **smol Hermes 是未过滤的吗？**：针对新的 **smol Hermes**，一位成员询问它是否是**未过滤的（unfiltered）**，并指出之前的版本有所限制。
   - 另一位成员分享道，Hermes 模型通常默认为**友好助手模式**，但可以通过特定的系统提示词进行调整。
- **Ollama 中上下文长度的影响**：一位成员提出了关于在使用 **Ollama** 时 **num_ctx** 在系统提示词中放置位置的问题。
   - 讨论注意到增加**上下文长度（context length）**时模型输出存在显著差异，表明可能存在潜在影响。
- **Llama Instruct 的持续 SFT 比较**：一位成员询问 **Nous Research** 是否曾对 **Llama Instruct** 应用过持续 **SFT**。
   - 他们表示有兴趣将其性能与 **theta-way** 方法论进行比较。


  

---

### **Nous Research AI ▷ #[research-papers](https://discord.com/channels/1053877538025386074/1104063238934626386/1316510980359979199)** (5 messages): 

> `QTIP 模型分析，信号处理复兴，通信理论论文` 


- **QTIP 在无需重新训练的情况下超越 AQLM**：一位成员对 **QTIP 模型**在无需重新训练的情况下性能优于 **AQLM** 表示惊讶，这标志着模型设计上的重大进步。
   - *看起来类信号处理的方法正在强势回归*，凸显了模型开发中一个有趣的趋势。
- **对模型容量利用率的担忧**：另一位成员指出，**模型容量利用率 (model capacity utilization)** 似乎至关重要，并指出 **Llama3** 的性能下降幅度超出了预期。
   - 他们计划详细研读提供的论文，以更好地理解这些动态机制。
- **QTIP 项目的 GitHub 仓库**：分享了一个指向 [QTIP GitHub 仓库](https://github.com/Cornell-RelaxML/qtip) 的链接，可以在该处为开发做出贡献。
   - 该仓库与最近讨论的论文中得出的见解相关联。
- **对通信理论的兴趣**：成员们开始阅读关于**通信理论 (communication theory)** 的论文，这可能反映了研究重心向早期方法论的转移。
   - 随着讨论的深入，这可能会导致这些理论在现代语境下的创新应用。



**提及的链接**：<a href="https://github.com/Cornell-RelaxML/qtip">GitHub - Cornell-RelaxML/qtip</a>：通过在 GitHub 上创建账号，为 Cornell-RelaxML/qtip 的开发做出贡献。

  

---


### **Nous Research AI ▷ #[research-papers](https://discord.com/channels/1053877538025386074/1104063238934626386/1316510980359979199)** (5 messages): 

> `Qtip 模型讨论，模型容量利用率，AI 中的通信理论` 


- **Qtip 模型引发关注**：关于 [Qtip 模型](https://openreview.net/pdf?id=7sdkLVuYCU) 的最新研究结果显示，其在不需要重新训练的情况下优于 AQLM，许多人认为这非常了不起。
   - 初步反应强调了**信号处理技术**在机器学习策略中的显著复兴。
- **Llama3 与模型容量利用率**：讨论表明 **Llama3 的性能**受模型容量利用率的影响尤为严重，这表明需要对模型动态进行更深入的研究。
   - 一位用户提到需要详细阅读该研究，以充分理解其影响和结果。
- **Qtip 的 Github 仓库**：Qtip 模型的开发记录在其 [GitHub 仓库](https://github.com/Cornell-RelaxML/qtip) 中，鼓励大家贡献。
   - 该仓库被视为研究人员了解 Qtip 底层机制的重要资源。
- **对通信理论的兴趣**：据观察，社区中一些人正在探索**通信理论论文**，这标志着研究重点的一个趋势。
   - 这反映了传统通信理论与现代 AI 应用之间一种有趣的融合。



**提及的链接**：<a href="https://github.com/Cornell-RelaxML/qtip">GitHub - Cornell-RelaxML/qtip</a>：通过在 GitHub 上创建账号，为 Cornell-RelaxML/qtip 的开发做出贡献。

  

---


### **GPU MODE ▷ #[general](https://discord.com/channels/1189498204333543425/1189498205101109300/1316831725984284703)** (7 messages): 

> `Intel CPU, Intel Arc B580 对比 RX 6750 XT, Torch Compile 性能, 动态填充与性能损耗` 


- **现在 Intel CPU 值得买吗？**：成员们讨论了 **Intel CPU** 的现状，有人评论说它们还不赖，但建议在同等价位下选择 **Ryzen 芯片**。
   - 对话强调了根据这些 CPU 的具体使用场景，观点会有所不同。
- **Intel Arc B580 与 RX 6750 XT 的对比**：有人提出了 **Intel Arc B580** 是否比 **RX 6750 XT** 是更好选择的问题，表明了对 GPU 对比的持续关注。
   - 虽然没有给出定论，但对这两款型号之间性能对比的兴趣依然存在。
- **torch.compile 的性能问题**：一位用户报告了在使用 **torch.compile(mode='max-autotune')** 编译模型后出现的性能异常，特别是在处理新的 conditioning shapes 时初始运行速度较慢。
   - 尽管使用了 **dynamic=True**，他们仍然遇到了显著的性能损耗，尤其是在第一和第二次 decoder 迭代中。
- **关于动态填充解决方案的疑问**：该用户承认，虽然填充 (padding) 是处理可变长度输入的显而易见的方法，但他们希望 **dynamic=True** 能够减轻性能影响。
   - 他们指出之前也出现过类似问题，并请求提供建议以避免性能下降。

### **GPU MODE ▷ #[triton](https://discord.com/channels/1189498204333543425/1189607595451895918/1316554567084675083)** (8 messages🔥): 

> `Fused Kernel for Matmul and Softmax, Fused Attention and Flash Attention, Elementwise Operations on FP16 vs FP32, Floating Point Precision in Triton, Resource Requests for Triton Fused Attention` 


- **关于 Matmul 和 Softmax 融合 Kernel 的咨询**：一位成员正尝试为 **matmul** 和 **softmax** 创建 **fused kernel**，表示自己熟悉融合 ReLU 等逐点激活函数，但在处理 softmax 操作时遇到了挑战。
   - 他们寻求关于如何为此目的**利用 Triton 文档中的组排序 matmul 示例 (group-ordered matmul example)** 的指导。
- **关于 Fused Attention 中外层循环参数的困惑**：一位用户询问为什么 `_attn_fwd()` 中的 **外层 for 循环** 向 `_attn_fwd_inner()` 传递的是 `4-STAGE` 而不是直接传递 `stage`。
   - 这一实现细节引起了多位成员对其具体实现的关注。
- **掩码逻辑中的浮点值差异**：一位成员发现掩码逻辑中同时使用 `-float('inf')` 作为 `m_i` 和 `-1.0e-6` 令人困惑，怀疑存在浮点精度问题。
   - 这引发了关于在类似操作中选择不同浮点值背后原理的疑问。
- **Triton 中 FP16 和 FP32 的逐元素操作**：一位成员正在探索在 Triton 中使用 FP32 指令对 **FP16** 矩阵执行逐元素操作的方法，并指出自动类型转换带来的性能问题。
   - 他们引用了 **flash attention** 教程中的特定代码，该代码展示了数据类型管理方面的挑战。
- **请求 Fused Attention 相关资源**：鉴于围绕 **fused attention** 的诸多疑问，一位成员询问是否有详细解释相关代码的资源。
   - 他们建议可以与该领域的专家进行简短的交流，以澄清疑虑。


  

---


### **GPU MODE ▷ #[cuda](https://discord.com/channels/1189498204333543425/1189607726595194971/1316545819834322967)** (9 messages🔥): 

> `Best GEMM Implementations, Occupancy and Branching, CUDA Programming Techniques, GPU Glossary Release` 


- **讨论最佳 GEMM 实现**：一位成员询问除 cuBLAS 之外 **性能最好的 GEMM 实现**，并提议了纯 CUDA、Triton 或 CUTLASS 等选项。
   - 另一位成员回应称，**CUTLASS** 可能是目前最顶尖的选择。
- **关于占用率和分支的理论咨询**：一位成员提出了一个理论问题，即在 kernel 中使用两个不同的分支（一个寄存器占用较多，另一个较少）时对 **占用率 (occupancy)** 的影响。
   - 另一位成员澄清说，**寄存器分配发生在编译时**，暗示传递的参数不会影响线程数量。
- **CUDA 编程变通方法**：针对分支问题，一位成员建议使用 **模板参数 (template arguments)** 作为提高灵活性的变通方案。
   - 提问的成员对这一方法表示乐观，认为这可能是一个**有趣的解决方案**。
- **令人兴奋的 GPU 术语表发布**：一位成员宣布在 Modal 上发布了 **GPU Glossary**，并分享了访问链接。
   - 其他成员对分享这一资源表示感谢，该资源在社区内反响良好。



**提到的链接**：<a href="https://modal.com/gpu-glossary">GPU Glossary</a>：GPU 相关术语表。

  

---


### **GPU MODE ▷ #[torch](https://discord.com/channels/1189498204333543425/1189607750876008468/1316642993352081408)** (2 messages): 

> `Forward and Backward Hooks, Activation Checkpointing, Context Function in Checkpointing` 


- **Hook 与 Checkpointing 的有趣行为**：一位成员报告称，在使用 **activation checkpointing** 时，前向和后向 hook 出现了“有趣”的行为：前向 hook 在反向传播期间会打印两次。
   - 他们注意到，在不使用 checkpointing 时前向 hook 只触发一次，由于反向传播需要重新运行前向过程，这导致了混淆。
- **使用外部变量跟踪反向传播**：为了解决反向传播期间的前向行为，一位成员实现了一个*外部变量*来跟踪是否处于反向阶段，并在 `loss.backward()` 之前将其设置为 **True**。
   - 这种调整使前向 hook 能够根据该变量的状态决定是否执行其逻辑。
- **在 Checkpointing 中利用 context_fn**：此外，讨论的另一种方法是在 **checkpoint()** 中使用 `context_fn` 参数来管理反向传播期间的行为。
   - 该方法允许自定义 checkpoint 函数的运行方式，可能作为使用外部变量的替代方案。

### **GPU MODE ▷ #[algorithms](https://discord.com/channels/1189498204333543425/1189861061151690822/)** (1 messages): 

konakona666: https://arxiv.org/pdf/2302.02451 类似这样的东西？
  

---


### **GPU MODE ▷ #[cool-links](https://discord.com/channels/1189498204333543425/1189868872887705671/1316570231556145173)** (3 messages): 

> `vLLM Office Hours, Machete GEMM Kernel, Trillium TPU, Gemini 2.0 AI Model, Building ML Systems` 


- **来自 vLLM Office Hours 的洞察**：最近的 [vLLM Office Hours](https://youtu.be/-4ZkpQ7agXM) 讨论了 Machete，这是 Neural Magic 为 NVIDIA Hopper GPU 优化的最新混合输入 GEMM Kernel。
   - 这一创新标志着 **mixed-precision inference**（混合精度推理）的重大进步，显著提升了计算密集型和内存受限型任务的性能。
- **为大规模运营构建机器学习**：[一段 YouTube 视频](https://youtu.be/139UPjoq7Kw?feature=shared) 讨论了过去十年机器学习的演变及其在各个领域的巨大影响。
   - 该演讲强调了 ML 如何渗透到从科技行业到甚至获得诺贝尔奖的方方面面。
- **Google Trillium TPU 发布**：Google Cloud 宣布其第六代 TPU **Trillium** 现已正式上市（GA），旨在满足大规模 AI 模型的强劲需求。
   - Trillium TPU 在训练新的 [Gemini 2.0 AI Model](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024) 中起到了关键作用，该模型以其增强的能力和效率而闻名。


<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://youtu.be/-4ZkpQ7agXM">vLLM Office Hours - 探索 Machete，一个用于 Hopper GPU 的混合输入 GEMM Kernel - 2024年12月5日</a>：在本次会议中，我们探索了 Machete，这是 Neural Magic 在为 NVIDIA Hopper GPU 设计混合输入 GEMM Kernel 方面的最新创新。基于之前的进步...</li><li><a href="https://youtu.be/139UPjoq7Kw?feature=shared">为万亿亿次浮点运算构建机器学习系统</a>：在过去的 10 年里，我们看到机器学习吞噬了一切，从科技行业到诺贝尔奖，甚至连 ML 这个缩写也不例外。这种崛起...</li><li><a href="https://cloud.google.com/blog/products/compute/trillium-tpu-is-ga">Trillium TPU 正式上市 | Google Cloud 博客</a>：Trillium，Google 的第六代 Tensor Processing Unit (TPU) 现已正式上市，为 AI 工作负载提供增强的性能和成本效益。
</li>
</ul>

</div>
  

---


### **GPU MODE ▷ #[torchao](https://discord.com/channels/1189498204333543425/1205223658021458100/1316538700359929887)** (4 messages): 

> `Float8 Training Implementation, DDP vs FSDP in TorchAO` 


- **使用 TorchAO 进行 Float8 训练面临挑战**：一位成员分享了他们使用 **torchao FP8** 实现 **float8 training** 的尝试，但在扩展到 **multi-GPU** 设置时遇到了问题。
   - 虽然 **FP8 training** 在单 GPU 上运行顺畅，但在更大规模的配置中，前向传播（forward pass）时会出现错误。
- **从 DDP 转向 FSDP 解决方案**：另一位成员建议，大多数测试都是使用 **FSDP** 进行数据并行处理的，并鼓励分享代码或在 **TorchAO** 上提交 issue 以便跟踪。
   - 使用 **DDP** 的初始实现被视为一个过渡，并计划转向以 **FSDP** 作为主要方法。


  

---


### **GPU MODE ▷ #[off-topic](https://discord.com/channels/1189498204333543425/1215328286503075953/1316890911493587087)** (1 messages): 

> `Video Game Datasets, Keyboard/Mouse Inputs, Labeled Actions in Games` 


- **寻求高质量视频游戏数据集**：一位成员询问是否有任何包含标记动作的 **高质量视频游戏数据集**，特别是寻找将屏幕截图与键盘/鼠标输入配对的数据集。
   - 他们强调需要能够通过后续截图显示输入结果的数据集，社区可能会推荐此类资源。
- **对标记动作数据的需求**：该请求强调了包含 **键盘/鼠标输入** 和游戏结果的数据集的重要性，以促进研究或开发。
   - 社区对可用数据集的建议可以极大地帮助寻找适合的游戏标记动作数据资源。


  

---

### **GPU MODE ▷ #[rocm](https://discord.com/channels/1189498204333543425/1233704710389764236/1316788935321587727)** (1 messages): 

> `Instinct devices and XDP kernels, Gemms with CUDA core style MAC, GEMM DL examples in ROCm` 


- **Instinct 设备需要 XDP Kernels**：询问在 Instinct 设备上是否只能使用利用 **V_MFMA op** 的 **XDP kernels**，或者是否存在使用经典 **CUDA core** 风格 MAC 的 kernels。
   - 这一疑虑源于 **GEMM DL examples** 的兼容性问题，这些示例无法在 **MI250** 上运行。
- **关于 GEMM DL 示例兼容性的担忧**：注意到 ROCm 仓库中的 **GEMM DL examples** 默认不进行编译，具体参考了 [此 GitHub 链接](https://github.com/ROCm/composable_kernel/blob/develop/example/01_gemm/gemm_dl_fp16.cpp) 以获取上下文。
   - 这种情况引发了关于这些示例的执行及其与特定硬件设置兼容性的疑问。



**Link mentioned**: <a href="https://github.com/ROCm/composable_kernel/blob/develop/example/01_gemm/gemm_dl_fp16.cpp">composable_kernel/example/01_gemm/gemm_dl_fp16.cpp at develop · ROCm/composable_kernel</a>: Composable Kernel: Performance Portable Programming Model for Machine Learning Tensor Operators - ROCm/composable_kernel

  

---


### **GPU MODE ▷ #[lecture-qa](https://discord.com/channels/1189498204333543425/1238926773216084051/1316884084437286987)** (1 messages): 

> `CUDA Performance Checklist, Kernel Occupancy vs Duration` 


- **理解 Kernel Occupancy 与 Duration 的关系**：一位成员询问，为什么在 `copyDataCoalesced` kernel 中将 **block size** 从 **128** 增加到 **1024** 会导致更好的 **occupancy**（从 **76%** 提升至 **86%**），但耗时（**duration**）却从 **500 微秒** 增加到了 **600 微秒**。
   - *他们表示，对于即使拥有更好的 occupancy 性能反而下降的现象缺乏直观理解，并请求针对这一观察结果提供见解。*
- **关于性能指标的见解**：讨论强调了在 CUDA 编程中，分解 **occupancy** 之外的性能指标的重要性，重点关注执行时间及其与 **block size** 的相关性。
   - *几位成员分享了关于内存访问模式（memory access patterns）如何影响性能的想法，强调了同时优化 **occupancy** 和执行时间的复杂性。*


  

---


### **GPU MODE ▷ #[liger-kernel](https://discord.com/channels/1189498204333543425/1275130785933951039/)** (1 messages): 

0x000ff4: 关于 KTO 的更新请见 #410
  

---


### **GPU MODE ▷ #[self-promotion](https://discord.com/channels/1189498204333543425/1288557096404516945/1316755867445760042)** (11 messages🔥): 

> `Pruna AI guest appearance, GPU Glossary creation, H100 GPU thread count confusion, Tensor core functionality, Register limitations` 


- **Pruna AI 寻求 GPU mode 合作**：一位成员询问应联系谁来安排 **Pruna AI** 在 GPU mode YouTube 频道上的客座亮相。
   - 另一位成员建议有两位特定用户此前负责邀请他人进行演讲。
- **GPU Glossary 的发布引发讨论**：一位成员宣布与 **Modal** 共同创建了 **GPU Glossary**（GPU 词汇表），详细解释了诸如“Streaming Multiprocessor”等关键术语，并包含互联的文章。
   - 成员们讨论了完善该词汇表的建议，特别是关于核心数量的准确性和 **tensor core** 行为的描述。
- **关于 H100 GPU 线程数的澄清**：一位成员对每个 Streaming Multiprocessor (SM) 拥有 **32 threads** 的说法提出质疑，指出 H100 每个 SM 拥有 **128 FP32 cores**，这意味着线程数应该是 128。
   - 随后进行了关于 GPU 调度器运行机制的讨论，确认每个 SM 拥有 **4 个调度器**，每个周期发布一个 **warp**。
- **Tensor cores 的运行方式不同**：有建议指出应澄清 **tensor cores** 利用的是 **warp** 级执行，而不是基于单个线程（per-thread），这与 **CUDA cores** 不同。
   - 成员们承认在较新架构上使用 **int8** 和 **fp8** 时可能存在的性能注意事项。
- **讨论寄存器访问限制**：一位成员建议在词汇表的寄存器页面中加入关于寄存器不可动态寻址（not dynamically addressable）的限制说明。
   - 他们还建议提供一段代码片段，以演示高效与低效的寄存器访问模式。



**Link mentioned**: <a href="https://modal.com/gpu-glossary/device-hardware">Device Hardware | GPU Glossary</a>: no description found

### **GPU MODE ▷ #[🍿](https://discord.com/channels/1189498204333543425/1298372518293274644/1316910696461635706)** (1 条消息): 

> `Markdown Blog 版本，针对 Kernels 的 Eval 性能` 


- **Markdown Blog 请求**：一位成员询问另一位成员是否有其博客的 **Markdown 版本**，并建议可以将其用作 **Megaprompt**。
   - 这样做的目的是看它是否能帮助提高其 **Kernels** 的 **Evaluation 性能**。
- **针对性能的 Megaprompt 探索**：目前正在讨论使用 **Megaprompt** 的想法，希望能提升其 **Kernels** 的 **Evaluation 性能**。
   - 利用 **Markdown** 格式的博客可能在评估任务中产生更好的结果。


  

---

### **GPU MODE ▷ #[arc-agi-2](https://discord.com/channels/1189498204333543425/1316377974672588850/1316711484033601578)** (23 条消息🔥): 

> `ARC 谜题与 LLM，Transduction vs. Program Induction，Test Time Training 扩展，图像分割与 GNN，ARC 增强策略` 


- **利用 LLM 解决 ARC 谜题**：成员们讨论了使用基于 LLM 的标注来处理 ARC 谜题，指出了 2D 表示的重要性以及 Vision Transformers 的潜在优势。一位成员分享了[他们的实验](https://github.com/arc-community/arc-research/tree/main/prototyping/arc_vit)，通过不同的表示方法来改善结果。
   - 提到了 *Ryan Greenblatt 使用 GPT4o ARV agents 的方法* 是一种很有前景的 Program Induction 手段，建议在 Vision-Language Models 上尝试类似的策略。
- **Transduction vs. Program Induction 的见解**：关于 Transduction 是否比 Program Induction 更有效展开了热烈讨论，并引用了一篇论文指出这两种方法可能是互补的。一位成员指出，与优化的离散方法相比，基于 LLM 的程序搜索在采样性能方面存在挑战。
   - 有人幽默地建议采用“归纳-转导钳形攻势”（Induction-Transduction pincer movement），从多个角度攻克 ARC。
- **增强 Test Time Training 技术**：分享了关于扩展 Test Time Training 的想法，即通过各种变换来帮助模型学习图像中的不变属性。这种方法可以促进对 ARC 谜题解法的更好理解。
   - 成员们考虑了将分割方法与 Graph Neural Networks（GNN）结合的技术难度，以创建供 LLM 使用的向量表示。
- **探索 ARC 增强策略**：提出了一系列针对 ARC 谜题的增强技术，包括旋转、翻转和颜色映射，以确定它们在 Test Time Training 中的有效性。一位成员表示打算整理并分享这些实验的结果。
   - 大家公认增强对于训练能够泛化到未见测试示例的模型至关重要，并对如何最好地利用它们保持持续关注。
- **对 ARC-AGI-2 更好计算资源的期待**：成员们对 ARC 竞赛中施加给参赛者的计算限制表示担忧，希望能够获得更好的硬件支持（如 A100 GPU）。提到 ARC-AGI-2 的新数据集格式将与 ARC-1 相似，可能允许使用现有的 Solvers 进行过滤。
   - 成员们计划整理一份材料和想法清单来规划未来的项目，强调了在后续行动中的协作与准备。


<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://arxiv.org/abs/2411.02272">Combining Induction and Transduction for Abstract Reasoning</a>：当从极少数示例中学习输入-输出映射时，是先推断出一个解释示例的潜在函数更好，还是直接预测新的测试输出（例如使用...）更好？</li><li><a href="https://arxiv.org/abs/2410.06405">Tackling the Abstraction and Reasoning Corpus with Vision Transformers: the Importance of 2D Representation, Positions, and Objects</a>：Abstraction and Reasoning Corpus (ARC) 是一个专注于评估人工智能系统视觉推理能力的流行基准。在其原始框架中，ARC 任务需要解决...</li><li><a href="https://github.com/open-thought/arc-agi-2/tree/main/arc-1/annotated-re-arc">arc-agi-2/arc-1/annotated-re-arc at main · open-thought/arc-agi-2</a>：构建解决 ARC-AGI-2 的认知核心。通过在 GitHub 上创建账号为 open-thought/arc-agi-2 的开发做出贡献。</li><li><a href="https://github.com/arc-community/arc-research/tree/main/prototyping/arc_vit">arc-research/prototyping/arc_vit at main · arc-community/arc-research</a>：一个测试不同假设的仓库。通过在 GitHub 上创建账号为 arc-community/arc-research 的开发做出贡献。</li><li><a href="https://github.com/arc-community/arc-research/blob/b8566c752c5d4163a3949769079887e88d0b92ac/prototyping/infer_func/infer_func.py#L191">arc-research/prototyping/infer_func/infer_func.py at b8566c752c5d4163a3949769079887e88d0b92ac · arc-community/arc-research</a>：一个测试不同假设的仓库。通过在 GitHub 上创建账号为 arc-community/arc-research 的开发做出贡献。
</li>
</ul>

</div>
  

---

### **Cohere ▷ #[discussions](https://discord.com/channels/954421988141711382/954421988783444043/1316525019639316552)** (26 条消息🔥): 

> `Cohere 支持问题, 超时问题, 系统状态更新, 用户交互, 错误消息` 


- **Cohere 支持团队响应迅速**：当用户报告问题时，成员强调对于紧急事项应通过 [support@cohere.com](mailto:support@cohere.com) 联系支持团队。
   - 另一位用户鼓励直接发送消息以获得更快的协助，并确认了支持团队的存在。
- **报告了间歇性超时问题**：多位用户在使用 Rerank 功能时遇到了 **504 gateway timeout** 错误，其中一人报告请求在 **40 秒**后超时。
   - 该问题似乎是偶发的，因为一些成员注意到服务随后不久便恢复了，而其他人仍报告面临挑战。
- **系统状态确认运行正常**：Cohere 确认其系统**完全正常运行**，状态更新显示各组件的 **uptime 为 99.84%**。
   - 更新已在 [Cohere Status Page](https://status.cohere.com/) 上共享，并保证用户不应再面临持续性问题。
- **用户互动显示出社区参与度**：成员们积极交流各自的体验，一位用户在调试后发现之前的聊天失败问题已解决，感到非常欣慰。
   - 对话凸显了一个愿意分享支持渠道并反馈问题解决情况的社区。
- **确认先前问题已解决**：在关于停机时间的几次讨论后，用户最终被告知先前的问题已经**解决**，所有 endpoints 均恢复正常。
   - 社区对这一解决结果表示庆祝，对整个排查过程中提供的更新表示宽慰和感谢。


<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://tenor.com/view/magic-eight-eightball-gif-8220138296338768220">Magic Eight GIF - Magic Eight Eightball - 发现并分享 GIF</a>：点击查看 GIF</li><li><a href="https://status.cohere.com/">Cohere Status Page 状态</a>：Cohere Status Page 的最新服务状态
</li>
</ul>

</div>
  

---


### **Cohere ▷ #[questions](https://discord.com/channels/954421988141711382/1168411509542637578/1316570338787594252)** (40 条消息🔥): 

> `模型训练中的量化技术, Cohere Go SDK 更新需求, Aya Expanse 模型使用, 模型校准数据集, 许可问题与合规性` 


- **探索量化策略**：关于 FP8 quantization 有效性的讨论显示，在 **H100 硬件**上，它的 fast inference 性能优于 **BnB**，尤其是在高用户负载下。
   - 成员们一致认为，像 WikiText 这样的传统校准数据集在实际性能中往往表现不足，特别是对于非英语语言。
- **Cohere Go SDK 需要修复**：收到了关于 **Cohere Go SDK** 的反馈，指出与 tools calls 相关的 **StreamedChatResponseV2** 字段结构不正确。
   - 有人指出 **ToolPlanDelta** 和 **ToolCallDelta** 的定义也缺少准确解析所需的必要字段。
- **Aya Expanse 模型讨论**：用户表示倾向于在公司内部环境中使用 **Aya Expanse 模型**，强调在避免潜在数据泄露的同时需要保证速度。
   - 讨论中提出了对 **CC-BY-NC 许可证** 的担忧，引发了关于即使在企业内部环境中使用也涉及非商业用途影响的讨论。
- **模型校准数据集选择**：对话强调了校准数据集的选择，其中 **Neural Magic** 使用来自 **Ultrachat 的 2,048 个样本**的方法对英语模型非常有效。
   - 一位成员指出了使用繁体中文数据的困难，并建议探索多语言数据集以获得更好的性能。
- **需要 JSON Schema 示例**：用户请求提供关于处理结构化 JSON 的更清晰文档，特别是涉及对象数组的示例。
   - 这凸显了 **structured outputs** 文档中的空白，促使需要针对数组处理提供明确的指导。


<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://huggingface.co/minyichen/aya-expanse-32b-Dynamic-fp8">minyichen/aya-expanse-32b-Dynamic-fp8 · Hugging Face</a>：未找到描述</li><li><a href="https://docs.cohere.com/v2/docs/structured-outputs#json-schema-mode">Structured Outputs — Cohere</a>：此页面描述了如何让 Cohere 模型以特定格式（如 JSON）创建输出。</li><li><a href="https://github.com/hiyouga/LLaMA-Factory">GitHub - hiyouga/LLaMA-Factory: 100+ LLMs 的统一高效微调 (ACL 2024)</a>：100+ LLMs 的统一高效微调 (ACL 2024) - hiyouga/LLaMA-Factory
</li>
</ul>

</div>
  

---

### **Cohere ▷ #[api-discussions](https://discord.com/channels/954421988141711382/1168578329423642786/1316705249297174529)** (2 messages): 

> `403 Error Response, VPN Usage, IP Information, Email Issues` 


- **用户报告在未使用 VPN 时出现 403 错误**：一名用户报告称，在尝试不使用 VPN 访问服务时收到了 **403 error response**。
   - 他们指出，即使不使用 VPN 问题依然存在，这暗示可能存在特定地区的限制。
- **用户的 ISP 和地理位置详情**：该用户提供的 **IP information** 显示其 ISP 为 **ChinaTelecom**（中国电信），所在地为 **中国福建厦门**。
   - 这一细节可能有助于确定他们所遇到的访问问题的根本原因。


  

---


### **LLM Agents (Berkeley MOOC) ▷ #[hackathon-announcements](https://discord.com/channels/1280234300012494859/1280236929379602493/1316846401963163648)** (1 messages): 

> `Hackathon submission deadline, Submission platform change, Evaluation criteria, Announcement timeline` 


- **Hackathon 提交截止日期即将到来！**：**LLM Agents MOOC Hackathon** 的提交截止日期正迅速临近，定于 **12/17**。
   - *请记住，所有提交必须在 12 月 17 日之前完成，才有资格参加评审。*
- **从 Devpost 迁移至 Google Forms**：本次 Hackathon 的提交平台已从 **Devpost** 切换为 **Google Forms**；请务必使用消息中链接的正确表单。
   - 这一变更对于确保您的创新解决方案被纳入竞赛至关重要。
- **热切期待获胜者名单公布**：Hackathon 的获胜者将于 **2025 年 1 月上半月**公布，这为即将到来的提交增添了期待感。
   - 鼓励参与者在截止日期前提交作品，用项目打动评委。
- **提供最后时刻的协助！**：提醒成员，如果需要帮助或有最后的问题，可以在聊天频道中提出。
   - 此外，随着截止日期的临近，建议访问 Hackathon 网站以获取更详细的信息。


  

---


### **LLM Agents (Berkeley MOOC) ▷ #[mooc-announcements](https://discord.com/channels/1280234300012494859/1280369709623283732/1316850552847597700)** (1 messages): 

> `Advanced Large Language Model Agents MOOC, LLM technology advancements, MATHEMATICS in AI, AI Code Generation, Program Verification` 


- **全新的 Advanced LLM Agents MOOC 将于 2025 年春季开课！**：全新的 **Advanced Large Language Model Agents MOOC** 将于 **2025 年春季**启动，该课程基于 2024 年秋季的成功经验，重点关注推理和 AI 数学等主题。
   - 本课程承诺探索 LLM Agents 的**下一代前沿技术**，目前已开放报名，链接见 [此表单](https://forms.gle/9u6HdVCWXgws16go9)。
- **教学大纲仍在制定中，更多细节即将公布**：*敬请关注*有关教学大纲的更多信息，根据公告，大纲目前仍在开发中。
   - 鼓励参与者关注 **Prof Song** 即将发布的关于该 MOOC 的正式公告。
- **课程时间为 1 月中旬至 5 月初**：**Advanced LLM Agents MOOC** 计划从 **1 月中旬运行至 5 月初**，提供一个充实的学习周期。
   - 邀请潜在参与者访问 [Advanced LLM Agents 网站](https://llmagents-learning.org/sp25) 进一步了解课程详情。


  

---

### **LLM Agents (Berkeley MOOC) ▷ #[mooc-questions](https://discord.com/channels/1280234300012494859/1280370030609170494/1316495978295201924)** (44 messages🔥): 

> `文章作业信息、测验与证书要求、黑客松参与、课程反馈与未来开设、TA 协助` 


- **所有作业截止日期为 2024 年 12 月 12 日**：包括书面文章在内的所有作业均需在 **2024 年 12 月 12 日** **11:59 PM PST** 之前提交。
   - 此截止日期适用于文章作业，该作业要求提供包含该文章的社交媒体帖子链接。
- **测验基于完成情况评分**：测验按**完成情况**计分，因此分数较低不会影响获得证书。
   - 参与者在提交测验后应能立即看到分数，其目的是为了学习而非严格的考核。
- **黑客松贡献信息**：对于 **Ninja Tier**，完成所有测验并提交文章作业至关重要，但 labs 不是必须的。
   - 参与者可以针对其黑客松项目撰写书面文章作业。
- **未来课程的准备情况**：目前的课程涵盖了理解 Agent 至关重要的基础入门内容，使学生能够快速跟上进度。
   - 预期的先修知识包括 **Python** 基础以及对 **machine learning** 或 **LLMs** 的一些接触，适合许多本科生。
- **感谢 TA 协助**：参与者对 TA 表示感谢，称赞他们在整个课程中的响应速度和支持。
   - TA 确认了他们将持续致力于帮助学生完成课程。


<div class="linksMentioned">

<strong>提及的链接</strong>:

<ul>
<li>
<a href="https://mickelb.org/blog/visual-ai-safety">A Visual Perspective on Technical Concepts in AI Safety</a>: 欢迎！理解人工智能的复杂性及其潜在风险可能具有挑战性。本文旨在提炼这些技术概念...</li><li><a href="https://forms.gle/7ekobPNSWDLBWnDT6">Written Article Assignment Submission</a>: 说明：创建一个大约 500 字的 Twitter、Threads 或 LinkedIn 帖子。你可以直接在首选平台发布文章，也可以在 Medium 上撰写文章然后发布链接...
</li>
</ul>

</div>
  

---


### **Interconnects (Nathan Lambert) ▷ #[events](https://discord.com/channels/1179127597926469703/1179127598442348729/1316878469346623629)** (3 messages): 

> `会议地点、活动详情` 


- **会议地点说明**：一位成员询问会议地点，问道：“我们要去哪里集合？”。回复明确了会议在**二楼**举行。
   - 进一步说明地点位于**东北角**。
- **会议场地确认**：对话确认会议在场地的**二楼**举行。
   - 参与者被引导至**东北角**作为确切的集合点。


  

---


### **Interconnects (Nathan Lambert) ▷ #[news](https://discord.com/channels/1179127597926469703/1179128538679488533/1316802218594140234)** (4 messages): 

> `Android XR, Gemini, Google 增强现实, 实时翻译, 智能眼镜` 


- **Google 在 Android XR 上的豪赌**：Google 推出了 **Android XR**，这是一款用于头显和智能眼镜的新型混合现实 OS，并在最近的演示中展示了其功能。
   - 与会者体验了带有字幕的实时**翻译**等功能，标志着 Google 对增强现实的重新投入。
- **对实时翻译功能的期待**：成员们表示期待**实时翻译**能彻底改变沟通方式，并指出这是科技领域期待已久的功能。
   - 一位与会者幽默地回忆了他们在佩戴原型设备时，看到语音被实时翻译出来的惊讶。
- **关注 Gemini 的表现**：关于 **Gemini** 系统与 Android XR 协同工作的反馈已经出现，用户对 Google 的方向感到乐观。
   - 参与者指出，这些技术的结合可能意味着 Google 在 AR 领域的一次显著回归。



**提及的链接**: <a href="https://www.theverge.com/2024/12/12/24319528/google-android-xr-samsung-project-moohan-smart-glasses">I saw Google’s plan to put Android on your face</a>: 这是我最接近成为钢铁侠的一次。

  

---

### **Interconnects (Nathan Lambert) ▷ #[ml-drama](https://discord.com/channels/1179127597926469703/1181746144821387334/1316567030794682488)** (3 messages): 

> `内容争论，温馨互动` 


- **与 Gary 的内容之争**：一位成员表示需要有人代表他们就内容问题与 Gary 进行“战斗”。
   - 这凸显了讨论的竞争性质以及维护个人观点所需的努力。
- **温馨的氛围**：频道中分享的情绪被描述为“非常温馨”。
   - 这表明尽管存在潜在冲突，但社区氛围是积极且相互支持的。



**提到的链接**：<a href="https://bsky.app/profile/mdagost.bsky.social/post/3ld2gnb7vns25">Michelangelo D’Agostino (@mdagost.bsky.social)</a>：我没有任何内部消息，只有 @natolambert.bsky.social 在那篇帖子中写的内容：

  

---


### **Interconnects (Nathan Lambert) ▷ #[random](https://discord.com/channels/1179127597926469703/1183121795247779910/1316495072228937899)** (12 messages🔥): 

> `Nous Dunks, Nextcloud 推广, Frankle 签名的 Databrick 砖块, OpenAI vs Anthropic, Claude Pro 订阅` 


- **对 Nous Dunks 的赞美引发神秘感**：一位成员收到了对其 **Nous Dunks** 的赞美，并暗示了该产品吸引力背后的**神秘感**，称赞美者“根本不知道闭门之后发生了什么”。
   - *Fight!!!* 是他们对最初评论的俏皮反应，暗示了一种喧闹的氛围。
- **Nextcloud：开源宠儿**：一位爱好者分享了他们对 **Nextcloud.com** 的热爱，将其推广为他们经常倡导的卓越开源平台。
   - 他们对其功能表示感谢，表明对该服务非常满意。
- **渴望 Frankle 签名的 Databrick 砖块**：一位用户表达了对 **Frankle 签名的 Databrick 砖块** 的强烈渴望，幽默地指出其在心愿单上的排名仅次于剑。
   - 这展示了对收集技术纪念品的轻松态度。
- **OpenAI 与 Anthropic 紧张局势升级**：一份详细分析强调了 **OpenAI** 与 **Anthropic** 之间日益加剧的紧张关系，两家公司都在争夺市场领导地位和编程霸权。
   - Anthropic 在编程应用方面的增长引起了 **OpenAI 高管** 的担忧，报告显示其重点已从安全转向激进的营销策略。
- **新的 Claude Pro 订阅者发声**：一位成员承认终于订阅了 **Claude Pro**，展示了人们对竞争性 AI 工具日益增长的兴趣。
   - 对 Dario 的俏皮评论标志着他们小组内部对于这一决定的情谊。



**提到的链接**：<a href="https://x.com/btibor91/status/1867233337284395288">来自 Tibor Blaho (@btibor91) 的推文</a>：The Information 详细描述了 OpenAI（2024 年收入 40 亿美元，估值 1570 亿美元）与 Anthropic（到 2024 年底 ARR 为 10 亿美元，估值 180 亿美元）之间日益紧张的关系，强调了 Anthropic 在编程领域的增长...

  

---


### **Interconnects (Nathan Lambert) ▷ #[cv](https://discord.com/channels/1179127597926469703/1208183243447468093/1316759828881997865)** (9 messages🔥): 

> `MLLM 发展来源, Hugging Face 的 VLM 见解, MVLM 文章请求, 关于 MLLM 的大学课程` 


- **寻找 MLLM 发展的优质来源**：成员们表达了追踪 **MLLM** 发展的兴趣，并强调需要更好的来源，一些人求助于**抓取**信息。
   - 一位用户将他们的 Twitter 动态 [在此](https://x.com/jbohnslav) 推荐为潜在来源。
- **Hugging Face 的 Merve 分享宝贵见解**：一位成员建议通过 [此链接](https://x.com/mervenoyann) 关注来自 Hugging Face 的 **Merve**，以获取与 **VLM** 相关的优质内容。
   - 建议她的帖子对于那些对该领域感兴趣的人来说具有启发性和相关性。
- **深度 MVLM 文章请求**：一位成员注意到缺乏来自 **Lilian W** 等信任作者的长篇、更新的 **MVLM** 文章，并对目前高水平资源的匮乏表示失望。
   - 他们提到关于该主题的大学课程似乎有限，引用斯坦福大学的多模态课程称其缺乏深度。
- **个人 MVLM 见解的潜力**：一位成员考虑撰写自己的 **MVLM** 文章，承认创作出 **Lilian 质量** 的内容将具有挑战性，但值得一试。
   - 另一位成员表示鼓励，幽默地表示如果付诸努力，他们将免费提供质量反馈。


<div class="linksMentioned">

<strong>提到的链接</strong>:

<ul>
<li>
<a href="https://x.com/mervenoyann">来自 undefined 的推文</a>: 未找到描述</li><li><a href="https://x.com/jbohnslav">来自 undefined 的推文</a>: 未找到描述
</li>
</ul>

</div>
  

---

### **Interconnects (Nathan Lambert) ▷ #[reads](https://discord.com/channels/1179127597926469703/1214764639397617695/1316534615048982538)** (8 messages🔥): 

> `AI 模型创意基准测试, 算法责任, Claude 的垃圾信息问题, Tulu 3 后训练技术` 


- **AI 模型创意基准测试讨论**：社区讨论了衡量 LLM 在“创意”任务中能力的可能任务，指出了目前缺乏有意义的创意和**多样性（diversity）**基准测试。
   - 特别是，用户表达了不满，尽管 **Claude-3** 是他们的首选，但在与创意写作相关的基准测试中排名往往较低。
- **参与式算法责任术语**：一位成员赞赏在参与式算法责任语境下使用的“算法决策系统（algorithmic decision-making systems）”一词。
   - 这一术语强调了用户参与对于理解算法如何影响决策的重要性。
- **Claude 利用 AI 洞察应对垃圾信息**：一篇文章透露，**Anthropic** 的 Claude 聊天机器人面临垃圾信息问题，因为一些账号试图操纵其文本生成以达到 SEO 目的。
   - 文章强调，虽然生成关键词本身没有错，但操纵手段往往能逃避检测，这引发了平台方的担忧。
- **探索 Tulu 3 创新**：最近的一场 **YouTube** 演讲涵盖了“Tulu 3：探索开源语言模型后训练的前沿”，重点关注 RLHF 和后训练（post-training）技术的创新。
   - 社区成员注意到会议期间提出了许多深刻的问题，特别是联合主持人 **Sadhika** 在最后提出的问题。


<div class="linksMentioned">

<strong>提到的链接</strong>：

<ul>
<li>
<a href="https://www.platformer.news/how-claude-uses-ai-to-identify-new-threats/">Claude 如何利用 AI 识别新威胁</a>：此外：关于人们如何使用 Anthropic 聊天机器人的独家数据</li><li><a href="https://www.youtube.com/live/ltSzUIJ9m6s?si=3Y_NgGdrVRGwz1nf">Tulu 3：探索开源语言模型后训练的前沿 - Nathan Lambert (AI2)</a>：来自人类反馈的强化学习 (RLHF) 和其他后训练技术正驱动着领先的、主要的开源模型中日益增长的创新比例...</li><li><a href="https://gwern.net/creative-benchmark">迈向 LLM 多样性与创意基准测试 · Gwern.net</a>：未找到描述
</li>
</ul>

</div>
  

---


### **Interconnects (Nathan Lambert) ▷ #[posts](https://discord.com/channels/1179127597926469703/1228051082631188530/1316794281834320017)** (2 messages): 

> `Discord 临界规模, 技术问题` 


- **用户对技术问题的幽默调侃**：一位成员在表示“哇，它一直没出现，也许我把它弄坏了，哈哈”后，开玩笑地思考自己是否搞垮了系统。
   - 这反映了对话的轻松氛围，即使在面临技术挑战时也是如此。
- **Discord 达到临界规模**：另一位成员评论说 Discord 已经达到了**临界规模（critical mass）**，通过“Discord 现在已经有临界规模了，没关系”这句话暗示了其稳健性和用户群的稳定性。
   - 这表明了对平台增长的积极看法以及用户对其运行状态的信心。


  

---


### **LlamaIndex ▷ #[blog](https://discord.com/channels/1059199217496772688/1187460979064324127/1316509000652689478)** (3 messages): 

> `CalPitch 工具, RAG Agent 与 SharePoint, Google Gemini 2.0 发布, Llama Index 兼容性` 


- **Calsoft 为业务开发推出 CalPitch**：Calsoft 创建了 [CalPitch](https://twitter.com/llama_index/status/1866949720654090423)，这是一个辅助其业务开发团队研究潜在客户并在人工监督下起草外联邮件的工具。
   - 这展示了 **AI 如何增强并加速**现有的工作流程。
- **构建具备 SharePoint 权限的 RAG Agent**：一项新功能允许构建遵循 SharePoint 权限的 RAG Agent，解决了 **Azure stack** 用户连接企业数据源的常规需求。
   - 用户现在可以在符合现有**权限结构**的情况下，享受更量身定制的数据体验。
- **Google 发布 Gemini 2.0 模型并提供首日支持**：Google 推出了最新的 **Gemini 2.0** 模型，并提供首日支持，可通过 `pip install llama-index-llms-gemini` 或 `pip install llama-index-llms-vertex` 使用。
   - 该模型，特别是 [Gemini 2.0 Flash](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#gemini-2-0-flash)，承诺提升速度和能力，被誉为 AI 领域的游戏规则改变者。



**提到的链接**：<a href="https://t.co/zNDoASjMIc">Gemini 2.0 Flash：具有科幻级流式传输模式的卓越多模态 LLM</a>：Google 今天早上的重大发布：介绍 Gemini 2.0：我们为 Agent 时代打造的新 AI 模型。其中包含大量内容（包括 Project Astra 的更新以及……

  

---

### **LlamaIndex ▷ #[general](https://discord.com/channels/1059199217496772688/1059201661417037995/1316507553709953075)** (21 条消息🔥): 

> `Slack Bot Personalization, Techniques for Unstructured PDF, Function Calling Defaults, BGEM3 Model Integration, Setting System Prompts in FunctionCallingProgram` 


- **使用 ReAct Agent 实现 Slack Bot 个性化**：一位用户正在使用 **ReAct Agent** 构建 Slack Bot，并寻求关于如何在不暴露其 AI 身份的情况下展示个性的建议。
   - 另一位成员建议使用 **FunctionCallingAgent** 并配合 system prompt 来定制其个性。
- **使用 LlamaParse 为 PDF 优化 RAG**：推荐使用 **LlamaParse** 解析非结构化 PDF 数据，在处理各种文件类型的同时，确保为 LLM 应用提供高质量的输入。
   - 关于数据隐私的问题得到了解答，确保数据保留时间不会超过 **48 小时**。
- **OpenAI Function Calling 的默认设置**：会议澄清了由于延迟问题以及与 Pydantic 类的兼容性，`strict=True` 在 **FunctionCallingProgram** 中并非默认设置。
   - 成员们获知可以手动设置 `strict=True`，但这可能会导致某些 Pydantic 类失效。
- **将 BGEM3 与 Qdrant 数据库集成**：一位用户询问如何通过 **LlamaIndex** 将 **BGEM3** 模型与 **Qdrant** 数据库集成，并寻求相关流程的指导。
   - 分享了与 BGEM3 相关的资源以提供进一步帮助。
- **在 FunctionCallingProgram 中设置 System Prompts**：用户可以向 **FunctionCallingProgram** 传递 **ChatMessagePromptTemplate**，以便轻松设置自定义的 system prompts。
   - 还讨论了设置工具选择（tool choices）的选项，以优化程序内的 function calls。



**提及的链接**：<a href="https://docs.llamaindex.ai/en/stable/llama_cloud/llama_parse/">LlamaParse - LlamaIndex</a>：未找到描述

  

---


### **LlamaIndex ▷ #[ai-discussion](https://discord.com/channels/1059199217496772688/1100478495295017063/1316500228148564020)** (1 条消息): 

> `Athina AI, LLM Experiments, Prompt Engineering Techniques` 


- **探索使用 Athina AI 进行 LLM 实验**：创建了一个演示，旨在使用 YC 初创公司 **Athina AI** 在中高难度问题上测试各种 **prompt engineering 技术**。
   - 成员称赞 **Athina AI** 是一个在**开源和闭源 LLM** 上运行实验的**强大产品**。
- **分享用于 LLM 测试的演示视频**：附带的 [演示视频](https://cdn.discordapp.com/attachments/1100478495295017063/1316500227825336341/timeline-1_xx0hPTjx.mp4?ex=675c9761&is=675b45e1&hm=1c438eaa931b8d6072e6d0f8100b29777f20d72f5dd94458c2f898d3db3900a3&) 展示了测试过程。
   - 该视频旨在深入展示在 **Athina AI** 测试过程中应用的各种技术。


  

---


### **Modular (Mojo 🔥) ▷ #[general](https://discord.com/channels/1087530497313357884/1098713601386233997/1316619719138349137)** (8 条消息🔥): 

> `New Forum Experience, Excitement for Upcoming Events, User Level Advancement, Company Praise` 


- **用户喜欢改版后的论坛**：成员们对**新论坛的观感**表示赞赏，其中一位表示非常**棒**。
   - *反馈重点包括更具吸引力的用户界面和整体体验。*
- **承诺充满乐趣的一周**：一位成员提到他们被承诺接下来会有**充满乐趣的一周**，这在社区内引发了期待。
   - *这一承诺在用户中引起了轰动，增加了社区的热情。*
- **用户晋升至 6 级**：<@360038721778745345> 庆祝在社区排名中升至 **6 级**，并收到了其他成员的祝贺。
   - *这类成就通常会在参与者之间培养友好的竞争精神。*
- **对公司的普遍正面评价**：如 “Lit” 和 “Cool company” 等言论反映了成员对该组织的正面情绪。
   - *这些评价有助于在社区内形成一种赞赏的文化。*


  

---

### **Modular (Mojo 🔥) ▷ #[announcements](https://discord.com/channels/1087530497313357884/1098765954302873621/1316781895278923786)** (1 条消息): 

> `Swag 挑战赛，Ask Me Anything 环节，社区包早期访问，Async Mojo 实现，Mojo 优化流水线` 


- **Swag 挑战赛获胜者公布**：我们周一以 **swag challenge** 开启了本周，获胜者名单已在 [这里](https://forum.modular.com/t/winners-of-day-1-swag-challenge/189) 公布。Ahmed 还主持了一场 **[关于使用 Mojo 进行 GPU 编程的 Ask Me Anything 环节](https://forum.modular.com/t/simplifying-gpu-programming-with-parametric-tile-level-tensors-in-mojo-llvm-developers-meeting-2024/38)**。
- **Joe 对标准库的见解**：周二，Joe 主持了一场 **[关于标准库的 Ask Me Anything 环节](https://forum.modular.com/t/ask-joe-anything-about-the-mojo-standard-library/195)**。本次会议为该库的功能和特性提供了宝贵的见解。
- **社区包早期访问预览版发布**：昨天，我们发布了 **社区包的早期访问预览版 (early access preview)**，鼓励用户加入并协助测试打包功能。感兴趣的用户可以在 <#1098713770961944628> 注册，以获取教学频道 <#1313164738116583454> 的访问权限。
- **今日 Ask Me Anything 环节**：今天的特色环节包括 **[向 Steffi 提问关于 MLIR 中 async Mojo/协程实现的问题](https://forum.modular.com/t/efficient-coroutine-implementation-in-mlir-llvm-developers-meeting-2024/39)** 以及 **[向 Weiwei 提问关于 Mojo 优化流水线的问题](https://forum.modular.com/t/what-we-learned-from-building-mojos-optimization-pipeline-llvm-developers-meeting-2024/35)**。这些环节旨在加深对特定技术主题的理解。
- **为明天的挑战做准备！**：鼓励参与者关注明天激动人心的挑战！🥳 请务必回来查看更多详情。


  

---


### **Modular (Mojo 🔥) ▷ #[mojo](https://discord.com/channels/1087530497313357884/1151418092052815884/1316546222483443785)** (10 条消息🔥): 

> `Mojo 开源，Mojo 吉祥物，Boitatá，Mojo 角色名称` 


- **对 Mojo 开源时间线的好奇**：一位成员询问了 **Mojo** 开源的时间线，表达了对其未来可用性的兴趣。
   - 虽然没有提供具体的时间线，但该问题凸显了社区对开源进展的持续关注。
- **关于 Mojo 吉祥物的讨论**：成员们提到了一场关于 Mojo 吉祥物的讨论，特别是与 **Boitatá**（一个与 Mojo 身份相关的巴西神话生物）有关的内容。
   - 这种联系激发了人们对该角色身份的好奇，并暗示了潜在的文化意义。
- **为小火焰角色命名**：成员们分享了对这个小火焰角色的看法，最初不确定它是否有名字，或者它是否属于一种“小火焰生物”物种。
   - 最终确认该角色就叫作 **Mojo**，这为早期的困惑提供了一些清晰的解答。
- **关于 Mojo 的幽默互动**：成员们进行了轻松的互动，讨论了角色名称的简洁性，并对吉祥物的身份分享了笑声。
   - 这些交流反映了 Mojo 社区内轻松有趣的氛围。



**提及的链接**：<a href="https://github.com/modularml/mojo/discussions/941">Mojo mascot? Python+Mojo=Boitatá (brazilian mythological creature) · modularml/mojo · Discussion #941</a>：这本身不是一个 issue，但作为一个巴西人，这让我产生了一个有趣的想法。Mojo 作为 Python 的超集（或 "Python++"），让我想起了巴西民间传说中一个著名的怪物...

### **DSPy ▷ #[show-and-tell](https://discord.com/channels/1161519468141355160/1202371242519441499/1316889085423390751)** (2 messages): 

> `DSPy, Prompt Optimization, Categorization Tasks` 


- **用于 LLM 的 DSPy 框架**：一位成员介绍了 **DSPy**，这是一个用于对语言模型进行编程的框架，显著减少了在 Prompting 上花费的时间。
   - _“DSPy 是用于编程——而非提示（prompting）——语言模型的框架，”_ 强调了其在构建由 LLM 驱动的应用程序时的高效性。
- **利用样板代码实现轻松 Prompting**：**DSPy** 的方法利用了样板式的 Prompting，允许用户通过 **signatures** 定义任务，从而简化了 Prompt 的创建过程。
   - 这种方法有助于以简洁高效的方式构建各种任务，使与 LLM 的交互不再繁琐。
- **解释 DSPy 的分类示例**：使用一个简单的分类任务来演示 **DSPy** 的运行方式及其作为工具的实用性。
   - 该示例展示了框架的实际应用，有助于阐明其优势。



**提及的链接**：<a href="https://www.dbreunig.com/2024/12/12/pipelines-prompt-optimization-with-dspy.html">Pipelines &amp; Prompt Optimization with DSPy</a>：关于技术、文化、媒体、数据以及它们之间相互作用方式的文章。

  

---


### **DSPy ▷ #[general](https://discord.com/channels/1161519468141355160/1161519469319946286/1316541660384985141)** (12 messages🔥): 

> `Video and Audio Input Discussion, LLM Agent Definition Debate, Use of Optimizers with Labeled Data, Impact of AI on Conventional Categories` 


- **投资于文本和图像输入**：成员们讨论了视频和音频输入的价值，其中一人建议目前应专注于文本和图像输入。
   - *我可能眼光不够长远，但我觉得目前投资于文本和图像输入是最好的选择。*
- **什么是 LLM Agent？辩论**：一位成员发起了关于 “LLM agents” 定义的讨论，分享了一个探讨其隐喻含义的帖子。
   - 几位参与者幽默地承认了这场辩论的争议性，指出 *你现在捅了马蜂窝了*。
- **带标签数据的 Optimizer 使用**：针对一个查询，确认了 Optimizer 确实可以与带标签的数据（特别是金标准输入输出对）一起使用。
   - 这一确认引发了成员们的进一步参与，表达了共同的兴趣。
- **AI 作为技术界的新“鸭嘴兽”**：一位成员反思了 AI 如何挑战现有的分类和惯例，将其比作技术界的“鸭嘴兽”。
   - 他们强调 AI 可能是迄今为止最显著的例子，并指出：*AI 和 LLM 的几乎每一个显著特征都在挑战我们的惯例、分类和规则集。*


<div class="linksMentioned">

<strong>提及的链接</strong>：

<ul>
<li>
<a href="https://www.dbreunig.com/2023/05/08/ai-is-a-platypus.html">The Platypus In The Room</a>：关于技术、文化、媒体、数据以及它们之间相互作用方式的文章。</li><li><a href="https://x.com/lateinteraction/status/1867261806726819890">Omar Khattab (@lateinteraction) 的推文</a>：我长期以来一直避免关于定义 “LLM agents” 的争论，因为这感觉很愚蠢。但好吧：就正确答案而言，Agent 是一种抽象。是一种隐喻的选择...
</li>
</ul>

</div>
  

---

### **OpenInterpreter ▷ #[general](https://discord.com/channels/1146610656779440188/1147665339266650133/1316576398097252413)** (6 条消息): 

> `Spider Verse 故障效果, Docker 中的 OI 问题, GitHub model i 教程更新, NVIDIA NIM base URL 设置, 关于 WebVoyager 的想法` 


- **寻找 Spider Verse 故障效果**：一位用户回想起曾看到一个带有 **Spider Verse 故障效果 (glitch effect)** 的网站，并表示希望再次找到它以复制该效果。
   - *我记得看过一个有 Spider Verse 故障效果的网站*，表现出对创意方面的浓厚兴趣。
- **Open Interpreter 的 Docker 问题**：一位成员提出了在 Docker 中运行 **Open Interpreter** 的问题，指出它仅返回模型的聊天响应，而不执行代码。
   - 他们认为该应用程序似乎在假装执行代码，而实际上并没有执行。
- **GitHub Model I 教程的变更**：有人询问了 **GitHub 页面**上关于 model i 教程的最新变化，称大量信息发生了变动。
   - *似乎 GitHub 页面更新了，现在很多东西都不一样了*，表示对文档感到困惑。
- **NVIDIA NIM Base URL 链接配置困扰**：一位用户在设置 **NVIDIA NIM base URL 链接**时寻求帮助，提到他们面临挑战且未获成功。
   - 他们表达了挫败感，称已经尝试了很久但**运气不佳**。
- **WebVoyager 对比 GPT 4V**：一位成员询问了关于 **WebVoyager** 的看法，表示倾向于将模型更新为使用 **GPT o1** 而非 **GPT 4V**，认为这可能会提供更好的结果。
   - 他们对测试该方案并可能切换模型感到好奇。


  

---


### **OpenInterpreter ▷ #[ai-content](https://discord.com/channels/1146610656779440188/1149229778138824765/)** (1 条消息): 

zohebmalik: ChatGPT 第 6 天宣布推出视频转高级语音模式 (Advanced Voice Mode)
  

---


### **tinygrad (George Hotz) ▷ #[general](https://discord.com/channels/1068976834382925865/1068976834928193609/1316701887109791784)** (6 条消息): 

> `测试覆盖率工具, 寻找死代码, Coverage.py, gcov 工具, 代码质量` 


- **寻求测试覆盖率方面的专业建议**：一位成员询问是否有精通**测试覆盖率工具**的用户，以帮助识别**死代码 (dead code)**。
   - 他们强调，如果代码没有经过测试，*它可能应该被删除*。
- **Coverage.py 介绍**：另一位成员推荐使用 [Coverage.py](https://coverage.readthedocs.io/en/7.6.9/) 来测量 Python 中的代码覆盖率，并指出它可以追踪已执行的代码并分析未执行的部分。
   - 最新版本 **7.6.9** 已于 **2024 年 12 月 6 日**发布，支持包括 3.9 到 3.14 alpha 2 在内的多个 Python 版本。
- **关于替代工具的讨论**：一位成员建议使用 [gcov](https://gcc.gnu.org/onlinedocs/gcc/Gcov.html)（一种流行的覆盖率工具），并询问是否有更*细粒度 (fine-grained)* 的选项。
   - 这一询问似乎为进一步讨论各种可用的覆盖率工具拉开了序幕。
- **George Hotz 认可 Coverage.py**：George Hotz 承认 **Coverage.py** 是衡量测试覆盖率的一个*很好的起点*。
   - 他的认可反映了对该工具在提高代码质量方面有效性的信心。



**提到的链接**：<a href="https://coverage.readthedocs.io/en/7.6.9/">Coverage.py &mdash; Coverage.py 7.6.9 文档</a>：未找到描述

  

---

### **Torchtune ▷ #[papers](https://discord.com/channels/1216353675241590815/1293438210097025085/1316530837415792700)** (3 messages): 

> `QRWKV6-32B Model, Compute Efficiency, Training Innovations, RWKV-V6 Attention, Model Limitations` 


- **QRWKV6-32B 模型取得重大突破**：[Recursal AI](https://x.com/rohanpaul_ai/status/1866971776737218564) 将 Qwen 32B Instruct 模型转换为 **QRWKV6** 架构，在推理中实现了原始 32B 的性能，且**计算效率提升了 1000 倍**。
   - 这种转换通过一种新颖的方法将 Transformer Attention 替换为 **RWKV-V6 Attention**，确保了**计算成本的大幅降低**。
- **AMD GPU 的训练速度令人印象深刻**：使用 **16 张 AMD MI300X GPU**（每张 192GB VRAM），QRWKV6 模型的训练仅用 **8 小时**完成，展示了 AI 的快速发展。
   - 未来模型如 **Q-RWKV-6 72B** 和 **RWKV-7 32B** 目前正在开发中，有望提供更强大的能力。
- **Linear Attention 展示了长期潜力**：QRWKV6 模型中采用的 Linear Attention 机制证明在规模化时非常高效，特别是在处理长上下文时。
   - 尽管有这些进步，由于计算限制，该模型目前的上下文长度被限制在 **16k**，但在超出此窗口后仍表现出稳定性。
- **模型转换的关键亮点**：转换过程允许将任何 QKV Attention 模型转换为 RWKV 变体，而无需**全量重新训练**，从而降低了计算成本。
   - 然而，该模型继承了 **Qwen 模型**的语言限制，仅支持约 **30 种语言**，而 RWKV 通常支持 **100 多种语言**。
- **社区协作激发创新**：该模型的训练由 **TensorWave** 赞助，**EleutherAI** 和 RWKV 社区也做出了显著贡献。
   - 虽然转换过程具有开创性，但内部运作的细节可能尚未公开，让一些人对**具体实现方法**感到好奇。



**提及的链接**：<a href="https://x.com/rohanpaul_ai/status/1866971776737218564">来自 Rohan Paul (@rohanpaul_ai) 的推文</a>：新的线性模型：QRWKV6-32B（基于 Qwen2.5-32B 的 RWKV6）和基于 RWKV 的 MoE：Finch-MoE-37B-A11B🚀 Recursal AI 将 Qwen 32B Instruct 模型转换为 QRWKV6 架构，替换了 Transformer Attention...

  

---


### **Gorilla LLM (Berkeley Function Calling) ▷ #[discussion](https://discord.com/channels/1111172801899012102/1111353033352294440/1316840492272717824)** (2 messages): 

> `finetuning Gorilla LLM, downloading GoEx model, implementing reversibility, training in Colab` 


- **为自定义 API 微调 Gorilla LLM**：一位用户正在寻求关于如何微调 **Gorilla LLM** 以识别自定义 API 的指导，并表示之前在此过程中遇到了困难。
   - 他们特别提到了从 Hugging Face 下载 **GoEx 模型**时遇到的挑战。
- **GoEx 模型下载挑战**：该用户提到在尝试下载 **GoEx 模型**以便在 **Colab 环境**中使用时遇到了麻烦。
   - 这种情况凸显了对模型获取需要更清晰的说明或故障排除步骤的需求。
- **寻求可逆性实现策略**：用户询问了在项目中成功实现**可逆性/撤销操作**的参考建议。
   - 这个问题表明了开发者对开发过程中有效控制机制的广泛兴趣。


  

---


### **Axolotl AI ▷ #[general](https://discord.com/channels/1104757954588196865/1104757955204743201/1316689564739305503)** (1 messages): 

> `PYTORCH_TUNABLEOP_ENABLED, PyTorch tunable operations` 


- **探索 PyTorch 的可调优操作**：一位成员发现了关于 `PYTORCH_TUNABLEOP_ENABLED=1` 的相关信息，这与 PyTorch 中的可调优操作（Tunable Operations）有关。详细信息可以在 [PyTorch GitHub repository](https://github.com/pytorch/pytorch/tree/main/aten/src/ATen/cuda/tunable) 中找到。
   - 该功能暗示了 CUDA 可调优操作的优化，增强了开发者利用 PyTorch 的整体效率。
- **关于 CUDA 可调优性的讨论**：围绕 `PYTORCH_TUNABLEOP_ENABLED=1` 的讨论强调了其对 CUDA 操作的潜在益处。成员们认为这可能会提高 GPU 计算任务的性能。
   - 这种可调优方法可能允许开发者更有效地自定义操作，以符合特定用户的需求。


  

---

### **Mozilla AI ▷ #[announcements](https://discord.com/channels/1089876418936180786/1089876419926032396/1316894545656418424)** (1 messages): 

> `Mozilla Builders Demo Day, Community Engagement, Social Media Highlights` 


- **Mozilla Builders Demo Day 回顾发布**：[Mozilla Builders Demo Day 回顾](https://blog.mozilla.org/en/mozilla/mozilla-builders-demo-day/) 重点介绍了成员们如何在挑战性的天气条件下坚持线下聚会。
   - 该活动展示了令人惊叹的技术以及参与者之间的紧密联系。
- **感谢核心贡献者**：对使活动成为可能的特定团队和贡献者表示感谢，特别是那些在 [此处](https://discord.com/channels/1089876418936180786/1301981533447393430) 讨论串中提到的成员。
   - 社区成员们 *冒着海啸般的困难* 前来参加，展现了非凡的韧性和支持。
- **来自活动的社交媒体热度**：Mozilla Builders 分享了他们的社交媒体帖子链接，包括 [LinkedIn 更新](https://www.linkedin.com/posts/mozilla-builders_when-purpose-meets-technology-activity-7273076925529481216-1dug?utm_source=share&utm_medium=member_desktop) 和 X 上的推文。
   - 他们的推文将这次活动概括为 *优秀人才与卓越技术的精彩交汇*。
- **Demo Day 亮点视频已上线**：为错过活动的人分享了名为 [Demo_day.mp4](https://cdn.discordapp.com/attachments/1089876419926032396/1316894546571034715/Demo_day.mp4?ex=675cb51e&is=675b639e&hm=0981245db20d7860bd878f4e98eefb65291266ff8c0dcae04ae28dc0e5b12717&) 的活动亮点视频。
   - 视频展示了当天一些精彩的演示和互动。



**提到的链接**：<a href="https://fxtwitter.com/mozillabuilders/status/1867312203571114041)">来自 Mozilla Builders 🔧 (@mozillabuilders) 的推文</a>：我们终于从 Demo Day 的忙碌中抽身，及时撰写了世界上最有趣的回顾。说真的，这太壮观了——这是优秀人才与卓越技术的交汇...

  

---


---


---


---


{% else %}


> 完整的各频道详情已在邮件中截断。 
> 
> 如果你想查看完整详情，请访问此邮件的网页版：[{{ email.subject }}]({{ email_url }})！
>
> 如果你喜欢 AInews，请[分享给朋友](https://buttondown.email/ainews)！提前感谢！

{% endif %}